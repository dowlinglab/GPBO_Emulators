{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d566f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import qmc\n",
    "from bo_methods_lib.bo_functions_generic import round_time, gen_theta_set,gen_x_set, find_train_doc_path, set_ep, clean_1D_arrays\n",
    "# from bo_methods_lib.GP_Vs_True import Muller_plotter\n",
    "from bo_methods_lib.GP_Vs_True_Sensitivity import Muller_plotter\n",
    "# from .CS1_create_data import gen_y_Theta_GP, calc_y_exp, create_y_data\n",
    "from bo_methods_lib.CS2_create_data import gen_y_Theta_GP, calc_y_exp, create_y_data\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875160c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "#Need to run at a and b, need 2 arrays to test that this will work\n",
    "CS = 2.2\n",
    "\n",
    "Bound_Cut = True #Whether or not to shrink the bounds of the original problem\n",
    "\n",
    "Constants = np.array([[-200,-100,-170,15],\n",
    "                      [-1,-1,-6.5,0.7],\n",
    "                      [0,0,11,0.6],\n",
    "                      [-10,-10,-6.5,0.7],\n",
    "                      [1,0,-0.5,-1],\n",
    "                      [0,0.5,1.5,1]])\n",
    "if CS == 2.2:\n",
    "    skip_param_types = 1 #This is what changes for subpoint\n",
    "    true_p = Constants[skip_param_types:skip_param_types+2].flatten() #Define true parameter set\n",
    "    param_dict = {0 : 'a_1', 1 : 'a_2', 2 : 'a_3', 3 : 'a_4', #Parameter dictionary\n",
    "                  4 : 'b_1', 5 : 'b_2', 6 : 'b_3', 7 : 'b_4'}\n",
    "    exp_d = 2 #Number of experimental x dimensions\n",
    "    if Bound_Cut == True:\n",
    "        bounds_x = np.array([[-1.0, 0.0], #Bounds on X\n",
    "                            [   0.5, 1.5]])\n",
    "        n = 25 #Number of experimental data points to use\n",
    "    else:    \n",
    "        bounds_x = np.array([[-1.5, -0.5],\n",
    "                     [   1,    2]])\n",
    "        n = 27 #Number of experimental data points to use\n",
    "    bounds_p = np.array([[-2, -2, -10, -2, -2, -2,  5, -2], #Bounds on parameter values\n",
    "                   [ 2,  2,   0,  2,  2,  2, 15,  2]])\n",
    "    minima = np.array([[-0.558,1.442], #Minima points\n",
    "                  [-0.050,0.467],\n",
    "                  [0.623,0.028]])\n",
    "\n",
    "    saddle = np.array([[-0.82,0.62], #Saddle points\n",
    "                  [0.22,0.30]])\n",
    "\n",
    "else:\n",
    "    Constants = true_p = np.array([1,-1])\n",
    "    skip_param_types = 0\n",
    "    param_dict = {0 : '\\\\theta_1', 1 : '\\\\theta_2'}\n",
    "    exp_d = 1\n",
    "    n = 5\n",
    "    bounds_x = np.array([[-2], [2]])\n",
    "    bounds_p = np.array([[-2, -2],\n",
    "                         [ 2,  2]])\n",
    "\n",
    "# print(Theta_True)\n",
    "t = 200 #Number of training parameter sets to use\n",
    "d = len(true_p) #dimensionality of parameter sets\n",
    "train_iter = 1000 #Tried 1000 and 300, Number of training iterations to use (not sure how to implement this)\n",
    "noise_std = 0.1 #Standard deviation of the noise\n",
    "initialize = 2 #Number of initializations\n",
    "# set_lengthscale = 1.0\n",
    "set_lengthscale = None #If not none, the value at which to hold the lengthscale constant\n",
    "emulator = True #GP emulates a function, not an error metric\n",
    "obj = \"obj\" #See above\n",
    "verbose = False #Whether functions are verbose\n",
    "\n",
    "if Bound_Cut == True: #Determines which csv to use if bounds are cut vs uncut\n",
    "    cut_bounds = '_cut_bounds'\n",
    "else:\n",
    "    cut_bounds = \"\"\n",
    "\n",
    "#Pull Experimental data from CSV\n",
    "exp_data_doc = 'Input_CSVs/Exp_Data/d='+str(exp_d)+'/n='+str(n)+cut_bounds+'.csv'\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1:exp_d+1]\n",
    "Yexp = exp_data[:,-1]\n",
    "Xexp = clean_1D_arrays(Xexp)\n",
    "\n",
    "#Pull training data from CV\n",
    "all_data_doc = find_train_doc_path(emulator, obj, d, t*n, bound_cut = Bound_Cut)\n",
    "all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\"))\n",
    "X_train = all_data[:,1:(d+exp_d)]\n",
    "Y_train = all_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538d908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set meshgrid values and define a meshgrid over X_space\n",
    "p = 20\n",
    "X1 =  np.linspace(bounds_x[0,0],bounds_x[1,0],p) \n",
    "X2 =  np.linspace(bounds_x[0,1],bounds_x[1,1],p) \n",
    "X_mesh = np.array(np.meshgrid(X1, X2)) \n",
    "#Generate the same points as X_mesh in a 2D array\n",
    "X_space = gen_x_set(LHS = False, n_points = p, dimensions = exp_d, bounds = bounds_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Gaussian Process\n",
    "#Set lengthscale if appropriate and set kernel\n",
    "if set_lengthscale != None:\n",
    "    kernel = 1*Matern(length_scale=set_lengthscale, length_scale_bounds=(1e-05, 10000000.0), nu=2.5) #Matern 5/2\n",
    "    # kernel = 1*Matern(length_scale=1.0, length_scale_bounds=(1e-05, 100000.0), nu=1.5) #Matern 3/2\n",
    "    # kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) # RBF\n",
    "    gaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=noise_std**2, n_restarts_optimizer=initialize, \n",
    "                                                random_state = 9, optimizer = None)\n",
    "else:\n",
    "    kernel = Matern(length_scale=np.ones(X_train.shape[1]), length_scale_bounds=(1e-05, 100.0), nu=2.5) #Matern 5/2\n",
    "    # kernel = 1*Matern(length_scale=1.0, length_scale_bounds=(1e-05, 100000.0), nu=1.5) #Matern 3/2\n",
    "    # kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) # RBF\n",
    "    gaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=noise_std**2, n_restarts_optimizer=initialize, \n",
    "                                                random_state = 9)\n",
    "#Train GP\n",
    "gaussian_process.fit(X_train, Y_train)\n",
    "\n",
    "lenscl_final = kernel.theta\n",
    "print(\"Final Lengthscale: \", lenscl_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_GP_scipy(theta_set, X_space, true_model_coefficients, skip_param_types=0, CS=1):\n",
    "    \"\"\" \n",
    "    Evaluates the GP over some set of X_values and some set of parameter values\n",
    "    Parameters\n",
    "    ----------\n",
    "        theta_set: ndarray (num_LHS_points x dimensions), list of parameter values to test\n",
    "        X_space: ndarray, The p^2 x dim(x) meshgrid points for X over which to evaluate the GP\n",
    "        true_model_coefficients: ndarray, The array containing the true values of problem constants\n",
    "        skip_param_types: The offset of which parameter types (A - y0) that are being guessed. Default 0\n",
    "        CS: float, the number of the case study to be evaluated. Default is 1, other option is 2.2 \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        GP_mean: ndaarray, Array of GP mean predictions at X_space and theta_set\n",
    "        GP_stdev: ndarray, Array of GP variances related to GP means at X_space and theta_set\n",
    "        y_sim: ndarray, simulated values at X_space and theta_set\n",
    "    \"\"\"\n",
    "    #Define dimensionality of X\n",
    "    m = X_space.shape[1]\n",
    "    p_sq = X_space.shape[0]\n",
    "    p = int(np.sqrt(p_sq))\n",
    "    \n",
    "    #Set theta_set to only be parameter values\n",
    "    theta_set_params = theta_set\n",
    "    \n",
    "    #Define the length of theta_set (len_set) and the number of parameters that will be regressed (q)\n",
    "    if len(theta_set_params.shape) > 1:\n",
    "        len_set, q = theta_set_params.shape[0], theta_set_params.shape[1]\n",
    "    else:\n",
    "        theta_set_params = clean_1D_arrays(theta_set_params, param_clean = True)\n",
    "        len_set, q = theta_set_params.shape[0], theta_set_params.shape[1]\n",
    "    \n",
    "    #Initialize values for saving data\n",
    "    GP_mean = np.zeros((p_sq))\n",
    "    GP_var = np.zeros((p_sq))\n",
    "    y_sim = np.zeros((p_sq))\n",
    "    \n",
    "    #Loop over number of X values\n",
    "    for k in range(p_sq):\n",
    "        ##Calculate Values\n",
    "        #Define a parameter set, point\n",
    "        point = list(theta_set_params[0])\n",
    "        #Append Xexp_k to theta_set to evaluate at theta, xexp_k\n",
    "        x_point_data = list(X_space[k]) #astype(np.float)\n",
    "        #Create point to be evaluated\n",
    "        point = point + x_point_data\n",
    "        eval_point = torch.from_numpy(np.array([point])).float()\n",
    "        #Evaluate GP given parameter set theta and state point value\n",
    "        model_mean, model_variance = gaussian_process.predict(eval_point, return_std=True)\n",
    "        #Add values to lists for GP mean and standard deviation\n",
    "        GP_mean[k] = model_mean\n",
    "        GP_var[k] = model_variance\n",
    "        \n",
    "        #Calculate y_sim and save the value for each individual point\n",
    "        if CS == 1:\n",
    "            #Case study 1, the 2D problem takes different arguments for its function create_y_data than 2.2\n",
    "            y_sim[k] = create_y_data(eval_point)\n",
    "        else:\n",
    "            y_sim[k] = create_y_data(eval_point, true_model_coefficients, X_space, skip_param_types)\n",
    "\n",
    "    #Define GP standard deviation    \n",
    "    GP_stdev = np.sqrt(GP_var)  \n",
    "    \n",
    "    if m > 1:\n",
    "        #Turn GP_mean, GP_stdev, and y_sim back into meshgrid form\n",
    "        GP_stdev = np.array(GP_stdev).reshape((p, p))\n",
    "        GP_mean = np.array(GP_mean).reshape((p, p))\n",
    "        y_sim = np.array(y_sim).reshape((p, p))\n",
    "    \n",
    "    return GP_mean, GP_stdev, y_sim\n",
    "\n",
    "#Set parameter set to evaluate at\n",
    "# eval_p = true_p\n",
    "eval_p = X_train[0,1:d+1]\n",
    "print(\"Evaluation Parameter Set\", eval_p)\n",
    "\n",
    "#Evaluate GP for true parameter set value over all of X parameter space\n",
    "GP_mean, GP_stdev, y_sim = eval_GP_scipy(eval_p, X_space, Constants, skip_param_types=skip_param_types, CS=CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot GP Predictions and True value\n",
    "title = [\"Y Sim\", \"GP Mean\", \"GP St.Dev\"]\n",
    "z = [y_sim.T, GP_mean.T, GP_stdev.T]\n",
    "#Not sure how to find stdev of the lengthscale\n",
    "Muller_plotter(X_mesh, z, minima, saddle, title, set_lengthscale, train_iter, t, CS, Bound_Cut, \n",
    "               lenscl_final = lenscl_final, lenscl_noise_final = 0, kernel = \"Mat 5/2\", DateTime = None, X_train = Xexp, \n",
    "               save_csvs = False, save_figure = False, Mul_title = \"\", param = \"\", percentile = \"\", \n",
    "               tot_lev = [40,40,75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560a02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
