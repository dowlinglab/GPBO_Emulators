{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "# from bo_functions import eval_GP_components\n",
    "from bo_functions import create_y_data\n",
    "from bo_functions import bo_iter\n",
    "from bo_functions import test_train_split\n",
    "\n",
    "from bo_plotters import plot_hyperparams\n",
    "# from bo_plotters import sse_plotter\n",
    "# from bo_plotters import stdev_plotter\n",
    "# from bo_plotters import ei_plotter_adv_test\n",
    "# from bo_plotters import ei_plotter\n",
    "from bo_plotters import plot_xy\n",
    "from bo_plotters import error_plotter_4D\n",
    "from bo_plotters import y_plotter_4D\n",
    "from bo_plotters import stdev_plotter_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2934c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull x and Y data from CSV\n",
    "#Pull x data from CSV\n",
    "#Set Parameters\n",
    "Theta_True = np.array([1,-1])\n",
    "BO_iters = 10\n",
    "emulator = False\n",
    "verbose = False\n",
    "BO_iters=10\n",
    "# verbose= False\n",
    "\n",
    "iterations = 300\n",
    "train_iter = 300\n",
    "\n",
    "emulator = True\n",
    "verbose = False\n",
    "\n",
    "shuffle_seed = 6\n",
    "t=4\n",
    "\n",
    "explore_bias = torch.tensor([0,0.1,0.5])\n",
    "\n",
    "#Pull Experimental data from CSV\n",
    "exp_data_doc = \"exp_data.csv\"\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "n = len(Xexp)\n",
    "\n",
    "#Define GP Testing space\n",
    "p=20\n",
    "Theta1 =  np.linspace(0.5,1.5,p) #1x10\n",
    "Theta2 =  np.linspace(-1.5,-0.5,p) #1x10\n",
    "Theta1 =  np.linspace(-2,2,p) #1x10\n",
    "Theta2 =  np.linspace(-2,2,p) #1x10\n",
    "theta_mesh = np.array(np.meshgrid(Theta1, Theta2)) #2 Uniform 5x5 arrays\n",
    "theta1_mesh = theta_mesh[0]\n",
    "theta2_mesh = theta_mesh[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ac3685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(111.2516, dtype=torch.float64)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from bo_functions import create_sse_data\n",
    "train_T = np.array([theta1_mesh[0,1],theta2_mesh[0,1]])\n",
    "print(create_sse_data(2,train_T, Xexp, Yexp, obj = \"obj\"))\n",
    "\n",
    "a = [1,2]\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore Bias: tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:130: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12832025371240505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch365/mcarlozo/Toy_Problem/bo_functions.py:622: RuntimeWarning: invalid value encountered in sqrt\n",
      "  SSE_stdev_GP = np.sqrt(SSE_var_GP)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 3 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(explore_bias)):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplore Bias:\u001b[39m\u001b[38;5;124m\"\u001b[39m, explore_bias[i])\n\u001b[0;32m---> 23\u001b[0m     BO_Results \u001b[38;5;241m=\u001b[39m \u001b[43mbo_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBO_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtheta_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTheta_True\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestarts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_fig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43memulator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExploration Parameter:\u001b[39m\u001b[38;5;124m\"\u001b[39m,explore_bias[i] )\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_functions.py:1058\u001b[0m, in \u001b[0;36mbo_iter\u001b[0;34m(BO_iters, train_p, train_y, theta_mesh, Theta_True, train_iter, explore_bias, Xexp, Yexp, obj, restarts, verbose, save_fig, emulator)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         theta0_o \u001b[38;5;241m=\u001b[39m Theta_Opt_GP\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m#         theta0_b = np.array([0.95,-0.95])\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m#         theta0_o = np.array([0.95,-0.95])\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \n\u001b[1;32m   1057\u001b[0m         \u001b[38;5;66;03m#Use argmax/argmin method as initial guesses for use with scipy.minimize\u001b[39;00m\n\u001b[0;32m-> 1058\u001b[0m         theta_b, theta_o \u001b[38;5;241m=\u001b[39m \u001b[43mfind_opt_best_scipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta0_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtheta0_o\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mei\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;66;03m#Save theta_best and theta_opt values for iteration\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m         All_Theta_Best[i], All_Theta_Opt[i] \u001b[38;5;241m=\u001b[39m theta_b, theta_o\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_functions.py:965\u001b[0m, in \u001b[0;36mfind_opt_best_scipy\u001b[0;34m(theta_mesh, train_y, theta0_b, theta0_o, sse, ei, model, likelihood, explore_bias)\u001b[0m\n\u001b[1;32m    963\u001b[0m     argmts_best \u001b[38;5;241m=\u001b[39m ((train_y, model, likelihood, explore_bias, ei_sse_choice1))\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m#     Best_Solution = optimize.minimize(eval_GP_basic_tot_scipy, theta0_b,bounds=bnds, method='Nelder-Mead',args=argmts_best)\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m     Best_Solution \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_GP_basic_tot_scipy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta0_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margmts_best\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     theta_b \u001b[38;5;241m=\u001b[39m Best_Solution\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m    968\u001b[0m     ei_sse_choice2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_minimize.py:681\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    679\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 681\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    684\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    685\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:308\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m--> 308\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[1;32m    314\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_optimize.py:263\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(grad):\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_functions.py:807\u001b[0m, in \u001b[0;36meval_GP_basic_tot_scipy\u001b[0;34m(theta_guess, train_sse, model, likelihood, explore_bias, ei_sse_choice, verbose)\u001b[0m\n\u001b[1;32m    805\u001b[0m     point \u001b[38;5;241m=\u001b[39m [theta1_guess,theta2_guess]\n\u001b[1;32m    806\u001b[0m     eval_point \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([point])\n\u001b[0;32m--> 807\u001b[0m     GP_Outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_GP_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_point\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m     model_sse \u001b[38;5;241m=\u001b[39m GP_Outputs[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m#1xn \u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m#     print(model_sse)\u001b[39;00m\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_functions.py:440\u001b[0m, in \u001b[0;36mcalc_GP_outputs\u001b[0;34m(model, likelihood, test_param)\u001b[0m\n\u001b[1;32m    429\u001b[0m     test_param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(test_param) \u001b[38;5;66;03m#1xn\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gpytorch\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mfast_pred_var(), torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m#torch.no_grad() \u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;66;03m#Disabling gradient calculation is useful for inference, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m#Good up to 10,000 data points\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m#Predicts data points for model (sse) by sending the model through the likelihood\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     observed_pred \u001b[38;5;241m=\u001b[39m likelihood(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_param\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#1 x n_test\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m#Calculates model mean  \u001b[39;00m\n\u001b[1;32m    443\u001b[0m model_mean \u001b[38;5;241m=\u001b[39m observed_pred\u001b[38;5;241m.\u001b[39mmean \u001b[38;5;66;03m#1 x n_test\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:302\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m         train_input \u001b[38;5;241m=\u001b[39m train_input\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtrain_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m--> 302\u001b[0m     full_inputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Get the joint distribution for training/test data\u001b[39;00m\n\u001b[1;32m    305\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(ExactGP, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39mfull_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 3 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "#Create training and test data\n",
    "##Objective function = SSE\n",
    "##USING SCIPY METHOD\n",
    "##Uses 20 LHS Training points\n",
    "save_fig=False\n",
    "obj = \"LN_obj\"\n",
    "restarts = 0\n",
    "\n",
    "#Set 20 Point Training data, Model, and Likelihood\n",
    "#Pull training data from CSV\n",
    "#Separate training and testing data, uses default of an 80%/20% split\n",
    "all_data_doc = \"all_3_data.csv\"\n",
    "all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\"))\n",
    "train_data, test_data = test_train_split(all_data, shuffle_seed=shuffle_seed)\n",
    "train_p = train_data[:,1:(len(Theta_True)+Xexp[0].size+1)]\n",
    "train_y = train_data[:,-1]\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_p, train_y, likelihood)\n",
    "\n",
    "for i in range(len(explore_bias)):\n",
    "    print(\"Explore Bias:\", explore_bias[i])\n",
    "    BO_Results = bo_iter(BO_iters,train_p,train_y,theta_mesh,Theta_True,train_iter,explore_bias[i], Xexp, \n",
    "                          Yexp, obj, restarts, verbose = verbose,save_fig=save_fig,emulator = emulator)\n",
    "    if verbose == True:\n",
    "        print(\"Exploration Parameter:\",explore_bias[i] )\n",
    "        print(\"Best_GP_Theta \\n\",BO_Results[0])\n",
    "        print(\"\\n Optimal_GP_Theta \\n\",BO_Results[1])\n",
    "        print(\"\\n Total SSE \\n\", BO_Results[2], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9397ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot xy data\n",
    "title = \"XY Comparison\"\n",
    "y_GP_Opt = y_GP[argmin[0],argmin[1],:][0]\n",
    "print(Theta_Opt_GP)\n",
    "plot_xy(Xexp, Yexp, y_GP_Opt,Theta_True,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f659c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_3D = np.meshgrid(Theta1,Theta2,Xexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fd27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "853fa683",
   "metadata": {},
   "source": [
    "stdev_plot = stdev_plotter_4D(mesh_3D,stdev_GP)\n",
    "print(\"Max Stdev: \", np.amax(stdev_GP))\n",
    "print(\"Min Stdev: \", np.amin(stdev_GP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16656",
   "metadata": {},
   "source": [
    "## Analysis of Standard Deviation\n",
    " - The GP estimates that the standard deviation is lowest at points that were directly tested\n",
    "  - This can be rationalized by the way that the contour plot is drawn\n",
    " - Standard deviation is smallest away from the edges and larger towards them\n",
    "  - This is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The more points that get tested, the more the standard deviations will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7420597",
   "metadata": {},
   "source": [
    "error_plot = error_plotter_4D(mesh_3D,error_sq_GP)\n",
    "print(\"Max Error: \", np.amax(error_sq_GP))\n",
    "print(\"Min Error: \", np.amin(error_sq_GP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4a585",
   "metadata": {},
   "source": [
    "## Analysis of Error Squared Magnitude\n",
    " - The GP emulator is most inaccurate when all values of $\\bar{p}$ are at their extreme points \n",
    "  - In general, the GP is less accurate at extreme points, this is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The GP emulator is most accurate after convergence\n",
    " - GP error is mostly very low, as more iterations are added, error decreases"
   ]
  },
  {
   "cell_type": "raw",
   "id": "562e6d2a",
   "metadata": {},
   "source": [
    "y_plot = y_plotter_4D(mesh_3D,y_GP)\n",
    "print(\"Max y: \", np.amax(y_GP))\n",
    "print(\"Min y: \", np.amin(y_GP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d487",
   "metadata": {},
   "source": [
    "## Analysis of GP Emulator (Model y)\n",
    " - The GP emulator correctly captures that y increases as $\\bar{p}$ increases. This tells us that this GP emulator model could be viable\n",
    "  - The GP emulator suitably estimates where the lowest y is achieved and the actual value of y\n",
    "  - Slight error leads to small inaccuracies in the value of $\\bar{\\theta}$ and the values of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1eb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
