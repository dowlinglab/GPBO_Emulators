{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d9c0f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date and Time:  14-Dec-2022 (16:58:57)\n",
      "Runs: 1\n",
      "BO Iterations: 10\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "-------------------\n",
      "Emulator?: False\n",
      "______________________________\n",
      "Sparse Grid?: False\n",
      "Objective Function: obj\n",
      "-  -  -  -  -  -  -  -  -  -  -\n",
      "Separation Factor Train/Test: 0.9\n",
      "Lengthscale Set To: None\n",
      "Explore Bias Multiplier: 1.0\n",
      "Run Number:  1\n",
      "365555.051346344\n",
      "[[0.61032438 0.43428296 0.72599213 0.66055616 0.52820981 0.95271155\n",
      "  0.94534902 0.87020441]]\n",
      "1236476096410.422\n",
      "1.0729034576187826\n",
      "tensor([1.])\n",
      "0.0\n",
      "365555.051346344\n",
      "[[0.00000000e+00 1.00000000e+00 3.70735521e-01 9.23236422e-04\n",
      "  1.66088842e-01 1.69900862e-01 1.00000000e+00 2.43813673e-02]]\n",
      "-945327999181.6357\n",
      "1.283609725144434\n",
      "tensor([1.])\n",
      "945328422912.0\n",
      "365555.051346344\n",
      "[[0.61032438 0.43428296 0.72599213 0.66055616 0.52820981 0.95271155\n",
      "  0.94534902 0.87020441]]\n",
      "1236476096410.4226\n",
      "1.0729034576187826\n",
      "tensor([1.])\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:130\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:1303\u001b[0m, in \u001b[0;36mbo_iter_w_runs\u001b[0;34m(BO_iters, all_data_doc, t, theta_set, Theta_True, train_iter, explore_bias, Xexp, Yexp, noise_std, obj, runs, sparse_grid, emulator, set_lengthscale, true_model_coefficients, param_dict, bounds_p, bounds_x, verbose, save_fig, shuffle_seed, DateTime, sep_fact, LHS, skip_param_types, eval_all_pairs, normalize, case_study)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             bounds_p_scl, train_p_scl, test_p_scl, bounds_x_scl, Xexp_scl, theta_set_scl, Theta_True_scl, true_model_coefficients_scl \u001b[38;5;241m=\u001b[39m  bounds, train_p, test_p, Xexp, theta_set, Theta_True, true_model_coefficients\n\u001b[1;32m   1279\u001b[0m         \u001b[38;5;66;03m#Testing that normalization is happening correctly\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m#         norm = False\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m#         train_p_unscl = train_p_scl.clone()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                              \n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;66;03m#Run BO Iteration\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m         BO_results \u001b[38;5;241m=\u001b[39m \u001b[43mbo_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBO_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtheta_set_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTheta_True_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_lengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDateTime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep_fact\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msep_fact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLHS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_all_pairs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_all_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcase_study\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m         \u001b[38;5;66;03m#Add all SSE/theta results at each BO iteration for that run\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m         Theta_Best_matrix[i,:,:] \u001b[38;5;241m=\u001b[39m BO_results[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:995\u001b[0m, in \u001b[0;36mbo_iter\u001b[0;34m(BO_iters, train_p, train_y, theta_set, Theta_True, train_iter, explore_bias, Xexp, Yexp, noise_std, obj, run, sparse_grid, emulator, set_lengthscale, true_model_coefficients, param_dict, bounds_p, verbose, save_fig, tot_runs, DateTime, test_p, sep_fact, LHS, skip_param_types, eval_all_pairs, normalize, norm_scalers, case_study)\u001b[0m\n\u001b[1;32m    991\u001b[0m         explore_bias \u001b[38;5;241m=\u001b[39m ep_init \u001b[38;5;66;03m#Sets ep to the multiplicative scaler between 0.1 and 1\u001b[39;00m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;66;03m#Evaluate GP to find sse and ei for optimization step\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m#         print(theta_set[0:5], train_p[0:5], Xexp[0:5], true_model_coefficients)\u001b[39;00m\n\u001b[0;32m--> 995\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m \u001b[43meval_GP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_lengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m         \u001b[38;5;66;03m#Determine which parameters will be plotted given the method type and whether verbose is T/F. Save parameters to plot to a list\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m#eval_GP will also save internal parameters used in the calculation of EI if the standard approach is used and verbose is true. These are useful in critically analyzing which components of EI have a large effect, but are tedious to save and take up a lot of space. Therefore, they are only saved when verbose == True    \u001b[39;00m\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m emulator \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:862\u001b[0m, in \u001b[0;36meval_GP\u001b[0;34m(theta_set, train_y, explore_bias, Xexp, Yexp, true_model_coefficients, model, likelihood, verbose, emulator, sparse_grid, set_lengthscale, train_p, obj, skip_param_types, norm_scalers)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m#Evaluate GP based on error emulator or property emulator\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m emulator \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m \u001b[43meval_GP_basic_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m#         eval_components = eval_GP_emulator_tot(Xexp,Yexp, theta_mesh, model, likelihood, sparse_grid, explore_bias, verbose)\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m eval_GP_emulator_set(Xexp, Yexp, theta_set, true_model_coefficients, model, likelihood, sparse_grid, emulator, explore_bias, verbose, train_p, obj, skip_param_types, norm_scalers)\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:483\u001b[0m, in \u001b[0;36meval_GP_basic_set\u001b[0;34m(theta_set, train_sse, model, likelihood, explore_bias, verbose)\u001b[0m\n\u001b[1;32m    480\u001b[0m         eval_point \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([point])\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m#         print(eval_point)\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;66;03m#Note: eval_point[0:1] prevents a shape error from arising when calc_GP_outputs is called\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m         GP_Outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_GP_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_point\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;66;03m#Save GP outputs\u001b[39;00m\n\u001b[1;32m    485\u001b[0m         model_sse \u001b[38;5;241m=\u001b[39m GP_Outputs[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m#1xn\u001b[39;00m\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/bo_functions_generic.py:548\u001b[0m, in \u001b[0;36mcalc_GP_outputs\u001b[0;34m(model, likelihood, test_param)\u001b[0m\n\u001b[1;32m    537\u001b[0m     test_param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(test_param) \u001b[38;5;66;03m#1xn\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gpytorch\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mfast_pred_var(), torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m#torch.no_grad() \u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m#Disabling gradient calculation is useful for inference, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;66;03m#Good up to 10,000 data points\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m#Predicts data points for model (sse) by sending the model through the likelihood\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     observed_pred \u001b[38;5;241m=\u001b[39m likelihood(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_param\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#1 x n_test\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m#Calculates model mean  \u001b[39;00m\n\u001b[1;32m    551\u001b[0m model_mean \u001b[38;5;241m=\u001b[39m observed_pred\u001b[38;5;241m.\u001b[39mmean \u001b[38;5;66;03m#1 x n_test\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:319\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m test_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([joint_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_strategy\u001b[38;5;241m.\u001b[39mtrain_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39mtasks_shape])\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcg_tolerance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_cg_tolerance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    320\u001b[0m     predictive_mean, predictive_covar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_strategy\u001b[38;5;241m.\u001b[39mexact_prediction(full_mean, full_covar)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/linear_operator/settings.py:108\u001b[0m, in \u001b[0;36m_value_context.__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orig_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241m.\u001b[39mvalue()\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instance_value \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_functions_generic import gen_theta_set\n",
    "from bo_methods_lib.CS2_bo_functions_multi_dim import bo_iter_w_runs, find_train_doc_path, set_ep\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "#----------------------------------------------\n",
    "CS = 2.2\n",
    "\n",
    "#Set Date and Time\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S)\")\n",
    "print(\"Date and Time: \", timestampStr)\n",
    "# DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M-%S%p\")\n",
    "DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M\")\n",
    "DateTime = None ##For Testing\n",
    "\n",
    "#Set Parameters\n",
    "#Need to run at a and b, need 2 arrays to test that this will work\n",
    "Constants = np.array([[-200,-100,-170,15],\n",
    "                      [-1,-1,-6.5,0.7],\n",
    "                      [0,0,11,0.6],\n",
    "                      [-10,-10,-6.5,0.7],\n",
    "                      [1,0,-0.5,-1],\n",
    "                      [0,0.5,1.5,1]])\n",
    "\n",
    "Theta_True = Constants[1:3].flatten()\n",
    "# print(Theta_True.shape)\n",
    "param_dict = {0 : 'a_1', 1 : 'a_2', 2 : 'a_3', 3 : 'a_4',\n",
    "              4 : 'b_1', 5 : 'b_2', 6 : 'b_3', 7 : 'b_4'}\n",
    "\n",
    "# print(Theta_True)\n",
    "\n",
    "d = len(Theta_True)\n",
    "BO_iters = 10\n",
    "runs = 1\n",
    "train_iter = 300\n",
    "noise_std = 0.1\n",
    "shuffle_seed = 9\n",
    "sep_fact = np.linspace(0.9,1,1)\n",
    "set_lengthscale = None\n",
    "explore_bias = 1\n",
    "\n",
    "skip_param_types = 1\n",
    "# eval_all_pairs = True\n",
    "eval_all_pairs = False\n",
    "\n",
    "obj = np.array([\"obj\"])\n",
    "# obj = np.array([\"obj\",\"LN_obj\"])\n",
    "# emulator = False\n",
    "emulator = np.array([False])\n",
    "# emulator = np.array([True])\n",
    "# sparse_grid = np.array([True])\n",
    "sparse_grid = np.array([False])\n",
    "norm = True\n",
    "# sparse_grid = np.array([False,True])\n",
    "verbose = False\n",
    "# verbose = True\n",
    "# save_fig = True\n",
    "save_fig = False\n",
    "\n",
    "#Pull Experimental data from CSV\n",
    "exp_d = 2\n",
    "n = 15 #Number of experimental data points to use\n",
    "exp_data_doc = 'Input_CSVs/Exp_Data/d='+str(exp_d)+'/n='+str(n)+'.csv'\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1:exp_d+1]\n",
    "Yexp = exp_data[:,-1]\n",
    "bounds_x = np.array([[-1.5, -0.5],\n",
    "                     [   1,    2]])\n",
    "# print(Xexp)\n",
    "# print(Yexp)\n",
    "#Define GP Testing space\n",
    "LHS = True\n",
    "p=20\n",
    "bounds_p = np.array([[-2, -2, -10, -2, -2, -2,  5, -2],\n",
    "                   [ 2,  2,   0,  2,  2,  2, 15,  2]])\n",
    "# Theta1 =  np.linspace(-2,2,p) #1x10\n",
    "# Theta2 =  np.linspace(-2,2,p) #1x10\n",
    "# theta_mesh = np.array(np.meshgrid(Theta1, Theta2)) #2 Uniform 5x5 arrays \n",
    "theta_mesh = gen_theta_set(LHS = LHS, n_points = p, dimensions = d, bounds = bounds_p)\n",
    "# print(theta_mesh.shape)\n",
    "\n",
    "print(\"Runs:\", runs)\n",
    "print(\"BO Iterations:\",BO_iters)\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "for emul in emulator: \n",
    "    sys.stdout.flush()\n",
    "    obj_use = obj\n",
    "    print(\"-------------------\")\n",
    "    print(\"Emulator?:\", emul)\n",
    "    if emul == True: #Change this based on number of TP for each test\n",
    "        t = 300\n",
    "        sparse_grid_use = sparse_grid\n",
    "    else:\n",
    "        t = 20\n",
    "        sparse_grid_use = np.array([sparse_grid[0]]) #Sparse Grid will always be False for 2-Input\n",
    "        \n",
    "    for sparse in sparse_grid_use:\n",
    "#         #Can set ep to 1 for sparse grid if wanted\n",
    "        if sparse == True:\n",
    "            obj_use =  np.array([\"obj\"])\n",
    "        else:\n",
    "            obj_use =  obj\n",
    "#             ep_use = torch.tensor([1]) \n",
    "#         else:\n",
    "#             ep_use = explore_bias\n",
    "        print(\"______________________________\")\n",
    "        print(\"Sparse Grid?:\", sparse)  \n",
    "\n",
    "        for obj_func in obj_use:\n",
    "            all_data_doc = find_train_doc_path(emul, obj_func, d, t)\n",
    "            all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\")) \n",
    "            print(\"Objective Function:\", obj_func)\n",
    "            print(\"-  -  -  -  -  -  -  -  -  -  -\")\n",
    "            for i in range(len(sep_fact)):\n",
    "#                 explore_bias = set_ep(emul, obj_func, sparse)\n",
    "                ep = torch.tensor([float(explore_bias)])\n",
    "                print(\"Separation Factor Train/Test:\", str(np.round(sep_fact[i],3)))\n",
    "                print(\"Lengthscale Set To:\", set_lengthscale)\n",
    "                print(\"Explore Bias Multiplier:\", str(np.round(float(ep),3)))\n",
    "                results = bo_iter_w_runs(BO_iters,all_data_doc,t,theta_mesh,Theta_True,train_iter,ep, Xexp, Yexp,\n",
    "                                                 noise_std, obj_func, runs, sparse, emul, set_lengthscale, Constants, \n",
    "                                                 param_dict, bounds_p, bounds_x, verbose, save_fig, shuffle_seed, DateTime, \n",
    "                                                 sep_fact = sep_fact[i], LHS = LHS, skip_param_types = skip_param_types, \n",
    "                                                 eval_all_pairs = eval_all_pairs, normalize = norm, case_study = CS)\n",
    "#                 results = bo_iter_w_runs(BO_iters,all_data_doc,t,theta_mesh,Theta_True,train_iter,ep, Xexp, Yexp,\n",
    "#                                              noise_std, obj_func, runs, sparse, emul, set_lengthscale, Constants, \n",
    "#                                              param_dict, verbose, save_fig, shuffle_seed, DateTime, sep_fact = sep_fact[i], \n",
    "#                                              LHS = LHS, skip_param_types = skip_param_types, eval_all_pairs = eval_all_pairs)\n",
    "                print(\"The GP predicts the lowest SSE of\", \"{:.3e}\".format(np.exp(results[3])), \"occurs at \\u03B8 =\", results[2], \n",
    "                          \"during run\", results[1], \"at BO iteration\", results[0])\n",
    "                print(\"At this point, the highest EI occurs at \\u03B8 =\", results[4])\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf7c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
