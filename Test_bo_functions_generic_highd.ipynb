{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d9c0f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date and Time:  04-Jan-2023 (13:20:47)\n",
      "400\n",
      "Runs: 1\n",
      "BO Iterations: 2\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "-------------------\n",
      "Emulator?: True\n",
      "______________________________\n",
      "Sparse Grid?: False\n",
      "Objective Function: LN_obj\n",
      "-  -  -  -  -  -  -  -  -  -  -\n",
      "Separation Factor Train/Test: 0.9\n",
      "Lengthscale Set To: None\n",
      "Explore Bias Multiplier: 1.0\n",
      "Run Number:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/bo_functions_generic.py:699: RuntimeWarning: overflow encountered in exp\n",
      "  bound_a = ((y_target - pred_mean) +np.sqrt(np.exp(error_best*explore_bias)))/pred_stdev #1xn\n",
      "/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/bo_functions_generic.py:700: RuntimeWarning: overflow encountered in exp\n",
      "  bound_b = ((y_target - pred_mean) -np.sqrt(np.exp(error_best*explore_bias)))/pred_stdev #1xn\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:132\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:1339\u001b[0m, in \u001b[0;36mbo_iter_w_runs\u001b[0;34m(BO_iters, all_data_doc, t, theta_set, Theta_True, train_iter, explore_bias, Xexp, Yexp, noise_std, obj, runs, sparse_grid, emulator, set_lengthscale, true_model_coefficients, param_dict, bounds_p, bounds_x, verbose, save_fig, shuffle_seed, DateTime, sep_fact, LHS, skip_param_types, eval_all_pairs, normalize, case_study)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             bounds_p_scl, train_p_scl, test_p_scl, bounds_x_scl, Xexp_scl, theta_set_scl, Theta_True_scl, true_model_coefficients_scl \u001b[38;5;241m=\u001b[39m  bounds_p, train_p, test_p, bounds_x, Xexp, theta_set, Theta_True, true_model_coefficients\n\u001b[1;32m   1314\u001b[0m         \u001b[38;5;66;03m#Testing that normalization is happening correctly\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;66;03m#         print(Xexp, Xexp_scl)\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;66;03m#         norm = False\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1337\u001b[0m                              \n\u001b[1;32m   1338\u001b[0m         \u001b[38;5;66;03m#Run BO Iteration\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m         BO_results \u001b[38;5;241m=\u001b[39m \u001b[43mbo_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBO_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtheta_set_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTheta_True_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_lengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDateTime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep_fact\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msep_fact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLHS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_all_pairs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_all_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcase_study\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1341\u001b[0m         \u001b[38;5;66;03m#Add all SSE/theta results at each BO iteration for that run\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m         Theta_Best_matrix[i,:,:] \u001b[38;5;241m=\u001b[39m BO_results[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:1027\u001b[0m, in \u001b[0;36mbo_iter\u001b[0;34m(BO_iters, train_p, train_y, theta_set, Theta_True, train_iter, explore_bias, Xexp, Yexp, noise_std, obj, run, sparse_grid, emulator, set_lengthscale, true_model_coefficients, param_dict, bounds_p, verbose, save_fig, tot_runs, DateTime, test_p, sep_fact, LHS, skip_param_types, eval_all_pairs, normalize, norm_scalers, case_study)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         explore_bias \u001b[38;5;241m=\u001b[39m ep_init \u001b[38;5;66;03m#Sets ep to the multiplicative scaler between 0.1 and 1\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;66;03m#Evaluate GP to find sse and ei for optimization step\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m#         print(theta_set[0:5], train_p[0:5], Xexp[0:5], true_model_coefficients)\u001b[39;00m\n\u001b[0;32m-> 1027\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m \u001b[43meval_GP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_lengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m         \u001b[38;5;66;03m#Determine which parameters will be plotted given the method type and whether verbose is T/F. Save parameters to plot to a list\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;66;03m#eval_GP will also save internal parameters used in the calculation of EI if the standard approach is used and verbose is true. These are useful in critically analyzing which components of EI have a large effect, but are tedious to save and take up a lot of space. Therefore, they are only saved when verbose == True    \u001b[39;00m\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m emulator \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:879\u001b[0m, in \u001b[0;36meval_GP\u001b[0;34m(theta_set, train_y, explore_bias, Xexp, Yexp, true_model_coefficients, model, likelihood, verbose, emulator, sparse_grid, set_lengthscale, train_p, obj, skip_param_types, norm_scalers)\u001b[0m\n\u001b[1;32m    876\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m eval_GP_basic_set(theta_set, train_y, model, likelihood, explore_bias, verbose)\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m#         eval_components = eval_GP_emulator_tot(Xexp,Yexp, theta_mesh, model, likelihood, sparse_grid, explore_bias, verbose)\u001b[39;00m\n\u001b[0;32m--> 879\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m \u001b[43meval_GP_emulator_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m eval_components\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:408\u001b[0m, in \u001b[0;36meval_GP_emulator_set\u001b[0;34m(Xexp, Yexp, theta_set, true_model_coefficients, model, likelihood, sparse_grid, emulator, explore_bias, verbose, train_p, obj, skip_param_types, norm_scalers)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 SSE_stdev_GP[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mabs(SSE_var_GP[i]))\n\u001b[1;32m    405\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m sparse_grid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m                 \u001b[38;5;66;03m#Compute EI w/ approximation for each value of Xexp_k and add to get final EI\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m#                 print(model_mean.dtype)\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m                 EI_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_ei_emulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_variance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m#                     print(EI_temp)\u001b[39;00m\n\u001b[1;32m    410\u001b[0m                 EI[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m EI_temp\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/bo_functions_generic.py:711\u001b[0m, in \u001b[0;36mcalc_ei_emulator\u001b[0;34m(error_best, pred_mean, pred_var, y_target, explore_bias, obj)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m#             print(bound_lower,bound_upper)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m#             print(error_best, pred_mean, pred_stdev, y_target, explore_bias)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m             \u001b[38;5;66;03m#This first way is very slow\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m#             ei, abs_err = integrate.quad(ei_approx_ln_term, bound_lower, bound_upper, args = args) \u001b[39;00m\n\u001b[1;32m    709\u001b[0m             \u001b[38;5;66;03m#This 2nd way throws the error -> too many values to unpack (expected 3) even though 3 values are being unpacked unless you do it like this and not, EI, abs_err, infordict =\u001b[39;00m\n\u001b[1;32m    710\u001b[0m             ei_term_1 \u001b[38;5;241m=\u001b[39m (error_best\u001b[38;5;241m*\u001b[39mexplore_bias)\u001b[38;5;241m*\u001b[39m( norm\u001b[38;5;241m.\u001b[39mcdf(bound_upper)\u001b[38;5;241m-\u001b[39mnorm\u001b[38;5;241m.\u001b[39mcdf(bound_lower) )\n\u001b[0;32m--> 711\u001b[0m             ei_term_2_out \u001b[38;5;241m=\u001b[39m \u001b[43mintegrate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mei_approx_ln_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound_lower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound_upper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m             ei_term_2 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mei_term_2_out[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m#             ei_term_2 = (-1)*ei_term_2_out[0] \u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/integrate/_quadpack_py.py:351\u001b[0m, in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[1;32m    348\u001b[0m flip, a, b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m<\u001b[39m a, \u001b[38;5;28mmin\u001b[39m(a, b), \u001b[38;5;28mmax\u001b[39m(a, b)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43m_quad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsabs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/integrate/_quadpack_py.py:465\u001b[0m, in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _quadpack\u001b[38;5;241m.\u001b[39m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quadpack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qagie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43minfbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepsabs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepsrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m infbounds \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/bo_functions_generic.py:622\u001b[0m, in \u001b[0;36mei_approx_ln_term\u001b[0;34m(epsilon, error_best, pred_mean, pred_stdev, y_target, ep)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m    Calculates the integrand of expected improvement of the emulator approach using the log version\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m        ei_term_2_integral: ndarray, the expected improvement for term 2 of the GP model for method 2B\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m#     EI = ( (error_best - ep) - np.log( (y_target - pred_mean - pred_stdev*epsilon)**2 ) )*norm.pdf(epsilon)\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m     ei_term_2_integral \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog( \u001b[38;5;28mabs\u001b[39m((y_target \u001b[38;5;241m-\u001b[39m pred_mean \u001b[38;5;241m-\u001b[39m pred_stdev\u001b[38;5;241m*\u001b[39mepsilon)) )\u001b[38;5;241m*\u001b[39m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m#     ei_term_2_integral = np.log( (y_target - pred_mean - pred_stdev*epsilon)**2 )*norm.pdf(epsilon)\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ei_term_2_integral\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/stats/_distn_infrastructure.py:1909\u001b[0m, in \u001b[0;36mrv_continuous.pdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1907\u001b[0m cond \u001b[38;5;241m=\u001b[39m cond0 \u001b[38;5;241m&\u001b[39m cond1\n\u001b[1;32m   1908\u001b[0m output \u001b[38;5;241m=\u001b[39m zeros(shape(cond), dtyp)\n\u001b[0;32m-> 1909\u001b[0m \u001b[43mputmask\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mcond0\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbadvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(cond):\n\u001b[1;32m   1911\u001b[0m     goodargs \u001b[38;5;241m=\u001b[39m argsreduce(cond, \u001b[38;5;241m*\u001b[39m((x,)\u001b[38;5;241m+\u001b[39margs\u001b[38;5;241m+\u001b[39m(scale,)))\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mputmask\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_functions_generic import gen_theta_set\n",
    "from bo_methods_lib.CS2_bo_functions_multi_dim import bo_iter_w_runs, find_train_doc_path, set_ep\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "#----------------------------------------------\n",
    "CS = 2.2\n",
    "\n",
    "#Set Date and Time\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S)\")\n",
    "print(\"Date and Time: \", timestampStr)\n",
    "# DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M-%S%p\")\n",
    "DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M\")\n",
    "DateTime = None ##For Testing\n",
    "\n",
    "#Set Parameters\n",
    "#Need to run at a and b, need 2 arrays to test that this will work\n",
    "Constants = np.array([[-200,-100,-170,15],\n",
    "                      [-1,-1,-6.5,0.7],\n",
    "                      [0,0,11,0.6],\n",
    "                      [-10,-10,-6.5,0.7],\n",
    "                      [1,0,-0.5,-1],\n",
    "                      [0,0.5,1.5,1]])\n",
    "\n",
    "Theta_True = Constants[1:3].flatten()\n",
    "param_dict = {0 : 'a_1', 1 : 'a_2', 2 : 'a_3', 3 : 'a_4',\n",
    "              4 : 'b_1', 5 : 'b_2', 6 : 'b_3', 7 : 'b_4'}\n",
    "\n",
    "# print(Theta_True)\n",
    "\n",
    "d = len(Theta_True)\n",
    "BO_iters = 2\n",
    "runs = 1\n",
    "train_iter = 300\n",
    "noise_std = 0.1\n",
    "shuffle_seed = 9\n",
    "sep_fact = np.linspace(0.9,1,1)\n",
    "set_lengthscale = None\n",
    "explore_bias = 1\n",
    "\n",
    "skip_param_types = 1\n",
    "eval_all_pairs = True\n",
    "eval_all_pairs = False\n",
    "\n",
    "obj = np.array([\"LN_obj\"])\n",
    "# obj = np.array([\"obj\"])\n",
    "# obj = np.array([\"obj\",\"LN_obj\"])\n",
    "# emulator = False\n",
    "# emulator = np.array([False])\n",
    "emulator = np.array([True])\n",
    "sparse_grid = np.array([False])\n",
    "# sparse_grid = np.array([True])\n",
    "norm = True\n",
    "norm = False\n",
    "# sparse_grid = np.array([False,True])\n",
    "verbose = False\n",
    "# verbose = True\n",
    "# save_fig = True\n",
    "save_fig = False\n",
    "\n",
    "#Pull Experimental data from CSV\n",
    "exp_d = 2\n",
    "n = 15 #Number of experimental data points to use\n",
    "exp_data_doc = 'Input_CSVs/Exp_Data/d='+str(exp_d)+'/n='+str(n)+'.csv'\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1:exp_d+1]\n",
    "Yexp = exp_data[:,-1]\n",
    "bounds_x = np.array([[-1.5, -0.5],\n",
    "                     [   1,    2]])\n",
    "# print(Xexp)\n",
    "# print(Yexp)\n",
    "#Define GP Testing space\n",
    "LHS = True\n",
    "p_train = 20\n",
    "p=20\n",
    "bounds_p = np.array([[-2, -2, -10, -2, -2, -2,  5, -2],\n",
    "                   [ 2,  2,   0,  2,  2,  2, 15,  2]])\n",
    "# Theta1 =  np.linspace(-2,2,p) #1x10\n",
    "# Theta2 =  np.linspace(-2,2,p) #1x10\n",
    "# theta_mesh = np.array(np.meshgrid(Theta1, Theta2)) #2 Uniform 5x5 arrays \n",
    "theta_mesh = gen_theta_set(LHS = LHS, n_points = p, dimensions = d, bounds = bounds_p)\n",
    "print(len(theta_mesh))\n",
    "\n",
    "print(\"Runs:\", runs)\n",
    "print(\"BO Iterations:\",BO_iters)\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "for emul in emulator: \n",
    "    sys.stdout.flush()\n",
    "    obj_use = obj\n",
    "    print(\"-------------------\")\n",
    "    print(\"Emulator?:\", emul)\n",
    "    if emul == True: #Change this based on number of TP for each test\n",
    "        t = p_train*n\n",
    "        sparse_grid_use = sparse_grid\n",
    "    else:\n",
    "        t = p_train\n",
    "        sparse_grid_use = np.array([sparse_grid[0]]) #Sparse Grid will always be False for 2-Input\n",
    "        \n",
    "    for sparse in sparse_grid_use:\n",
    "#         #Can set ep to 1 for sparse grid if wanted\n",
    "        if sparse == True:\n",
    "            obj_use =  np.array([\"obj\"])\n",
    "        else:\n",
    "            obj_use =  obj\n",
    "#             ep_use = torch.tensor([1]) \n",
    "#         else:\n",
    "#             ep_use = explore_bias\n",
    "        print(\"______________________________\")\n",
    "        print(\"Sparse Grid?:\", sparse)  \n",
    "\n",
    "        for obj_func in obj_use:\n",
    "            all_data_doc = find_train_doc_path(emul, obj_func, d, t)\n",
    "            all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\")) \n",
    "            print(\"Objective Function:\", obj_func)\n",
    "            print(\"-  -  -  -  -  -  -  -  -  -  -\")\n",
    "            for i in range(len(sep_fact)):\n",
    "#                 explore_bias = set_ep(emul, obj_func, sparse)\n",
    "                ep = torch.tensor([float(explore_bias)])\n",
    "                print(\"Separation Factor Train/Test:\", str(np.round(sep_fact[i],3)))\n",
    "                print(\"Lengthscale Set To:\", set_lengthscale)\n",
    "                print(\"Explore Bias Multiplier:\", str(np.round(float(ep),3)))\n",
    "                results = bo_iter_w_runs(BO_iters,all_data_doc,t,theta_mesh,Theta_True,train_iter,ep, Xexp, Yexp,\n",
    "                                                 noise_std, obj_func, runs, sparse, emul, set_lengthscale, Constants, \n",
    "                                                 param_dict, bounds_p, bounds_x, verbose, save_fig, shuffle_seed, DateTime, \n",
    "                                                 sep_fact = sep_fact[i], LHS = LHS, skip_param_types = skip_param_types, \n",
    "                                                 eval_all_pairs = eval_all_pairs, normalize = norm, case_study = CS)\n",
    "#                 results = bo_iter_w_runs(BO_iters,all_data_doc,t,theta_mesh,Theta_True,train_iter,ep, Xexp, Yexp,\n",
    "#                                              noise_std, obj_func, runs, sparse, emul, set_lengthscale, Constants, \n",
    "#                                              param_dict, verbose, save_fig, shuffle_seed, DateTime, sep_fact = sep_fact[i], \n",
    "#                                              LHS = LHS, skip_param_types = skip_param_types, eval_all_pairs = eval_all_pairs)\n",
    "                print(\"The GP predicts the lowest SSE of\", \"{:.3e}\".format(np.exp(results[3])), \"occurs at \\u03B8 =\", results[2], \n",
    "                          \"during run\", results[1], \"at BO iteration\", results[0])\n",
    "                print(\"At this point, the highest EI occurs at \\u03B8 =\", results[4])\n",
    "                print(\"\\n\")\n",
    "print(Theta_True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403ff5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
