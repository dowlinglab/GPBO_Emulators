{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d5533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy import integrate\n",
    "import torch\n",
    "\n",
    "from bo_functions import ei_approx_ln_term\n",
    "from bo_functions import calc_ei_emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb6250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_best = 1.0376255530659095\n",
    "pred_mean = np.array([-8.14817608, -1.95393033,  0.00769104701, -2.03767010, -2.11993305])\n",
    "pred_stdev = np.array([1.58153871, 1.52678842, 1.52182998, 1.52678842, 1.58153871])\n",
    "pred_var = np.array([1.58153871, 1.52678842, 1.52182998, 1.52678842, 1.58153871])**2\n",
    "y_target = np.array([-14.0031178, -2.99270996,  0.00217820788,  0.991009082, 5.97513219])\n",
    "explore_bias = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8238da",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_best = 1.0376255530659095\n",
    "pred_mean = np.array([-8.14817608, -1.95393033,  0.00769104701, -2.03767010, -2.11993305])\n",
    "pred_stdev = np.array([1.58153871, 1.52678842, 1.52182998, 1.52678842, 1.58153871])\n",
    "pred_var = np.array([1.58153871, 1.52678842, 1.52182998, 1.52678842, 1.58153871])**2\n",
    "y_target = np.array([-14.0031178, -2.99270996,  0.00217820788,  0.991009082, 5.97513219])\n",
    "explore_bias = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb117772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ei_approx_ln_term(epsilon, error_best, pred_mean, pred_stdev, y_target, ep): \n",
    "    \"\"\" \n",
    "    Calculates the integrand of expected improvement of the 3 input parameter GP using the log version\n",
    "    Parameters\n",
    "    ----------\n",
    "        epsilon: The random variable. This is the variable that is integrated w.r.t\n",
    "        error_best: float, the best predicted error encountered\n",
    "        pred_mean: ndarray, model mean\n",
    "        pred_stdev: ndarray, model stdev\n",
    "        y_target: ndarray, the expected value of the function from data or other source\n",
    "        ep: float, the numerical bias towards exploration, zero is the default\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        ei: ndarray, the expected improvement for one term of the GP model\n",
    "    \"\"\"\n",
    "#     EI = ( (error_best - ep) - np.log( (y_target - pred_mean - pred_stdev*epsilon)**2 ) )*norm.pdf(epsilon)\n",
    "\n",
    "    ei_term_2_integral = np.log( abs((y_target - pred_mean - pred_stdev*epsilon)) )*norm.pdf(epsilon)\n",
    "#     ei_term_2_integral = np.log( (y_target - pred_mean - pred_stdev*epsilon)**2 )*norm.pdf(epsilon)\n",
    "    return ei_term_2_integral\n",
    "    \n",
    "def calc_ei_emulator(error_best,pred_mean,pred_var,y_target, explore_bias=0.0, obj = \"obj\"): #Will need obj toggle soon\n",
    "    \"\"\" \n",
    "    Calculates the expected improvement of the 3 input parameter GP\n",
    "    Parameters\n",
    "    ----------\n",
    "        error_best: float, the best predicted error encountered\n",
    "        pred_mean: ndarray, model mean\n",
    "        pred_var: ndarray, model variance\n",
    "        y_target: ndarray, the expected value of the function from data or other source\n",
    "        explore_bias: float, the numerical bias towards exploration, zero is the default\n",
    "        obj: str, LN_obj or obj, determines whether log or regular EI function is calculated\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        ei: ndarray, the expected improvement for one term of the GP model\n",
    "    \"\"\"\n",
    "    #Asserts that f_pred is a float, and y_target is an ndarray\n",
    "    assert isinstance(error_best, (float,int))==True, \"error_best must be a float or integer\"\n",
    "    \n",
    "    #Coverts any tensors given as inputs to ndarrays         \n",
    "    #Checks for equal lengths\n",
    "    assert isinstance(y_target, float)==True, \"y_target, pred_mean, and pred_var must be floats\"\n",
    "    assert isinstance(pred_mean, float)==True, \"y_target, pred_mean, and pred_var must be floats\"\n",
    "    assert isinstance(pred_var, float)==True, \"y_target, pred_mean, and pred_var must be floats\"\n",
    "    \n",
    "    #Defines standard devaition\n",
    "    pred_stdev = np.sqrt(pred_var) #1xn\n",
    "    \n",
    "    #If variance is zero this is important\n",
    "    if obj == \"obj\":\n",
    "        with np.errstate(divide = 'warn'):\n",
    "            #Creates upper and lower bounds and described by Alex Dowling's Derivation\n",
    "#             bound_a = ((y_target - pred_mean) +np.sqrt(error_best - explore_bias))/pred_stdev #1xn\n",
    "#             bound_b = ((y_target - pred_mean) -np.sqrt(error_best - explore_bias))/pred_stdev #1xn\n",
    "            bound_a = ((y_target - pred_mean) +np.sqrt(error_best*explore_bias))/pred_stdev #1xn\n",
    "            bound_b = ((y_target - pred_mean) -np.sqrt(error_best*explore_bias))/pred_stdev #1xn\n",
    "            bound_lower = np.min([bound_a,bound_b])\n",
    "            bound_upper = np.max([bound_a,bound_b])        \n",
    "\n",
    "            #Creates EI terms in terms of Alex Dowling's Derivation\n",
    "            ei_term1_comp1 = norm.cdf(bound_upper) - norm.cdf(bound_lower) #1xn\n",
    "#             ei_term1_comp2 = (error_best - explore_bias) - (y_target - pred_mean)**2 #1xn\n",
    "            ei_term1_comp2 = (error_best*explore_bias) - (y_target - pred_mean)**2 #1xn\n",
    "\n",
    "            ei_term2_comp1 = 2*(y_target - pred_mean)*pred_stdev #1xn\n",
    "            ei_eta_upper = -np.exp(-bound_upper**2/2)/np.sqrt(2*np.pi)\n",
    "            ei_eta_lower = -np.exp(-bound_lower**2/2)/np.sqrt(2*np.pi)\n",
    "            ei_term2_comp2 = (ei_eta_upper-ei_eta_lower)\n",
    "\n",
    "            ei_term3_comp1 = bound_upper*ei_eta_upper #1xn\n",
    "            ei_term3_comp2 = bound_lower*ei_eta_lower #1xn\n",
    "\n",
    "            ei_term3_comp3 = (1/2)*math.erf(bound_upper/np.sqrt(2)) #1xn\n",
    "            ei_term3_comp4 = (1/2)*math.erf(bound_lower/np.sqrt(2)) #1xn     \n",
    "\n",
    "            ei_term3_psi_upper = ei_term3_comp1 + ei_term3_comp3 #1xn\n",
    "            ei_term3_psi_lower = ei_term3_comp2 + ei_term3_comp4 #1xn\n",
    "            ei_term1 = ei_term1_comp1*ei_term1_comp2 #1xn\n",
    "\n",
    "            ei_term2 = ei_term2_comp1*ei_term2_comp2 #1xn\n",
    "            ei_term3 = -pred_var*(ei_term3_psi_upper-ei_term3_psi_lower) #1xn\n",
    "            EI = ei_term1 + ei_term2 + ei_term3 #1xn\n",
    "    else:\n",
    "#         print(\"It's working\")\n",
    "        with np.errstate(divide = 'warn'):\n",
    "            #Creates upper and lower bounds and described by Alex Dowling's Derivation\n",
    "#             bound_a = ((y_target - pred_mean) +np.sqrt(np.exp(error_best - explore_bias)))/pred_stdev #1xn\n",
    "#             bound_b = ((y_target - pred_mean) -np.sqrt(np.exp(error_best - explore_bias)))/pred_stdev #1xn\n",
    "            bound_a = ((y_target - pred_mean) +np.sqrt(np.exp(error_best*explore_bias)))/pred_stdev #1xn\n",
    "            bound_b = ((y_target - pred_mean) -np.sqrt(np.exp(error_best*explore_bias)))/pred_stdev #1xn\n",
    "            bound_lower = np.min([bound_a,bound_b])\n",
    "            bound_upper = np.max([bound_a,bound_b])\n",
    "            \n",
    "            args = (error_best, pred_mean, pred_stdev, y_target, explore_bias)\n",
    "#             print(bound_lower,bound_upper)\n",
    "#             print(error_best, pred_mean, pred_stdev, y_target, explore_bias)\n",
    "            #This first way is very slow\n",
    "#             ei, abs_err = integrate.quad(ei_approx_ln_term, bound_lower, bound_upper, args = args) \n",
    "            #This 2nd way throws the error -> too many values to unpack (expected 3) even though 3 values are being unpacked unless you do it like this and not, EI, abs_err, infordict =\n",
    "            ei_term_1 = (error_best*explore_bias)*( norm.cdf(bound_upper)-norm.cdf(bound_lower) )\n",
    "            ei_term_2_out = integrate.quad(ei_approx_ln_term, bound_lower, bound_upper, args = args, full_output = 1)\n",
    "            ei_term_2 = (-2)*ei_term_2_out[0] \n",
    "#             ei_term_2 = (-1)*ei_term_2_out[0] \n",
    "            term_2_abs_err = ei_term_2_out[1]\n",
    "            EI = ei_term_1 + ei_term_2\n",
    "#             print(EI)\n",
    "   \n",
    "    ei = EI         \n",
    "    return ei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e6a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4493], dtype=torch.float64)\n",
      "CPU times: user 303 ms, sys: 9.01 ms, total: 312 ms\n",
      "Wall time: 302 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ei = 0\n",
    "#Try bringing out the 2 and taking the abs()\n",
    "for i in range(len(y_target)):\n",
    "    with np.errstate(divide = 'warn'):\n",
    "        bound_a = ((y_target[i] - pred_mean[i]) + np.sqrt(np.exp(error_best*explore_bias)))/pred_stdev[i] #1xn\n",
    "        bound_b = ((y_target[i] - pred_mean[i]) - np.sqrt(np.exp(error_best*explore_bias)))/pred_stdev[i] #1xn\n",
    "        bound_lower = np.min([bound_a,bound_b])\n",
    "        bound_upper = np.max([bound_a,bound_b])\n",
    "#         print(bound_lower,bound_upper)\n",
    "\n",
    "        args = (error_best, pred_mean[i], pred_stdev[i], y_target[i], explore_bias)\n",
    "\n",
    "        ei_term_1 = (error_best*explore_bias)*( norm.cdf(bound_upper)-norm.cdf(bound_lower) )\n",
    "    #         print(ei_term_1)\n",
    "        ei_term_2_out = integrate.quad(ei_approx_ln_term, bound_lower, bound_upper, args = args, full_output = 1)\n",
    "        ei_term_2 = (-1)*ei_term_2_out[0] \n",
    "#         print(ei_term_1, ei_term_2)\n",
    "        term_2_abs_err = ei_term_2_out[1]\n",
    "        EI = ei_term_1 + ei_term_2\n",
    "        ei += EI\n",
    "\n",
    "print(ei)\n",
    "\n",
    "#Note: 1min + 45sec per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f418d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.2931], dtype=torch.float64)\n",
      "CPU times: user 296 ms, sys: 1.97 ms, total: 298 ms\n",
      "Wall time: 295 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ei = 0\n",
    "\n",
    "for i in range(len(y_target)):\n",
    "    ei_x = calc_ei_emulator(error_best,pred_mean[i],pred_var[i],y_target[i], explore_bias, obj = \"LN_obj\")\n",
    "    ei += ei_x\n",
    "    \n",
    "print(ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2670eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.2931], dtype=torch.float64)\n",
      "CPU times: user 295 ms, sys: 8.52 ms, total: 303 ms\n",
      "Wall time: 296 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ei = 0\n",
    "\n",
    "for i in range(len(y_target)):\n",
    "    ei_x = calc_ei_emulator(error_best,pred_mean[i],pred_var[i],y_target[i], explore_bias, obj = \"LN_obj\")\n",
    "    ei += ei_x\n",
    "    \n",
    "print(ei)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
