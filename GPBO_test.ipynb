{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-12 17:13:20.093388: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-12 17:13:20.093456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-12 17:13:20.095248: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-12 17:13:20.104615: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-12 17:13:21.621414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "import copy\n",
    "\n",
    "import bo_methods_lib\n",
    "# from bo_methods_lib.bo_methods_lib.bo_functions_generic import gen_theta_set, clean_1D_arrays\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.analyze_data import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pympler\n",
    "import pickle\n",
    "\n",
    "from pympler import asizeof\n",
    "import gpflow\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "cs_name_val = 17\n",
    "ep0 = 1 #Set initial ep as an even mix between exploration and exploitation\n",
    "ep_enum_val = 1\n",
    "meth_name_val = 6\n",
    "sep_fact = 1.0\n",
    "gen_heat_map_data = True\n",
    "normalize = True\n",
    "noise_mean = 0\n",
    "noise_std = None\n",
    "kernel_enum_val = 1\n",
    "lenscl = None #list([0.136113749, 221.573761, 830.968019, 1.67917241, 0.3, 0.2])\n",
    "outputscl = None\n",
    "retrain_GP = 1\n",
    "reoptimize_obj = 1\n",
    "bo_iter_tot = 2\n",
    "bo_run_total = 2\n",
    "runs_per_job_max = 5\n",
    "bo_runs_in_job = 2\n",
    "save_data = False\n",
    "ei_tol = 1e-7\n",
    "obj_tol = 1e-7\n",
    "num_x_data = 10\n",
    "gen_meth_theta = 1 \n",
    "gen_meth_x = 2\n",
    "gen_meth_theta_val = 2\n",
    "num_val_pts = 20\n",
    "num_theta_multiplier = 2 #How many simulation data points to generate is equal to num_theta_multiplier*number of parameters\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.61356984e-03 -1.35428561e-02 -2.11561516e-03 -2.51235296e-03\n",
      "  7.48420613e-03 -7.12119852e-03  6.91286035e-04  1.85894830e-01\n",
      "  1.00027743e+00  1.00383184e+00 -7.23624971e-03  7.52622413e-03\n",
      "  5.92770826e-03  2.33186176e-01  9.81889438e-01  9.94075176e-01\n",
      "  9.98990231e-01  9.93784509e-01  9.98222621e-01  1.00347775e+00\n",
      "  1.55422556e-02  5.60560639e-02  1.09663157e-01  2.53778634e-01\n",
      "  4.02456005e-01  6.14589396e-01  8.49124818e-01  9.59007053e-01\n",
      "  1.00176131e+00  9.98697254e-01  9.92056052e-01  9.78494312e-01\n",
      "  9.65722672e-01  9.32780952e-01  8.51417522e-01  7.30688591e-01\n",
      "  5.73938491e-01  4.61829865e-01  3.11504967e-01  2.67272231e-01\n",
      "  1.97353402e-03 -2.31544630e-03 -7.41137694e-03  7.54707058e-02\n",
      "  5.73580882e-01  8.95015198e-01  9.75599894e-01  9.94099918e-01\n",
      "  9.98321645e-01  1.00373181e+00 -4.95994618e-03  8.23724228e-03\n",
      "  1.16992912e-02  9.98028958e-01  1.00321170e+00  9.99503121e-01\n",
      "  1.00744013e+00  1.00999235e+00  1.01436952e+00  9.90818444e-01]\n",
      "[[ 1627.261251   -4876.15924081]\n",
      " [-3813.86537573   128.37638216]\n",
      " [ 8960.56182663 -1058.31612243]\n",
      " [ 3907.6580206   3977.00215908]\n",
      " [-1831.97895891  9931.10221689]\n",
      " [-9178.37702892  6154.64171695]]\n"
     ]
    }
   ],
   "source": [
    "# Define method, ep_enum classes, indecies to consider, and kernel\n",
    "meth_name = Method_name_enum(meth_name_val)\n",
    "method = GPBO_Methods(meth_name)\n",
    "ep_enum = Ep_enum(ep_enum_val)\n",
    "kernel = Kernel_enum(kernel_enum_val)\n",
    "lenscl = lenscl\n",
    "try:\n",
    "    lenscl = json.loads(lenscl)\n",
    "except:\n",
    "    lenscl = lenscl\n",
    "\n",
    "# Define Simulator Class (Export your Simulator Object Here)\n",
    "# simulator = simulator_helper_test_fxns(\n",
    "#     cs_name_val, noise_mean, noise_std, seed\n",
    "# )\n",
    "#All simulator objects will have the same seed. This keeps restarts/jobs consistent for data generation\n",
    "simulator = simulator_helper_test_fxns(\n",
    "    cs_name_val, noise_mean, noise_std, 1\n",
    ")\n",
    "\n",
    "# Generate Exp Data (OR Add your own experimental data as a Data class object)\n",
    "set_seed = 1  # Set set_seed to 1 for data generation\n",
    "gen_meth_x = Gen_meth_enum(gen_meth_x)\n",
    "if cs_name_val == 16:\n",
    "    x_vals = np.array([0.0,0.1115,0.2475,0.4076,0.5939,0.8230,0.9214,0.9296,0.985,1.000])\n",
    "elif cs_name_val == 17:\n",
    "    x_vals = np.array([0.0087,0.0269,0.0568,0.1556,0.2749,0.4449,0.661,0.8096,0.9309,0.9578])    \n",
    "else:\n",
    "    x_vals = None\n",
    "\n",
    "if cs_name_val in [16,17]:\n",
    "    noise_std = 0.01\n",
    "else:\n",
    "    noise_std = 0.05\n",
    "\n",
    "exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x, set_seed, x_vals, noise_std)\n",
    "\n",
    "#Check to make sure x_vals and y_vals are correct\n",
    "# print(exp_data.x_vals)\n",
    "# print(exp_data.y_vals)\n",
    "\n",
    "# Set simulator noise_std artifically as 5% of y_exp mean (So that noise will be set rather than trained)\n",
    "simulator.noise_std = np.abs(np.mean(exp_data.y_vals)) * noise_std\n",
    "\n",
    "# Create Exploration Bias Class\n",
    "if ep_enum.value == 1:\n",
    "    # Constant value stays constant\n",
    "    ep_bias = Exploration_Bias(\n",
    "        ep0, None, ep_enum, None, None, None, None, None, None, None\n",
    "    )\n",
    "elif ep_enum.value == 2:\n",
    "    # For decay method, decay from mixed to full exploitation (alpha of 0.5) for this example\n",
    "    ep_bias = Exploration_Bias(\n",
    "        ep0,\n",
    "        None,\n",
    "        ep_enum,\n",
    "        None,\n",
    "        bo_iter_tot,\n",
    "        None,\n",
    "        0.5,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "elif ep_enum.value == 3:\n",
    "    # Set ep multiplier to 1.5 as recommended in Boyle\n",
    "    ep_bias = Exploration_Bias(\n",
    "        ep0, None, ep_enum, None, None, 1.5, None, None, None, None\n",
    "    )\n",
    "elif ep_enum.value == 4:\n",
    "    # Jasrasaria method will take care of itself\n",
    "    ep_bias = Exploration_Bias(\n",
    "        None, None, ep_enum, None, None, None, None, None, None, None\n",
    "    )\n",
    "else:\n",
    "    raise Warning(\"Ep_enum value must be between 1 and 4!\")\n",
    "\n",
    "# Generate Sim (Training) Data (OR Add your own training data here as a Data class object)\n",
    "num_theta_data = len(simulator.indices_to_consider) * num_theta_multiplier\n",
    "gen_meth_theta = Gen_meth_enum(gen_meth_theta)\n",
    "# Note at present, training data is always the same between jobs since we set the data generation seed to 1\n",
    "sim_data = simulator.gen_sim_data(\n",
    "    num_theta_data,\n",
    "    num_x_data,\n",
    "    gen_meth_theta,\n",
    "    gen_meth_x,\n",
    "    sep_fact,\n",
    "    set_seed,\n",
    "    False,\n",
    "    x_vals\n",
    ")\n",
    "\n",
    "# print(sim_data.y_vals)\n",
    "# print(sim_data.get_unique_theta())\n",
    "# # Gen sse_sim_data and sse_sim_val_data\n",
    "sim_sse_data = simulator.sim_data_to_sse_sim_data(\n",
    "    method, sim_data, exp_data, sep_fact, False\n",
    ")\n",
    "\n",
    "# Generate validation data if applicable. This is only useful for small (<4 Params + 1 State Point). Otherwise this takes up too much memory\n",
    "if num_val_pts > 0:\n",
    "    gen_meth_theta_val = Gen_meth_enum(\n",
    "        gen_meth_theta_val\n",
    "    )  # input is an integer (1 or 2)\n",
    "    val_data = simulator.gen_sim_data(\n",
    "        num_val_pts,\n",
    "        num_x_data,\n",
    "        gen_meth_theta_val,\n",
    "        gen_meth_x,\n",
    "        sep_fact,\n",
    "        set_seed,\n",
    "        True,\n",
    "        x_vals\n",
    "    )\n",
    "    val_sse_data = simulator.sim_data_to_sse_sim_data(\n",
    "        method, val_data, exp_data, sep_fact, True\n",
    "    )\n",
    "# Set validation data to None if not generating it\n",
    "else:\n",
    "    val_data = None\n",
    "    val_sse_data = None\n",
    "    gen_meth_theta_val = gen_meth_theta_val  # Value is None\n",
    "\n",
    "# Define cs_name and cs_params class\n",
    "cs_name = get_cs_class_from_val(cs_name_val).name #Save name of case study here\n",
    "# Signac saves all BO_Results in different folders, so they can have the same name\n",
    "cs_params = CaseStudyParameters(\n",
    "    cs_name,\n",
    "    ep0,\n",
    "    sep_fact,\n",
    "    normalize,\n",
    "    kernel,\n",
    "    lenscl,\n",
    "    outputscl,\n",
    "    retrain_GP,\n",
    "    reoptimize_obj,\n",
    "    gen_heat_map_data,\n",
    "    bo_iter_tot,\n",
    "    bo_runs_in_job,\n",
    "    save_data,\n",
    "    None,\n",
    "    seed,\n",
    "    ei_tol,\n",
    "    obj_tol,\n",
    ")\n",
    "# Initialize driver class\n",
    "driver = GPBO_Driver(\n",
    "    cs_params,\n",
    "    method,\n",
    "    simulator,\n",
    "    exp_data,\n",
    "    sim_data,\n",
    "    sim_sse_data,\n",
    "    val_data,\n",
    "    val_sse_data,\n",
    "    None,\n",
    "    ep_bias,\n",
    "    gen_meth_theta,\n",
    ")\n",
    "# Get results\n",
    "gpbo_res_simple, gpbo_res_GP = driver.run_bo_restarts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define method, ep_enum classes, indecies to consider, and kernel\n",
    "meth_name = Method_name_enum(meth_name_val)\n",
    "method = GPBO_Methods(meth_name)\n",
    "ep_enum = Ep_enum(ep_enum_val)\n",
    "kernel = Kernel_enum(kernel_enum_val)\n",
    "\n",
    "#Define Simulator Class (Export your Simulator Object Here)\n",
    "simulator = simulator_helper_test_fxns(cs_name_val, noise_mean, noise_std, seed)\n",
    "\n",
    "#Generate Exp Data (OR Add your own experimental data as a Data class object)\n",
    "set_seed = 1 #Set set_seed to 1 for data generation\n",
    "gen_meth_x = Gen_meth_enum(gen_meth_x)\n",
    "# x_vals = None\n",
    "x_vals =np.array([0.0087,0.0269,0.0568,0.1556,0.2749,0.4449,0.661,0.8096,0.9309,0.9578]) #CS17\n",
    "# x_vals = np.array([0.0,0.1115,0.2475,0.4076,0.5939,0.8230,0.9214,0.9296,0.985,1.000]) #CS16\n",
    "exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x, set_seed, x_vals, 0.01)\n",
    "\n",
    "#Set simulator noise_std artifically as 5% of y_exp mean (So that noise will be set rather than trained)\n",
    "simulator.noise_std = np.abs(np.mean(exp_data.y_vals))*0.01\n",
    "\n",
    "#Create Exploration Bias Class\n",
    "if ep_enum.value == 1:\n",
    "    #Constant value stays constant\n",
    "    ep_bias = Exploration_Bias(ep0, None, ep_enum, None, None, None, None, None, None, None)\n",
    "elif ep_enum.value == 2:\n",
    "    #For decay method, decay from mixed to full exploitation (alpha of 0.5) for this example\n",
    "    ep_bias = Exploration_Bias(ep0, None, ep_enum, None, bo_iter_tot, None, 0.5, None, None, None)\n",
    "elif ep_enum.value == 3:\n",
    "    #Set ep multiplier to 1.5 as recommended in Boyle\n",
    "    ep_bias = Exploration_Bias(ep0, None, ep_enum, None, None, 1.5, None, None, None, None)\n",
    "elif ep_enum.value == 4:\n",
    "    #Jasrasaria method will take care of itself\n",
    "    ep_bias = Exploration_Bias(None, None, ep_enum, None, None, None, None, None, None, None)\n",
    "else:\n",
    "    raise Warning(\"Ep_enum value must be between 1 and 4!\")\n",
    "    \n",
    "#Generate Sim (Training) Data (OR Add your own training data here as a Data class object)\n",
    "num_theta_data = len(simulator.indices_to_consider)*num_theta_multiplier\n",
    "gen_meth_theta = Gen_meth_enum(gen_meth_theta)\n",
    "#Note at present, training data is always the same between jobs since we set the data generation seed to 1\n",
    "sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, set_seed, False, x_vals)\n",
    "\n",
    "# #Gen sse_sim_data and sse_sim_val_data\n",
    "sim_sse_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, sep_fact, False)\n",
    "\n",
    "#Generate validation data if applicable. This is only useful for small (<5 Params + State Points). Otherwise this takes up too much memory\n",
    "if num_val_pts > 0:\n",
    "    gen_meth_theta_val = Gen_meth_enum(gen_meth_theta_val) #input is an integer (1 or 2)\n",
    "    val_data = simulator.gen_sim_data(num_val_pts, num_x_data, gen_meth_theta_val, gen_meth_x, sep_fact, set_seed, True)\n",
    "    val_sse_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, sep_fact, True)        \n",
    "#Set validation data to None if not generating it\n",
    "else:\n",
    "    val_data = None\n",
    "    val_sse_data = None\n",
    "    gen_meth_theta_val = gen_meth_theta_val #Value is None\n",
    "                    \n",
    "#Define cs_name and cs_params class\n",
    "#Signac saves all BO_Results in different folders, so they can have the same name\n",
    "cs_name = \"BO_Results\"\n",
    "cs_params = CaseStudyParameters(cs_name, ep0, sep_fact, normalize, kernel, lenscl, outputscl,\n",
    "                                retrain_GP, reoptimize_obj, gen_heat_map_data, bo_iter_tot,\n",
    "                                bo_runs_in_job, True, None, seed, ei_tol, obj_tol)\n",
    "#Initialize driver class\n",
    "driver = GPBO_Driver(cs_params, method, simulator, exp_data, sim_data, sim_sse_data, val_data, val_sse_data, None, ep_bias, gen_meth_theta)\n",
    "#Get results\n",
    "restart_bo_results, gp_stuff = driver.run_bo_restarts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart_bo_results[0].results_df.iloc[:,0:13]\n",
    "#['Theta Min Obj', 'Theta Obj Act Cum', 'Min Obj Act', \"Min Obj Act Cum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Toy_Problem_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
