{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "import pygad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad\n",
    "import numpy\n",
    "cs_num = 11\n",
    "num_restarts = 10 if cs_num in [2,3] else 5\n",
    "\n",
    "class GA_run:\n",
    "    def __init__(self, num_generations, num_parents_mating, sol_per_pop, cs_num):\n",
    "        self.num_generations = num_generations\n",
    "        self.num_parents_mating = num_parents_mating\n",
    "        self.sol_per_pop = sol_per_pop\n",
    "        self.cs_num = cs_num\n",
    "        self.count = 0\n",
    "        self.cs_genmeth_dict = {\n",
    "            \"Simple Linear\": 1,\n",
    "            \"Muller x0\": 2,\n",
    "            \"Muller y0\": 2,\n",
    "            \"Yield-Loss\": 1,\n",
    "            \"Large Linear\": 2,\n",
    "            \"BOD Curve\": 1,\n",
    "            \"Log Logistic\": 1,\n",
    "            \"2D Log Logistic\": 2,\n",
    "        }\n",
    "\n",
    "        self.cs_xval_dict = {\n",
    "            \"Simple Linear\": 5,\n",
    "            \"Muller x0\": 5,\n",
    "            \"Muller y0\": 5,\n",
    "            \"Yield-Loss\": 10,\n",
    "            \"Large Linear\": 5,\n",
    "            \"BOD Curve\": 10,\n",
    "            \"Log Logistic\": 10,\n",
    "            \"2D Log Logistic\": 5,\n",
    "        }\n",
    "        self.get_cs_class_data(cs_num)\n",
    "\n",
    "    def get_cs_class_data(self, cs_num):\n",
    "        simulator = simulator_helper_test_fxns(cs_num, 0, None, 1)\n",
    "        cs_class = get_cs_class_from_val(cs_num)\n",
    "        gen_meth = Gen_meth_enum(self.cs_genmeth_dict[cs_class.name])\n",
    "        exp_data = simulator.gen_exp_data(self.cs_xval_dict[cs_class.name],\n",
    "                                          gen_meth, \n",
    "                                          1)\n",
    "        \n",
    "        simulator.noise_std = np.abs(np.mean(exp_data.y_vals))*0.05\n",
    "        self.num_genes = exp_data.get_dim_theta()# len(exp_data.x_vals)\n",
    "        self.simulator = simulator\n",
    "        self.exp_data = exp_data\n",
    "\n",
    "    def fitness_func(self, ga_instance, solution, solution_idx):\n",
    "        self.count += 1\n",
    "        soln_repeat = np.vstack([solution] * len(self.exp_data.x_vals))\n",
    "        solution_data = Data(\n",
    "            soln_repeat,\n",
    "            self.exp_data.x_vals,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            self.simulator.bounds_theta_reg,\n",
    "            self.simulator.bounds_x,\n",
    "            1,\n",
    "            1,\n",
    "        )\n",
    "        # print(self.exp_data.x_vals)\n",
    "        output = self.simulator.gen_y_data(solution_data, 0, self.simulator.noise_std)\n",
    "        # print(np.array(solution).reshape(1,-1), output)\n",
    "        sse = np.sum((self.exp_data.y_vals - output)**2)\n",
    "        fitness = 1/(sse+1e-6)\n",
    "        return float(fitness)\n",
    "    \n",
    "    def run(self):\n",
    "        gene_space = [{'low': row[0], 'high': row[1]} for row in self.simulator.bounds_theta_reg.T]\n",
    "        ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       gene_space = gene_space,\n",
    "                       num_genes=self.num_genes,\n",
    "                       fitness_func=self.fitness_func)\n",
    "        ga_instance.run()\n",
    "        # ga_instance.plot_fitness()\n",
    "        solution, solution_fitness, solution_idx = ga_instance.best_solution(ga_instance.last_generation_fitness)\n",
    "        # print(f\"Parameters of the best solution : {solution}\")\n",
    "        # # print(f\"Fitness value of the best solution = {solution_fitness}\")\n",
    "        sse = 1/solution_fitness + 1e-6\n",
    "        # print(f\"SSE of the best solution = {sse}\")\n",
    "        # print(f\"Index of the best solution : {solution_idx}\")\n",
    "        # if ga_instance.best_solution_generation != -1:\n",
    "        #     print(f\"Best fitness value reached after {ga_instance.best_solution_generation} generations.\")\n",
    "        # print(\"SSE Evaluations\", self.count)\n",
    "        self.ga_instance = ga_instance\n",
    "\n",
    "        return sse\n",
    "    \n",
    "\n",
    "num_generations = 50 # Number of generations.\n",
    "num_parents_mating = int(num_generations/10) # Number of solutions to be selected as parents in the mating pool.\n",
    "sol_per_pop = int(num_generations/5) # Number of solutions in the population.\n",
    "\n",
    "ga_classes = []\n",
    "solns = []\n",
    "for i in range(num_restarts):\n",
    "    garun = GA_run(num_generations, num_parents_mating, sol_per_pop, cs_num)\n",
    "    sse = garun.run()\n",
    "    ga_classes.append(garun)\n",
    "    solns.append(sse)\n",
    "\n",
    "# print(\"Min is: \", min(solns), \"at index: \", solns.index(min(solns)))\n",
    "use_ga = ga_classes[solns.index(min(solns))]\n",
    "# use_ga.ga_instance.plot_fitness()\n",
    "solution, solution_fitness, solution_idx = use_ga.ga_instance.best_solution(use_ga.ga_instance.last_generation_fitness)\n",
    "print(f\"Parameters of the best solution : {solution}\")\n",
    "# print(f\"Fitness value of the best solution = {solution_fitness}\")\n",
    "sse = 1/solution_fitness + 1e-6\n",
    "print(f\"SSE of the best solution = {sse}\")\n",
    "# print(f\"Index of the best solution : {solution_idx}\")\n",
    "# if use_ga.ga_instance.best_solution_generation != -1:\n",
    "#     print(f\"Best fitness value reached after {use_ga.ga_instance.best_solution_generation} generations.\")\n",
    "print(\"SSE Evaluations\", use_ga.count)\n",
    "\n",
    "# Saving the GA instance.\n",
    "# filename = 'genetic' # The filename to which the instance is saved. The name is without extension.\n",
    "# ga_instance.save(filename=filename)\n",
    "\n",
    "# Loading the saved GA instance.\n",
    "# loaded_ga_instance = pygad.load(filename=filename)\n",
    "# loaded_ga_instance.plot_fitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import shgo\n",
    "\n",
    "class SHGO_run:\n",
    "    def __init__(self, cs_num):\n",
    "        self.cs_num = cs_num\n",
    "        self.count = 0\n",
    "        self.cs_genmeth_dict = {\n",
    "            \"Simple Linear\": 1,\n",
    "            \"Muller x0\": 2,\n",
    "            \"Muller y0\": 2,\n",
    "            \"Yield-Loss\": 1,\n",
    "            \"Large Linear\": 2,\n",
    "            \"BOD Curve\": 1,\n",
    "            \"Log Logistic\": 1,\n",
    "            \"2D Log Logistic\": 2,\n",
    "        }\n",
    "\n",
    "        self.cs_xval_dict = {\n",
    "            \"Simple Linear\": 5,\n",
    "            \"Muller x0\": 5,\n",
    "            \"Muller y0\": 5,\n",
    "            \"Yield-Loss\": 10,\n",
    "            \"Large Linear\": 5,\n",
    "            \"BOD Curve\": 10,\n",
    "            \"Log Logistic\": 10,\n",
    "            \"2D Log Logistic\": 5,\n",
    "        }\n",
    "        self.get_cs_class_data(cs_num)\n",
    "\n",
    "    def get_cs_class_data(self, cs_num):\n",
    "        simulator = simulator_helper_test_fxns(cs_num, 0, None, 1)\n",
    "        cs_class = get_cs_class_from_val(cs_num)\n",
    "        gen_meth = Gen_meth_enum(self.cs_genmeth_dict[cs_class.name])\n",
    "        exp_data = simulator.gen_exp_data(self.cs_xval_dict[cs_class.name],\n",
    "                                          gen_meth, \n",
    "                                          1)\n",
    "        simulator.noise_std = np.abs(np.mean(exp_data.y_vals))*0.05\n",
    "        self.num_genes = exp_data.get_dim_theta()# len(exp_data.x_vals)\n",
    "        self.simulator = simulator\n",
    "        self.exp_data = exp_data\n",
    "\n",
    "    def shgo_scipy_func(self, theta_guess, exp_data, simulator):\n",
    "        \"\"\"\n",
    "        Function to define regression function for least-squares fitting\n",
    "        Parameters\n",
    "        ----------\n",
    "        theta_guess: np.ndarray\n",
    "            The parameter set values to evaluate\n",
    "        exp_data: Data\n",
    "            The experimental data to evaluate\n",
    "        simulator: Simulator\n",
    "            The simulator object to evaluate\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        error: np.ndarray\n",
    "            The error between the experimental data and the simulated data\n",
    "        \"\"\"\n",
    "        # Repeat the theta best array once for each x value\n",
    "        # Need to repeat theta_best such that it can be evaluated at every x value in exp_data using simulator.gen_y_data\n",
    "        t_guess_repeat = np.repeat(\n",
    "            theta_guess.reshape(1, -1), exp_data.get_num_x_vals(), axis=0\n",
    "        )\n",
    "        # Add instance of Data class to theta_best\n",
    "        theta_guess_data = Data(\n",
    "            t_guess_repeat,\n",
    "            exp_data.x_vals,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            simulator.bounds_theta_reg,\n",
    "            simulator.bounds_x,\n",
    "            1,\n",
    "            simulator.seed,\n",
    "        )\n",
    "        # Calculate y values and sse for theta_best with noise\n",
    "        theta_guess_data.y_vals = simulator.gen_y_data(\n",
    "            theta_guess_data, simulator.noise_mean, simulator.noise_std\n",
    "        )\n",
    "\n",
    "        error = exp_data.y_vals.flatten() - theta_guess_data.y_vals.flatten()\n",
    "\n",
    "        return np.sum(error**2)\n",
    "    \n",
    "    def run(self):\n",
    "        # Find shgo solution\n",
    "        solution = optimize.shgo(\n",
    "        lambda theta_guess: self.shgo_scipy_func(theta_guess, self.exp_data, self.simulator),\n",
    "        bounds = self.simulator.bounds_theta_reg.T,\n",
    "        sampling_method=\"sobol\",\n",
    "    )\n",
    "        self.solution = solution\n",
    "\n",
    "        return sse\n",
    "\n",
    "shgo_classes = []\n",
    "solns = []\n",
    "for i in range(num_restarts):\n",
    "    SHGO = SHGO_run(cs_num)\n",
    "    sse = SHGO.run()\n",
    "    shgo_classes.append(SHGO)\n",
    "    solns.append(sse)\n",
    "\n",
    "use_shgo = shgo_classes[solns.index(min(solns))]\n",
    "print(f\"Parameters of the best solution : {use_shgo.solution.x}\")\n",
    "print(f\"SSE of the best solution = {use_shgo.solution.fun}\")\n",
    "print(\"SSE Evaluations\", use_shgo.solution.nfev)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import shgo\n",
    "from scipy import optimize\n",
    "\n",
    "class NM_run:\n",
    "    def __init__(self, cs_num):\n",
    "        self.cs_num = cs_num\n",
    "        self.count = 0\n",
    "        self.cs_genmeth_dict = {\n",
    "            \"Simple Linear\": 1,\n",
    "            \"Muller x0\": 2,\n",
    "            \"Muller y0\": 2,\n",
    "            \"Yield-Loss\": 1,\n",
    "            \"Large Linear\": 2,\n",
    "            \"BOD Curve\": 1,\n",
    "            \"Log Logistic\": 1,\n",
    "            \"2D Log Logistic\": 2,\n",
    "        }\n",
    "\n",
    "        self.cs_xval_dict = {\n",
    "            \"Simple Linear\": 5,\n",
    "            \"Muller x0\": 5,\n",
    "            \"Muller y0\": 5,\n",
    "            \"Yield-Loss\": 10,\n",
    "            \"Large Linear\": 5,\n",
    "            \"BOD Curve\": 10,\n",
    "            \"Log Logistic\": 10,\n",
    "            \"2D Log Logistic\": 5,\n",
    "        }\n",
    "        self.get_cs_class_data(cs_num)\n",
    "\n",
    "    def get_cs_class_data(self, cs_num):\n",
    "        simulator = simulator_helper_test_fxns(cs_num, 0, None, 1)\n",
    "        cs_class = get_cs_class_from_val(cs_num)\n",
    "        gen_meth = Gen_meth_enum(self.cs_genmeth_dict[cs_class.name])\n",
    "        exp_data = simulator.gen_exp_data(self.cs_xval_dict[cs_class.name],\n",
    "                                          gen_meth, \n",
    "                                          1)\n",
    "        simulator.noise_std = np.abs(np.mean(exp_data.y_vals))*0.05\n",
    "        self.simulator = simulator\n",
    "        self.num_genes = exp_data.get_dim_theta()# len(exp_data.x_vals)\n",
    "        self.exp_data = exp_data\n",
    "\n",
    "    def NM_scipy_func(self, theta_guess, exp_data, simulator):\n",
    "        \"\"\"\n",
    "        Function to define regression function for least-squares fitting\n",
    "        Parameters\n",
    "        ----------\n",
    "        theta_guess: np.ndarray\n",
    "            The parameter set values to evaluate\n",
    "        exp_data: Data\n",
    "            The experimental data to evaluate\n",
    "        simulator: Simulator\n",
    "            The simulator object to evaluate\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        error: np.ndarray\n",
    "            The error between the experimental data and the simulated data\n",
    "        \"\"\"\n",
    "        # Repeat the theta best array once for each x value\n",
    "        # Need to repeat theta_best such that it can be evaluated at every x value in exp_data using simulator.gen_y_data\n",
    "        t_guess_repeat = np.repeat(\n",
    "            theta_guess.reshape(1, -1), exp_data.get_num_x_vals(), axis=0\n",
    "        )\n",
    "        # Add instance of Data class to theta_best\n",
    "        theta_guess_data = Data(\n",
    "            t_guess_repeat,\n",
    "            exp_data.x_vals,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            simulator.bounds_theta_reg,\n",
    "            simulator.bounds_x,\n",
    "            1,\n",
    "            simulator.seed,\n",
    "        )\n",
    "        # Calculate y values and sse for theta_best with noise\n",
    "        theta_guess_data.y_vals = simulator.gen_y_data(\n",
    "            theta_guess_data, simulator.noise_mean, simulator.noise_std\n",
    "        )\n",
    "\n",
    "        error = exp_data.y_vals.flatten() - theta_guess_data.y_vals.flatten()\n",
    "\n",
    "        return np.sum(error**2)\n",
    "    \n",
    "    def run(self):\n",
    "        # Find shgo solution\n",
    "        solution = optimize.minimize(\n",
    "        self.NM_scipy_func,\n",
    "        np.random.uniform(self.simulator.bounds_theta_reg[0], self.simulator.bounds_theta_reg[1]),\n",
    "        method = 'Nelder-Mead',\n",
    "        bounds = self.simulator.bounds_theta_reg.T,\n",
    "        args = (self.exp_data, self.simulator)\n",
    "    )\n",
    "        self.solution = solution\n",
    "\n",
    "        return sse\n",
    "\n",
    "nm_classes = []\n",
    "solns = []\n",
    "for i in range(num_restarts):\n",
    "    neldmead = NM_run(cs_num)\n",
    "    sse = neldmead.run()\n",
    "    nm_classes.append(neldmead)\n",
    "    solns.append(sse)\n",
    "\n",
    "use_nm = nm_classes[solns.index(min(solns))]\n",
    "print(f\"Parameters of the best solution : {use_nm.solution.x}\")\n",
    "print(f\"SSE of the best solution = {use_nm.solution.fun}\")\n",
    "print(\"SSE Evaluations\", use_nm.solution.nfev)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Define the methods to loop over\n",
    "methods = ['GPBO','GA', 'SHGO', 'NM']\n",
    "\n",
    "# Loop over CS numbers and methods\n",
    "for cs_num in [11, 14, 2, 1, 12, 13, 3, 10]:\n",
    "    num_restarts = 10 if cs_num in [2, 3] else 5  # Determine the number of restarts for each cs_num\n",
    "    max_runs = 75 if cs_num in [2, 3] else 50  # Determine the number of runs for each cs_num\n",
    "    cs_class = get_cs_class_from_val(cs_num)  # Get the CS class\n",
    "    cs_name = cs_class.name  # Get the name of the CS class\n",
    "    cs_genmeth_dict = {\n",
    "            \"Simple Linear\": 1,\n",
    "            \"Muller x0\": 2,\n",
    "            \"Muller y0\": 2,\n",
    "            \"Yield-Loss\": 1,\n",
    "            \"Large Linear\": 2,\n",
    "            \"BOD Curve\": 1,\n",
    "            \"Log Logistic\": 1,\n",
    "            \"2D Log Logistic\": 2,\n",
    "        }\n",
    "\n",
    "    cs_xval_dict = {\n",
    "        \"Simple Linear\": 5,\n",
    "        \"Muller x0\": 5,\n",
    "        \"Muller y0\": 5,\n",
    "        \"Yield-Loss\": 10,\n",
    "        \"Large Linear\": 5,\n",
    "        \"BOD Curve\": 10,\n",
    "        \"Log Logistic\": 10,\n",
    "        \"2D Log Logistic\": 5,\n",
    "    }\n",
    "\n",
    "    for method in methods:\n",
    "        if method == 'GPBO':\n",
    "            df = pd.read_csv('/scratch365/mcarlozo/Toy_Problem/Results_act/cs_name_val_' +str(cs_num) +'/ep_enum_val_1/gp_package_gpflow/meth_name_val_in_1_2_3_4_5_6_7/best_results.csv', header=0)\n",
    "            sse_method = df['Min Obj Act Cum'].min()\n",
    "            count_method = df['Max Evals'].iloc[df['Min Obj Act Cum'].idxmin()] + len(cs_class.idcs_to_consider)*10\n",
    "            soln_best = df['Theta Min Obj'].iloc[df['Min Obj Act Cum'].idxmin()]\n",
    "            method_report = df['BO Method'].iloc[df['Min Obj Act Cum'].idxmin()]\n",
    "            if \"Log\" in method_report:\n",
    "                sse_method = np.exp(sse_method)\n",
    "        else:\n",
    "            method_report = method\n",
    "            classes = []\n",
    "            solns = []\n",
    "            \n",
    "            for i in range(num_restarts):\n",
    "                if method == 'GA':\n",
    "                    classobj = GA_run(num_generations, num_parents_mating, sol_per_pop, cs_num)\n",
    "                elif method == 'NM':\n",
    "                    classobj = NM_run(cs_num)\n",
    "                elif method == 'SHGO':\n",
    "                    classobj = SHGO_run(cs_num)\n",
    "            \n",
    "                sse = classobj.run()\n",
    "                classes.append(classobj)\n",
    "                solns.append(sse)\n",
    "\n",
    "            best_class = classes[solns.index(min(solns))]\n",
    "\n",
    "            if method == 'GA':\n",
    "                soln_best, solution_fitness, solution_idx = best_class.ga_instance.best_solution(best_class.ga_instance.last_generation_fitness)\n",
    "                sse_method = min(solns)\n",
    "                count_method = best_class.count  # Number of evaluations for GA\n",
    "            elif method != \"GPBO\":\n",
    "                soln_best = best_class.solution.x  # Parameters for NM solution\n",
    "                sse_method = best_class.solution.fun  # SSE for NM solution\n",
    "                count_method = best_class.solution.nfev  # Number of evaluations for NM\n",
    "\n",
    "        # Append the results to the list\n",
    "        results.append({\n",
    "            'CS_Name': cs_name,\n",
    "            'Method': method_report,\n",
    "            'SSE': sse_method,\n",
    "            'Loss_Evals': count_method,\n",
    "            'Best_Solution': soln_best\n",
    "        })\n",
    "\n",
    "# Convert the list of results into a pandas DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "df.to_csv('stochastic_res_sob_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Toy_Problem_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
