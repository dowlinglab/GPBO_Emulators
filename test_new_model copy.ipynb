{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 20:40:34.370244: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-10 20:40:34.370301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-10 20:40:34.372307: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 20:40:34.382183: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 20:40:35.449835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "log_plot = True\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "\n",
    "criteria_dict = {\"cs_name_val\" : 12}\n",
    "project = signac.get_project(\"GPBO_Fix\")\n",
    "save_csv = False\n",
    "save_figs = False\n",
    "analyzer = General_Analysis(criteria_dict, project, mode = \"act\", save_csv = save_csv)\n",
    "plotters = Plotters(analyzer, save_figs)\n",
    "\n",
    "def grid_sampling(num_points, bounds):\n",
    "        \"\"\"\n",
    "        Generates Grid sampled data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_points: int, number of points in LHS, should be greater than # of dimensions\n",
    "        bounds: ndarray, array containing upper and lower bounds of elements in LHS sample. Defaults of 0 and 1\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        grid_data: ndarray, (num_points)**bounds.shape[1] grid sample of data\n",
    "        \n",
    "        \"\"\"\n",
    "        #Generate mesh_grid data for theta_set in 2D\n",
    "        #Define linspace for theta\n",
    "        params = np.linspace(0,1, num_points)\n",
    "        #Define dimensions of parameter\n",
    "        dimensions = bounds.shape[1]\n",
    "        #Generate the equivalent of all meshgrid points\n",
    "        df = pd.DataFrame(list(itertools.product(params, repeat=dimensions)))\n",
    "        df2 = df.drop_duplicates()\n",
    "        scaled_data = df2.to_numpy()\n",
    "        #Normalize to bounds \n",
    "        lower_bound = bounds[0]\n",
    "        upper_bound = bounds[1]\n",
    "        grid_data = scaled_data*(upper_bound - lower_bound) + lower_bound \n",
    "        return grid_data\n",
    "\n",
    "#Create a function to define the SSE for any Theta vector on a heat map.\n",
    "def sse_func(xx, yy, x, y, args):\n",
    "    '''\n",
    "    Function to define define sum of squared error function for heat map\n",
    "    Arguments:\n",
    "        xx: An N X D array of all Theta1 values\n",
    "            \n",
    "        yy: An D X N array of all Theta2 values\n",
    "        theta: parameter vector\n",
    "        x: independent variable vector (predicted x values including noise)\n",
    "        y: dependent variable vector (predicted y values on Heat Map)\n",
    "    Returns:\n",
    "        sse: N x N sum of squared error matrix of all generated combination of xx and yy\n",
    "    '''\n",
    "    sse = np.zeros([len(xx),len(yy)])\n",
    "    \n",
    "    for i in range(len(xx)):\n",
    "        for j in range(len(yy)):\n",
    "            theta = np.array([xx[i][j],yy[i][j]])\n",
    "            sse[i][j] = sum((y - uniquac_model(theta,x, args))**2) \n",
    "    \n",
    "    return sse\n",
    "\n",
    "# Create a function to optimize, in this case, least squares fitting\n",
    "def regression_func(theta_guess, x, y, args=None):\n",
    "    '''\n",
    "    Function to define regression function for least-squares fitting\n",
    "    Arguments:\n",
    "        theta_guess: ndarray, guess value for a\n",
    "        Constants: ndarray, The array containing the true values of Muller constants\n",
    "        x: ndarray, experimental X data (Inependent Variable)\n",
    "        y: ndarray, experimental Y data (Dependent Variable)\n",
    "    Returns:\n",
    "        e: residual vector\n",
    "    '''\n",
    "    \n",
    "    error = y - calc_mm_model(theta_guess,x, args); #NOTE: Least squares will calculate sse based off this to minimize\n",
    "    \n",
    "    return error\n",
    "\n",
    "def calc_gamma_exp(Xexp, P, y1, theta_ref, args):\n",
    "    # Extract parameters\n",
    "    r = np.array(args[\"r\"])\n",
    "    q = np.array(args[\"q\"])\n",
    "    z = args.get(\"z\", 10)\n",
    "    R = args[\"R\"]\n",
    "    T = args[\"T\"]\n",
    "    A, B, C = np.array(args[\"A\"]), np.array(args[\"B\"]), np.array(args[\"C\"])\n",
    "    \n",
    "    l = (z / 2) * (r - q) - (r - 1)\n",
    "    tau = np.exp(-theta_ref / (R * T))\n",
    "    psat = 10 ** (A - (B / (C + (T - 273.15))))\n",
    "    term1 = np.log(r[0]/r[1])\n",
    "    term2a = 5*np.log((q[0]*r[1])/(q[1]*r[0])) - np.log(tau[1]) + 1 -tau[0]\n",
    "    term2 = q[0]*term2a\n",
    "    term3 = l[0]-(r[0]/r[1])*l[1]\n",
    "    gamma_inf1 = np.exp(term1 + term2 + term3)\n",
    "\n",
    "    term1_x2 = np.log(r[1]/r[0])\n",
    "    term2a_x2 = 5*np.log((q[1]*r[0])/(q[0]*r[1])) - np.log(tau[0]) + 1 -tau[1]\n",
    "    term2_x2 = q[1]*term2a_x2\n",
    "    term3_x2 = l[1]-(r[1]/r[0])*l[0]\n",
    "    gamma_inf2 = np.exp(term1_x2 + term2_x2 + term3_x2)\n",
    "    gamma = []\n",
    "    for i in range(len(Xexp)):\n",
    "        if Xexp[i] == 0:\n",
    "            gamma.append(gamma_inf1)\n",
    "        elif Xexp[i] == 1:\n",
    "            gamma.append(gamma_inf2)\n",
    "        else:\n",
    "            value = P[i]*y1[i]/(psat[0]*Xexp[i])\n",
    "            gamma.append(value)\n",
    "    return np.array(gamma) #Gamma1\n",
    "\n",
    "def uniquac_model(unknown_params, xP, args):\n",
    "    \"\"\"\n",
    "    Compute activity coefficients using the UNIQUAC model for a binary mixture.\n",
    "\n",
    "    Parameters:\n",
    "    unknown_params : np.array\n",
    "        A vector containing the unknown interaction energy parameters Δu_ij.\n",
    "    xP : np.array or float\n",
    "        Mole fractions x1 (x2 is inferred).\n",
    "    args : dict\n",
    "        A dictionary containing necessary additional parameters:\n",
    "        - \"r\": np.array, volume parameters for components\n",
    "        - \"q\": np.array, surface area parameters for components\n",
    "        - \"R\": float, gas constant\n",
    "        - \"T\": float, temperature\n",
    "        - \"z\": float, coordination number (default 10)\n",
    "        - \"A\", \"B\", \"C\": Antoine equation parameters for vapor pressure\n",
    "\n",
    "    Returns:\n",
    "    np.array or float\n",
    "        Vapor pressure P.\n",
    "    \"\"\"\n",
    "    # Extract parameters\n",
    "    r = np.array(args[\"r\"])\n",
    "    q = np.array(args[\"q\"])\n",
    "    z = args.get(\"z\", 10)\n",
    "    R = args[\"R\"]\n",
    "    T = args[\"T\"]\n",
    "    A, B, C = np.array(args[\"A\"]), np.array(args[\"B\"]), np.array(args[\"C\"])\n",
    "    \n",
    "    # Precompute constants\n",
    "    l = (z / 2) * (r - q) - (r - 1)\n",
    "    tau = np.exp(-unknown_params / (R * T))\n",
    "    psat = 10 ** (A - B / (C + (T - 273.15)))\n",
    "\n",
    "    # Ensure xP is at least 1D\n",
    "    x1 = np.atleast_2d(xP).reshape(-1,1)\n",
    "    x2 = 1 - x1\n",
    "    x = np.hstack([x1, x2])\n",
    "    # print(x.shape)\n",
    "\n",
    "    # Initialize gamma with ones\n",
    "    gamma = np.ones_like(x)\n",
    "\n",
    "    # Identify valid indices where both x1 and x2 are nonzero\n",
    "    valid_mask = (x1.flatten() > 0) & (x2.flatten() > 0)\n",
    "\n",
    "    if np.any(valid_mask):\n",
    "        # Apply valid_mask correctly to both dimensions\n",
    "        valid_x = x[valid_mask, :]  # Shape (M, 2) where M is number of valid rows\n",
    "\n",
    "        sum_xq = np.dot(valid_x, q)\n",
    "        sum_xr = np.dot(valid_x, r)\n",
    "\n",
    "        theta = (valid_x * q) / sum_xq[:, None]\n",
    "        psi = (valid_x * r) / sum_xr[:, None]\n",
    "\n",
    "        lngC = (\n",
    "            np.log(psi / valid_x) + (z / 2) * q * np.log(theta / psi) + psi[:, ::-1] * (l - r * l[::-1] / r[::-1])\n",
    "        )\n",
    "\n",
    "        lngR = (\n",
    "            -q * np.log(theta + theta[:, ::-1] * tau[::-1]) + theta[:, ::-1] * q * (\n",
    "                tau[::-1] / (theta + theta[:, ::-1] * tau[::-1]) - tau / (theta[:, ::-1] + theta * tau)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        gamma[valid_mask, :] = np.exp(lngC + lngR)\n",
    "        \n",
    "    # Handle infinite dilution cases\n",
    "    if np.any(~valid_mask):\n",
    "        # Compute gamma at infinite dilution for both components\n",
    "        gamma_inf = np.zeros(2)\n",
    "\n",
    "        # term1 = 1- (r[0]/r[1]) +np.log(r[0]/r[1])\n",
    "        # term2 = -5*q[0]*(1-(r[0]*q[1])/(r[1]*q[0]) + np.log((r[0]*q[1])/(r[1]*q[0])))\n",
    "\n",
    "        term1 = np.log(r[0]/r[1])\n",
    "        term2a = 5*np.log((q[0]*r[1])/(q[1]*r[0])) - np.log(tau[1]) + 1 -tau[0]\n",
    "        term2 = q[0]*term2a\n",
    "        term3 = l[0]-(r[0]/r[1])*l[1]\n",
    "        gamma_inf[0] = np.exp(term1 + term2 + term3)\n",
    "\n",
    "        term1_x2 = np.log(r[1]/r[0])\n",
    "        term2a_x2 = 5*np.log((q[1]*r[0])/(q[0]*r[1])) - np.log(tau[0]) + 1 -tau[1]\n",
    "        term2_x2 = q[1]*term2a_x2\n",
    "        term3_x2 = l[1]-(r[1]/r[0])*l[0]\n",
    "        gamma_inf[1] = np.exp(term1_x2 + term2_x2 + term3_x2)\n",
    "\n",
    "        # Assign infinite dilution gamma where needed\n",
    "        if np.any((x2.flatten() > 0)):\n",
    "            gamma[~valid_mask[0], 0] = gamma_inf[0]  # Where x1 = 0\n",
    "            # gamma[~valid_mask[-1], 1] = gamma_inf[1] #Where x2 = 0\n",
    "\n",
    "    P = np.sum(x * gamma * psat, axis=1)\n",
    "    gamma1 = gamma[:, 0]\n",
    "    gamma2 = gamma[:, 1]\n",
    "\n",
    "    return gamma1#P[0] if P.shape == (1,) else P  # Return scalar if input was scalar-like\n",
    "\n",
    "def calc_mm_model(model_coefficients, x, args = None):\n",
    "    \"\"\"\n",
    "    Caclulates the Muller Potential\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        model_coefficients: ndarray, The array containing the values of Muller constants\n",
    "        x: ndarray, Values of X\n",
    "        noise: ndarray, Any noise associated with the model calculation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        y_mul: float, value of Muller potential\n",
    "    \"\"\"    \n",
    "    theta = model_coefficients\n",
    "    # y_mul = (theta[0] * x**3 - theta[1] * x**2 + 2*x - 1)**2 + (theta[0] - theta[1])**2 + (x**2 - 1)**2 #MC Example\n",
    "    # y_mul = theta[0]*(1 - theta[1]*np.exp(-theta[2]*x)) #Choline Chloride\n",
    "    # y_mul = -(theta[3]+theta[4])*np.exp(-theta[0]*x) + theta[3]*np.exp(-theta[1]*x) + theta[4]*np.exp(-theta[2]*x) #Ethyl Acrylate\n",
    "    # y_mul = (theta[0]*(x-theta[1])*(1-np.exp(theta[2]*(x-theta[3]))))**2 #Ratkowsky Model\n",
    "    # y_mul = theta[0]*(1-((x-theta[1])**2/((x-theta[1])**2+x*(theta[3]+theta[2]-x)-(theta[2]*theta[3])))) #Cardinal Temperature Model\n",
    "    # y_mul = theta[0]+1/(x - theta[1]) #Rod and Hancil Nonlinear Fit\n",
    "    # y_mul = theta[0]*((x**2 + theta[1]*x)/(x**2+theta[2]*x + theta[3])) #Kowalik Problem\n",
    "    # y_mul = theta[0] + (0.49-theta[0])*(np.exp(-theta[1]*(x-8))) #Model C (Bates and Watts)\n",
    "    # y_mul = theta[0]*np.exp(-np.exp(theta[1]-theta[2]*x)) #Model G (Bates and Watts)\n",
    "    # y_mul = theta[0]*(1-theta[1]*np.exp(-theta[2]*x)) #Model I (Bates and Watts)\n",
    "    # y_mul = (theta[1]*theta[2]+theta[0]*x**theta[3])/(theta[2]+x**theta[3]) #Model O (Bates and Watts)\n",
    "    # y_mul = theta[0]*np.exp(-theta[3]*x) + theta[1]*np.exp(-theta[4]*x) + theta[2]*np.exp(-theta[5]*x) #Pharmacokinetic model\n",
    "    # y_mul = np.exp(theta[0]-theta[3]*x) + np.exp(theta[1]-theta[4]*x) - 2*np.exp(theta[2]-theta[5]*x) #Pharmacokinetic model\n",
    "    y_mul = uniquac_model(theta, x, args)\n",
    "    return y_mul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.63480222 1.48233672 1.45379261 1.40418363 1.39338723 1.33769762\n",
      " 1.09488163 1.02432958 0.99969265 0.98903964 0.96833574 0.9762384 ]\n"
     ]
    }
   ],
   "source": [
    "#Choline Chloride (ILL POSED)\n",
    "# param_name_str = \"t1t2t3\"\n",
    "# indeces_to_consider = [0,1,2]\n",
    "# bounds_x = np.array([[3], [8]])\n",
    "# bounds_theta_l = [35.0,0.4, 0.01]\n",
    "# bounds_theta_u = [45.0, 1.0, 0.5]\n",
    "# theta_ref = np.array([39.09, 0.828, 0.159]) \n",
    "# theta_names = ['theta_1', 'theta_2', 'theta_3']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#Ethyl Acrylate (ILL POSED + Only 1 Min)\n",
    "# param_name_str = \"t1t2t3t4t5\"\n",
    "# indeces_to_consider = [0,1,2,3,4]\n",
    "# bounds_x = np.array([[0], [4]])\n",
    "# bounds_theta_l = [1,0.1,0.01, 0.1, 0.001]\n",
    "# bounds_theta_u = [10, 1, 0.1, 1, 0.01]\n",
    "# theta_ref = np.array([3.025, 0.481, 0.0258, 0.310, 0.0011]) \n",
    "# theta_names = ['theta_1', 'theta_2', 'theta_3', 'theta_4', 'theta_5']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#MC Example (Well Posed, 2 min)\n",
    "# param_name_str = \"t1t2\"\n",
    "# indeces_to_consider = [0,1]\n",
    "# bounds_x = np.array([[-2], [1.5]])\n",
    "# bounds_theta_l = [-2,-2]\n",
    "# bounds_theta_u = [2,2]\n",
    "# theta_ref = np.array([-1.5, 0.5 ]) \n",
    "# theta_names = ['theta_1', 'theta_2']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#The Ratkowsky Model (Ill posed, 2 min) (see Set-membership nonlinear regression approach to parameter estimation)\n",
    "# D. Ratkowsky, R. Lowry, T. McMeekin, A. Stokes, R. Chandler, A model for\n",
    "#bacterial culture growth rate throughout the entire biokinetic temperature\n",
    "#range, J. Bacteriol. 154 (1983) 1222–1226.)\n",
    "# param_name_str = \"t1t2t3t4\"\n",
    "# indeces_to_consider = [0,1,2,3]\n",
    "# bounds_x = np.array([[294], [320]])\n",
    "# bounds_theta_l = [0,245,0,310]\n",
    "# bounds_theta_u = [0.1,290,1,325]\n",
    "# theta_ref = np.array([0.0325, 273.54, 0.336, 321.37]) \n",
    "# theta_names = [\"b\", \"Tmin\", \"c\", \"Tmax\"]\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#cardinal temperature model (Well posed, 2 local min)\n",
    "#] J. Lobry, L. Rosso, J. Flandrois, A fortran subroutine for the determination of\n",
    "#parameter confidence limits in non-linear models, Binary 3 (1991) 86–93.\n",
    "# param_name_str = \"t1t2t3t4\"\n",
    "# indeces_to_consider = [0,1,2,3]\n",
    "# bounds_x = np.array([[294], [320]])\n",
    "# bounds_theta_l = [1.0,308,280,319]\n",
    "# bounds_theta_u = [2.0,318,296,325]\n",
    "# theta_ref = np.array([1.396, 313.25, 289.40, 320.23]) \n",
    "# theta_names = [\"mu_opt\", \"Topt\", \"Tmin\", \"Tmax\"]\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#Rod and Hancil Nonlinear Fit (Well posed, 2 min)\n",
    "#Rod, V.; Hancil, V. Iterative Estimation of Model Parameters when Measurements of \n",
    "# #All Variables are Subject to Error. Comput. Chem. Eng. 1980, 4, 33.\n",
    "# param_name_str = \"t1t2\"\n",
    "# indeces_to_consider = [0,1]\n",
    "# bounds_x = np.array([[0], [5]])\n",
    "# bounds_theta_l = [1,1]\n",
    "# bounds_theta_u = [10,10]\n",
    "# theta_ref = np.array([2.00,6.00]) \n",
    "# theta_names = ['theta_1', 'theta_2']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#Kowalik Problem (see Global Optimization in Parameter Estimation of Nonlinear\n",
    "#Algebraic Models via the Error-in-Variables Approach) (Ill posed, 2 local min)\n",
    "#Moore, R., Hansen, E., & Leclerc, A. (1992). Rigorous Methods for Global Optimization. \n",
    "# #In C. A. Floudas & P. M. Pardalos (Eds.), Recent Advances in Global Optimization (pp. 321–342). \n",
    "# #Princeton University Press. http://www.jstor.org/stable/j.ctt7ztwft.19\n",
    "# param_name_str = \"t1t2t3t4\"\n",
    "# indeces_to_consider = [0,1,2,3]\n",
    "# bounds_x = np.array([[1/4], [2.50]])\n",
    "# bounds_theta_l = [0,-0.2892, -0.2892,-0.2892]\n",
    "# bounds_theta_u = [0.2892,0.2892, 0.35,0.2892]\n",
    "# theta_ref = np.array([0.19283, 0.19088, 0.12314, 0.13578]) \n",
    "# theta_names = ['theta_1', 'theta_2', 'theta_3', 'theta_4']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#Model C (Bates and Watts) (Well posed, 1 min)\n",
    "# param_name_str = \"t1t2\"\n",
    "# indeces_to_consider = [0,1]\n",
    "# bounds_x = np.array([[8], [42]])\n",
    "# bounds_theta_l = [0.380,0.075]\n",
    "# bounds_theta_u = [0.400, 0.128]\n",
    "# theta_ref = np.array([0.3901,0.1016]) \n",
    "# theta_names = ['theta_1', 'theta_2']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#Gompertz Model (Bates and Watts Model H) (Ill posed, 1 min)\n",
    "# param_name_str = \"t1t2t3\"\n",
    "# indeces_to_consider = [0,1,2]\n",
    "# bounds_x = np.array([[118], [1582]])\n",
    "# bounds_theta_l = [130, 1, 0.001]\n",
    "# bounds_theta_u = [200, 5, 0.003]\n",
    "# theta_ref = np.array([172, 2.18,0.0016]) \n",
    "# theta_names = ['theta_1', 'theta_2', 'theta_3']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#Bates and Watts Model I (Ill Posed 1 min)\n",
    "# param_name_str = \"t1t2t3\"\n",
    "# indeces_to_consider = [0,1,2]\n",
    "# bounds_x = np.array([[118], [1582]])\n",
    "# bounds_theta_l = [450, 0.1, 10**-4]\n",
    "# bounds_theta_u = [500, 0.5, 5*10**-4]\n",
    "# theta_ref = np.array([478, 0.357, 2.64*10**-4]) \n",
    "# theta_names = ['theta_1', 'theta_2', 'theta_3']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#Bates and Watts Model O (see 10.1063/1.4940872) (Well posed, 1 local min)\n",
    "# param_name_str = \"t1t2t3t4\"\n",
    "# indeces_to_consider = [0,1,2,3]\n",
    "# bounds_x = np.array([[0], [10]])\n",
    "# bounds_theta_l = [0.5, 1,1,1]\n",
    "# bounds_theta_u = [2, 15, 10,5]\n",
    "# theta_ref = np.array([1, 12.371, 6.318,3.46]) \n",
    "# theta_names = ['theta_1', 'theta_2', 'theta_3', 'theta_4']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#Pharmacokinetic model\n",
    "# William R. Esposito, Christodoulos A. Floudas, Parameter estimation in nonlinear algebraic models via global optimization, \n",
    "# Computers & Chemical Engineering, Volume 22, Supplement 1, 1998, Pages S213-S220, ISSN 0098-1354, https://doi.org/10.1016/S0098-1354(98)00217-8. (Well posed, 2 local min)\n",
    "# param_name_str = \"t1t2t3t4t5t6\"\n",
    "# indeces_to_consider = [0,1,2,3,4,5]\n",
    "# bounds_x = np.array([[7.5], [120]])\n",
    "# bounds_theta_l = [-2.302, 0,0,0,0,0 ]\n",
    "# bounds_theta_u = [0, 2.302, 2.302, 0.5,0.5,0.5]\n",
    "# theta_ref = np.array([-1.0345, 0.6966, 1.5200, 0.01491, 0.1102, 0.2847]) \n",
    "# # bounds_theta_l = [-10,-10,-10,0,0,0 ]\n",
    "# # bounds_theta_u = [10,10,10, 5,5,5]\n",
    "# # theta_ref = np.array([0.3554,2.007,-4.572, 0.01491, 0.1102, 0.2847]) \n",
    "# theta_names = ['theta_1', 'theta_2', 'theta_3', 'theta_4', 'theta_5', 'theta_6']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "#VLE DMSO + EG\n",
    "# param_name_str = \"t1t2\"\n",
    "# indeces_to_consider = [0,1]\n",
    "# bounds_x = np.array([[0], [1]])\n",
    "# bounds_theta_l = [-2e3,-2e3 ]\n",
    "# bounds_theta_u = [2e3,2e3]\n",
    "# theta_ref = np.array([757.6653, -759.0704]) \n",
    "# theta_names = ['theta_1', 'theta_2']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "# Xexp = np.array([0,.149,.2100,.283,.4010,.5050,.5970,.7060,.7910,.899,1])\n",
    "# Yexp_org = np.array([15.80, 16.30,16.80,17.70,17.80,19.60,22.40,27.10,29.80,34.40,38.80])\n",
    "# argsvals = {\"r\" :[2.8266, 2.4088], #DMSO, EG\n",
    "#         \"q\" :[2.4720, 2.2480],\n",
    "#         \"T\" : 373.15, #K\n",
    "#         \"R\" : 1.98721 , #cal/molK\n",
    "#         \"A\": [6.88076,8.09083],\n",
    "#         \"B\": [1541.520,2088.936],\n",
    "#         \"C\": [191.797,203.454]\n",
    "#         } \n",
    "\n",
    "#VLE Methanol + Water (https://www.degruyter.com/document/doi/10.1515/zpch-1927-13002/html / DECHEMA)\n",
    "param_name_str = \"t1t2\"\n",
    "indeces_to_consider = [0,1]\n",
    "bounds_x = np.array([[0], [1]])\n",
    "bounds_theta_l = [-1e3,-1e3 ]\n",
    "bounds_theta_u = [1e3,1e3]\n",
    "theta_ref = np.array([-99.5814, 99.4288]) \n",
    "theta_names = ['theta_1', 'theta_2']\n",
    "theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "P = np.array([119.50, 157.00, 169.70, 196.00, 217.70, 236.60, \n",
    "                   283.00, 306.40, 324.10, 348.40, 373.50, 391.10])\n",
    "y1 = np.array([0.2741, 0.4741, 0.5220, 0.6294, 0.7106, 0.7580, \n",
    "               0.8203, 0.8654, 0.9007, 0.9406, 0.9627, 0.9736])\n",
    "Xexp = np.array([0.0486, 0.1218, 0.1478, 0.2131, 0.2693, 0.3252, \n",
    "               0.5143, 0.6279, 0.7083, 0.8037, 0.9007, 0.9461])\n",
    "argsvals = {\"r\" :[1.4311,0.92], #MeOH, H2O\n",
    "        \"q\" :[1.432,1.4],\n",
    "        \"T\" : 49.76+273.15, #K\n",
    "        \"R\" : 1.98721 , #cal/molK\n",
    "        \"A\": [8.08097,8.07131],\n",
    "        \"B\": [1582.271,1730.63],\n",
    "        \"C\": [239.726,233.426]\n",
    "        } \n",
    "Yexp_org = calc_gamma_exp(Xexp, P, y1, theta_ref, argsvals)\n",
    "\n",
    "\n",
    "#VLE Methanol + Water (DECHEMA 50C) (Only 1 Minimum)\n",
    "# param_name_str = \"t1t2\"\n",
    "# indeces_to_consider = [0,1]\n",
    "# bounds_x = np.array([[0], [1]])\n",
    "# bounds_theta_l = [-1e3,-1e3 ]\n",
    "# bounds_theta_u = [1e3,1e3]\n",
    "# theta_ref = np.array([349.2925, -246.6378]) \n",
    "# theta_names = ['theta_1', 'theta_2']\n",
    "# theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "# theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "# P = np.array([92.50,143.00,196.50, 244.50,286.00,333.00,373.00,406.00])\n",
    "# y1 = np.array([0.0, 0.3783,0.5883,0.7076, 0.7807,0.8655,0.9349,1.000])\n",
    "# Xexp = np.array([0.0,0.0873,0.1900,0.3417,0.4943,0.6919,0.8492,1.000])\n",
    "# argsvals = {\"r\" :[1.4311,0.92], #MeOH, H2O\n",
    "#         \"q\" :[1.432,1.4],\n",
    "#         \"T\" : 50+273.15, #K\n",
    "#         \"R\" : 1.98721 , #cal/molK\n",
    "#         \"A\": [8.08097,8.07131],\n",
    "#         \"B\": [1582.271,1730.63],\n",
    "#         \"C\": [239.726,233.426]\n",
    "#         } \n",
    "# Yexp_org = calc_gamma_exp(Xexp, P, y1, theta_ref, argsvals)\n",
    "print(Yexp_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = len(theta_ref)\n",
    "np.random.seed(1)\n",
    "# Evaluate model and add noise based on assumed theta values\n",
    "# This generates experimental data points\n",
    "num_points = 10 #len(Xexp)\n",
    "# Xexp = grid_sampling(num_points, bounds_x)\n",
    "# # Xexp = np.array([7.5,11.5,15.5,22,45,75,90,120])\n",
    "# Yexp_org = np.array([ calc_mm_model(theta_ref, Xexp[i], argsvals)  for i in range(len(Xexp)) ]).flatten()\n",
    "std = 0#abs(np.mean(Yexp_org))*0.05\n",
    "noise = np.random.normal(size=len(Yexp_org), loc = 0, scale = std)\n",
    "Yexp = Yexp_org + noise\n",
    "\n",
    "# Evaluate model based on the assumed experimental values\n",
    "X = np.linspace(np.min(Xexp),np.max(Xexp),100).reshape(-1,1)\n",
    "Y = calc_mm_model(theta_ref, X.reshape(-1,1),argsvals)\n",
    "# Compare the experiments to the true model\n",
    "plt.plot(X,Y,'b-',linewidth=2,label=r\"$y$\")\n",
    "plt.plot(Xexp,Yexp,'r.',markersize=10,label=r\"$y$\")\n",
    "plt.title(\"Plotting True Model and Synthetic Data\")\n",
    "plt.xlabel(r\"$x$\",fontsize=14)\n",
    "plt.ylabel(r'$y$',fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##New Cell\n",
    "\n",
    "## define function that includes nonlinear model\n",
    "def model(theta_guess, theta_ref, x, indeces_to_consider, args=None):\n",
    "    '''\n",
    "        \"\"\"\n",
    "    Creates Muller potential values given a guess for \"a\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        a_guess: ndarray, guess value for a\n",
    "        Constants: ndarray, The array containing the true values of Muller constants\n",
    "        x: ndarray, Independent variable data (exp or pred)\n",
    "    Returns\n",
    "    -------\n",
    "        y_model: ndarray, The simulated Muller potential given the guess\n",
    "    '''\n",
    "    #Define an array to store y values in\n",
    "    y_data = []\n",
    "    #Loop over all theta values\n",
    "    for i in range(len(x)):\n",
    "        #Create model coefficient from true space substituting in the values of param_space at the correct indeces\n",
    "        model_coefficients = theta_ref.copy()\n",
    "        #Replace coefficients a specified indeces with their theta_val counterparts\n",
    "        model_coefficients[indeces_to_consider] = theta_guess              \n",
    "        #Create y data coefficients\n",
    "        y = calc_mm_model(model_coefficients, x[i], args)\n",
    "        y_data.append(y)\n",
    "        # print(model_coefficients, x[i], y)\n",
    "\n",
    "    #Convert list to array and flatten array\n",
    "    y_model = np.array(y_data).flatten()\n",
    "    \n",
    "    return y_model\n",
    "\n",
    "print(model(theta_true, theta_true, Xexp, indeces_to_consider,argsvals))\n",
    "\n",
    "##New Cell\n",
    "\n",
    "# Create a function to optimize, in this case, least squares fitting\n",
    "def regression_func(theta_guess, theta_ref, x, indeces_to_consider, y, args=None):\n",
    "    '''\n",
    "    Function to define regression function for least-squares fitting\n",
    "    Arguments:\n",
    "        a_guess: ndarray, guess value for a\n",
    "        Constants: ndarray, The array containing the true values of Muller constants\n",
    "        x: ndarray, experimental X data (Inependent Variable)\n",
    "        y: ndarray, experimental Y data (Dependent Variable)\n",
    "    Returns:\n",
    "        e: residual vector\n",
    "    '''\n",
    "    error = y - model(theta_guess, theta_ref, x, indeces_to_consider, args) #NOTE: Least squares will calculate sse based off this to minimize\n",
    "    \n",
    "    return error\n",
    "\n",
    "print(regression_func(theta_true, theta_true, Xexp, indeces_to_consider, Yexp, argsvals))\n",
    "\n",
    "#Create a function to define the SSE for any Theta vector on a heat map.\n",
    "def sse_func(theta_guesses, theta_ref, indeces_to_consider, Xexp, Yexp, args):\n",
    "    '''\n",
    "    Function to define define sum of squared error function for heat map\n",
    "    Arguments:\n",
    "        xx: An N X D array of all a_1 values\n",
    "        yy: An D X N array of all a_2 values\n",
    "        x: independent variable vector (predicted x values including noise)\n",
    "        y: dependent variable vector (predicted y values on Heat Map)\n",
    "    Returns:\n",
    "        sse: N x N sum of squared error matrix of all generated combination of xx and yy\n",
    "    '''\n",
    "    #Initialize sse grid\n",
    "    sse = np.zeros(len(theta_guesses))\n",
    "    \n",
    "    #For each guess\n",
    "    for i in range(len(theta_guesses)):\n",
    "        #Evaluate the model\n",
    "        y_sim = model(theta_guesses[i], theta_ref, Xexp, indeces_to_consider, args)\n",
    "        #Calculate SSE\n",
    "        sse[i] = np.sum((y_sim - Yexp)**2)\n",
    "     \n",
    "    sse = sse.reshape(int(np.sqrt(len(theta_guesses))), -1).T\n",
    "    \n",
    "    return sse\n",
    "\n",
    "print(sse_func([theta_true], theta_true, indeces_to_consider, Xexp, Yexp, argsvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Cell\n",
    "# Create synthetic data assuming the following values for theta\n",
    "Theta_Guess = np.array([1,1])\n",
    "\n",
    "# print(calc_cs1_polynomial(Theta_Guess,Xexp))\n",
    "## specify initial guess\n",
    "sse_list = []\n",
    "opt_list = []\n",
    "theta_list = []\n",
    "\n",
    "## specify bounds\n",
    "lower = np.array([bounds_theta_l[i] for i in indeces_to_consider] )\n",
    "upper = np.array([bounds_theta_u[i] for i in indeces_to_consider] )\n",
    "bounds = (lower, upper)\n",
    "\n",
    "for i in range(1000):\n",
    "    theta_guess = np.random.uniform(low=lower, high=upper, size=len(lower) )\n",
    "    # print(theta_guess)\n",
    "    Solution = optimize.least_squares(regression_func, theta_guess, bounds=bounds, method='trf',\n",
    "                                        args=(theta_true, Xexp.reshape(-1,1), indeces_to_consider, Yexp, argsvals),verbose=0)\n",
    "\n",
    "    theta = Solution.x\n",
    "    sse_list.append(Solution.cost)\n",
    "    theta_list.append(theta)\n",
    "    opt_list.append(Solution.optimality)\n",
    "    # print(\"theta = \",theta)\n",
    "\n",
    "all_sets = pd.DataFrame({'Theta': theta_list, 'SSE': sse_list, 'Optimality': opt_list})\n",
    "\n",
    "# print(all_sets)\n",
    "#Organize all_sets by SSE, lowest to highest\n",
    "all_sets = all_sets.sort_values(by=\"SSE\", ascending=True)\n",
    "\n",
    "# # Drop duplicate minima\n",
    "all_sets = all_sets.drop_duplicates(\n",
    "    subset=\"SSE\", keep=\"first\")\n",
    "# # Drop minima with optimality > 1e-4\n",
    "all_sets = all_sets[all_sets[\"Optimality\"] < 1e-4]\n",
    "\n",
    "print(len(all_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale values between 0 and 1 with minmax scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit([bounds_theta_l, bounds_theta_u])\n",
    "all_param_sets = np.array(list(map(np.array, all_sets[\"Theta\"].values)))\n",
    "all_param_sets_scaled = scaler.transform(all_param_sets)\n",
    "#Calculate the scaled euclidean distance between each pair of scaled points\n",
    "dist = pdist(all_param_sets_scaled)/np.sqrt(all_param_sets.shape[1])\n",
    "#Convert the condensed distance matrix to square form\n",
    "dist_sq = squareform(dist)\n",
    "\n",
    "#Initialize a boolean array to keep track of unique sets\n",
    "unique_mask = np.ones(all_param_sets.shape[0], dtype=bool)\n",
    "duplicate_counts = np.zeros(all_param_sets.shape[0], dtype=int)\n",
    "\n",
    "# Iterate over the upper triangle of the distance matrix\n",
    "for i in range(all_param_sets.shape[0]):\n",
    "    # If the current set is already marked as non-unique, skip it\n",
    "    if not unique_mask[i]:\n",
    "        continue\n",
    "    # Mark sets within the threshold distance as non-unique\n",
    "    within_threshold = dist_sq[i] <= 0.01\n",
    "    duplicate_counts[i] = np.sum(within_threshold)\n",
    "    unique_mask[within_threshold] = False\n",
    "    unique_mask[i] = True  # Keep the current set\n",
    "\n",
    "# Filter out the unique sets from the pandas df\n",
    "local_min_sets = all_sets[unique_mask]\n",
    "local_min_counts = duplicate_counts[unique_mask]\n",
    "\n",
    "print(\"Num local min count\", local_min_counts)\n",
    "\n",
    "print(\"Num local min\", len(local_min_sets))\n",
    "print(local_min_sets)\n",
    "\n",
    "# print(all_sets)print(\"Best Theta = \", nlr_theta)\n",
    "try:\n",
    "    nlr_theta = local_min_sets.iloc[1]['Theta']\n",
    "except:\n",
    "    nlr_theta = local_min_sets.iloc[0]['Theta']\n",
    "nlr_thetas = np.vstack(local_min_sets['Theta'])\n",
    "\n",
    "print(\"Best Theta = \", nlr_theta)\n",
    "print(\"theta_ref\", theta_true)\n",
    "Y_nlr_exp = model(nlr_theta, theta_true, Xexp, indeces_to_consider, argsvals)\n",
    "error = (Yexp - Y_nlr_exp)\n",
    "print(\"SSE = \", np.sum(error**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heat map data\n",
    "#Create list of heat map theta data\n",
    "heat_map_data_dict = {}\n",
    "\n",
    "#Create a linspace for the number of dimensions and define number of points\n",
    "dim_theta = num_params\n",
    "dim_list = np.linspace(0, dim_theta-1, dim_theta)\n",
    "\n",
    "#Create a list of all combinations (without repeats e.g no (1,1), (2,2)) of dimensions of theta\n",
    "mesh_combos = np.array(list(combinations(dim_list, 2)), dtype = int)\n",
    "n_points = 20\n",
    "\n",
    "#Meshgrid set always defined by n_points**2\n",
    "theta_set = np.tile(np.array(theta_ref), (n_points**2, 1))\n",
    "\n",
    "#Set x_vals\n",
    "norm_x_vals = Xexp.reshape(-1,1)\n",
    "\n",
    "#Loop over all possible theta combinations of 2\n",
    "for i in range(len(mesh_combos)):\n",
    "    #Create a copy of the true values to change the mehsgrid valus on\n",
    "    theta_set_copy = np.copy(theta_set)\n",
    "    #Set the indeces of theta_set for evaluation as each row of mesh_combos\n",
    "    idcs = mesh_combos[i]\n",
    "    #define name of parameter set as tuple (\"param_1,param_2\")\n",
    "    data_set_name = (theta_true_names[idcs[0]], theta_true_names[idcs[1]])\n",
    "\n",
    "    #Create a meshgrid of values of the 2 selected values of theta and reshape to the correct shape\n",
    "    #Assume that theta1 and theta2 have equal number of points on the meshgrid\n",
    "    theta1 = np.linspace(lower[idcs[0]], upper[idcs[0]], n_points)\n",
    "    theta2 = np.linspace(lower[idcs[1]], upper[idcs[1]], n_points)\n",
    "    theta12_mesh = np.array(np.meshgrid(theta1, theta2))\n",
    "    theta12_vals = np.array(theta12_mesh).T.reshape(-1,2)\n",
    "\n",
    "    #Set initial values for evaluation (true values) to meshgrid values\n",
    "    theta_set_copy[:,idcs] = theta12_vals\n",
    "    \n",
    "    #Append data set to dictionary with name\n",
    "    heat_map_data_dict[data_set_name] = theta_set_copy\n",
    "    \n",
    "hm_data_keys = list(heat_map_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlr_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Cell\n",
    "log_data = False\n",
    "# save_figure = True\n",
    "save_figure = False\n",
    "\n",
    "#Get Number of pairs\n",
    "combos = list(combinations(dim_list, 2))\n",
    "pairs = len((list(combinations(dim_list, 2))))\n",
    "\n",
    "#For each pair\n",
    "for pair in range(pairs):\n",
    "    #Make a meshgrid for each parameter\n",
    "    idcs_to_plot = [int(combos[pair][i]) for i in range(len(combos[pair]))]\n",
    "    theta_data = heat_map_data_dict[hm_data_keys[pair]].reshape(n_points, n_points, -1).T\n",
    "    theta_mesh = np.take(theta_data, list(combos[pair]), axis=0)\n",
    "    \n",
    "    sse_sim = sse_func(heat_map_data_dict[hm_data_keys[pair]], theta_ref, indeces_to_consider, Xexp.reshape(-1,1), Yexp, argsvals)\n",
    "    param_names = theta_true_names[idcs_to_plot]\n",
    "    \n",
    "    title = \"Heat Map Pair \" + \"-\".join(map(str, param_names))\n",
    "    title = None\n",
    "\n",
    "    z = np.array([sse_sim])\n",
    "    # print(np.amin(z), np.amax(z))\n",
    "    if log_data == True:\n",
    "        z_titles = [\"ln(\"+ r\"$\\mathbf{e(\\theta)_{sim}}$\" + \")\"]\n",
    "        z = np.log(z)\n",
    "    else:\n",
    "        z_titles = [r\"$\\mathbf{e(\\theta)_{sim}}$\" + \")\"]\n",
    "    \n",
    "#     z_save_names = [\"sse_sim\", \"sse_nlr\"]\n",
    "#     path_end = '-'.join(z_save_names) \n",
    "    levels = [100]\n",
    "\n",
    "    param_info_dict = {\"true\":theta_true, \"min_sse\":nlr_thetas, \"names\":param_names, \"idcs\":idcs_to_plot}\n",
    "    plotters.plot_nlr_heat_maps(theta_mesh, z, z_titles, levels, param_info_dict, log_data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot and compare predictions and experiments\n",
    "print(nlr_theta)\n",
    "X_pred = np.linspace(bounds_x[0], bounds_x[1]).reshape(-1,1)\n",
    "Y_pred = model(nlr_theta, theta_true, X_pred, indeces_to_consider, argsvals).flatten()\n",
    "print(Y_pred)\n",
    "plt.figure(figsize = (9,6))\n",
    "plt.plot(Xexp,Yexp,'.g',markersize=20,label=r'$y$')\n",
    "plt.plot(X,Y,'r-',linewidth=3,label=r'$f(\\mathbf{\\theta_{true}})$')\n",
    "plt.plot(X_pred,Y_pred,'--b',linewidth=4,label=r'$f(\\mathbf{\\theta})$')\n",
    "# plt.title(\"Predictions with $\\\\theta = [0.994,-1.00]$ vs Synthetic Data\")\n",
    "# plt.title(\"Predictions with $\\\\theta = [0.802,-0.757]$ vs Synthetic Data\")\n",
    "plt.legend(loc = \"best\", fontsize=30) #(bbox_to_anchor=(1.04, 1), borderaxespad=0\n",
    "plt.xlabel(r'$x$',fontsize=30,fontweight='bold')\n",
    "plt.ylabel(r'$y$',fontsize=30,fontweight='bold')\n",
    "\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.minorticks_on() # turn on minor ticks\n",
    "plt.tick_params(which=\"minor\",direction=\"in\",top=True, right=True)\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.savefig(\"Figures/sim_true_comp_poster.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##New Cell\n",
    "\n",
    "#Plot error\n",
    "print(\"SSE = \", np.sum(error**2))\n",
    "plt.plot(Y_nlr_exp,error,\"b.\",markersize=20, label = \"Error\")\n",
    "plt.title(\"Residuals\")\n",
    "plt.xlabel('Predicted Y')\n",
    "plt.ylabel('Residuals vs. Predicted Value')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(np.log(7.73251354))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigre = np.maximum(std**2, 0.01)\n",
    "MSE = (error.T @ error)/(len(error) - 2)\n",
    "Hess = Solution.jac.T @ Solution.jac\n",
    "Covar = sigre * np.linalg.inv(Hess)\n",
    "FIM = (1/sigre)*Hess\n",
    "eigvals, eigvecs = np.linalg.eig(FIM)\n",
    "k = np.max(eigvals)/np.min(eigvals)\n",
    "print(\"MSE = \", MSE)\n",
    "print(\"Experimental Variance = \", sigre)\n",
    "print(\"Parameter Prediction Standard Deviation: \\n\", np.sqrt(np.diag(Covar)))\n",
    "print(\"Covariance matrix:\\n\",Covar)\n",
    "print(\"Det(FIM) = \", np.linalg.det(FIM))\n",
    "print(\"Eigen Values (FIM):\\n\", eigvals)\n",
    "print(\"Eigen Vectors (FIM)\\n\", eigvecs)\n",
    "print(\"Condition Number (FIM): \", k)\n",
    "print(\"Degree of precision loss (log10(k) of FIM): \", math.log10(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Toy_Problem_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
