#Pseudo code for all 2-Input GP


Step 1) Generate Experimental and Training data (Completed)

NOTE: 
Number of dimensions of coordinate system: m = 1, 
Number of Experimental data points: n = 5, 
Number of input variables: q = 2
Number of training points generated by LHS: t=t

--Generate Experimental data and training input data--
# Set  x values (m x n), noise_mean (float), and noise_stdev (float)
# noise is drawn from a normal distribution, N(noise_mean, noise_stdev)
# Create experimental data using y = x -x^2 +x^3 + noise (1 x n)
# Generate training data inputs through LHS for Theta1 and Theta2 (q x t)

--Generate training data outputs--
-- 2-Input GP
# Generate training data outputs with 
    ysim = Theta1*x + Theta2*x^2 +x^3 (1 x t)
    Yexp from CSV
    Error = sum((ysim-yexp)**2)


Step 2) Read Experimental and Training Data from the CSV (Completed)

# Read entire file with Pandas and convert to an array
# Create arrays for training/testing inputs and outputs based on data in stored files
# First column is an index, last column is output, all interior columns are inputs


Step 3) Train GP (Completed)

# Define likelihood and GP model clas
# Train GP based on input training data z, and output training data y
# Switch to evaluation mode


Step 4) Generate meshgrid for Theta

#Generate arrays for Theta1 and Theta2
Theta1 = np.linspace(-2,2,# points) (1 x p1)
Theta2 = np.linspace(-2,2,# points) (1 x p2)

#Create meshgrid for theta
theta_mesh = meshgrid (2 p1 x p2 arrays)

#Separate meshgrid into theta1 and theta2 arrays
theta1_mesh = theta_mesh[0] (p1 x p2)
theta2_mesh = theta_mesh[1] (p1 x p2)


Step 5) Calculate Best Error and EI

#Define f(x+)


##WHAT IS f(X+)? Best training data sse sample


#Will compare the rigorous solution and approximation later (multidimensional integral over each experiment using a sparse grid)

#Create an array in which to store expected improvement values
EI = np.zeros((len(p1),len(p2))) (p1 x p2) #Important for step 6
sse = np.zeros((len(p1),len(p2))) #For plotting purposes
# Loop over theta 1
for i in range(len(p1)):
    #Loop over theta2
    for j in range(len(p2)):
    #Evaluate GP at a point p = [Theta1,Theta2,Xexp]
    p = np.array(theta1_mesh[i,j],theta2_mesh[i,j],Xexp[k]) (1 x q)
    GP_mean, GP_var = calc_GP_outputs(model, likelihood, p) (float)
    #Caclulate Best Error
    #Note: Negative sign is here because max(f(x)) = -min(-f(x))
    best_error = max(-train_sse)
    EI[i,j] = calc_ei_basic(best_error, -GP_mean, GP_Var) #GP Mean is negative because max(f(x)) = -min(-f(x))


Step 6) Find GP Predicted Values of Theta
## Find point with lowest Error

#Caclulate argmin of Error_Point
argmin = np.array(np.where(sse == np.amin(sse))) (1 x q)

#Calculate correcsponding theta and x values and set Theta_Opt
##DOES THIS STEP LOOK OK? I'M NOT REALLY SURE IF THIS IS RIGHT
Theta1_Opt = float(theta1_mesh[argmin[0],argmin[1]]) (float)
Theta2_Opt = float(theta2_mesh[argmin[0],argmin[1]]) (float)
Theta_GP_Opt = np.array([Theta1_Opt,Theta2_Opt],dtype=object) (1 x q)


Step 7) Complete BO loops

BO_iter = # of iterations
#Loop pver BO iterations
    # If training data are numpy arrays, convert to tensors
    if torch.is_tensor(train_T) != True:
        train_p = torch.from_numpy(train_T)
    if torch.is_tensor(train_sse) != True:
        train_sse = torch.from_numpy(train_sse)
    
    ## Repeat steps 3-6

    ##Find point with best EI
    #Calculate argmax of EI
    argmax = np.array(np.where(EI == np.amax(EI))) (1 x q)

    #Calculate correcsponding theta and x values and set p_Best
    Theta1_Best = float(theta1_mesh[argmax[0],argmax[1]]) (float)
    Theta2_Best = float(theta2_mesh[argmax[0],argmax[1]]) (float)
    Theta_Best = np.array([Theta1_Best,Theta2_Best],dtype=object)
     
    ##Plot graphs
    
    ##Append best values to training data 
    #Convert training data to numpy arrays to allow concatenation to work
    train_T = train_T.numpy()
    train_sse = train_sse.numpy()
    #NEED TO CALCULATE VALUE OF SSE AT Best value. HOW?
    #Call the expensive function
    
    #Outdated, will need to change
    sse_Best = 0
    for i in range(len(train_p)):
        if np.array_equiv(train_T[i], Theta_Best) ==True:
            sse_Best = train_sse[i]
  
    #Add Theta_Best to train_p and y_best to train_y
    train_sse = np.concatenate((train_sse, sse_Best),axis=0)
    train_p = np.concatenate((train_T, Theta_Best), axis=0)

            
QUESTIONS:
1) What is f(x+)?

Answered Questions:
In the pseudo code you drew on the whiteboard, best error is called as best_error[k] in the EI equation. (Best error is 1xn)
1) What is f_bar and what is f(x) and are they both (1xn)? (f_bar = Yexp, f(x) approx. GP_mean)
2) When you add in a sample from the meshgrid do you retrain the GP for each set and apply it? (No)
3) Should there be a sum in the calculation of best error loop? (No we assume they act independently and summing them together in EI)
            
            
            
            
            
            
            
            
            
