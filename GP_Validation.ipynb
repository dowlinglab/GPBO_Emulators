{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a807dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "\n",
    "from bo_methods_lib.GP_Validation_Norm import LOO_Analysis\n",
    "# from bo_methods_lib.GP_Validation import LOO_Analysis\n",
    "from bo_methods_lib.bo_functions_generic import gen_theta_set, find_train_doc_path, set_ep, clean_1D_arrays\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8886b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date and Time:  19-Dec-2022 (18:00:46)\n"
     ]
    }
   ],
   "source": [
    "#Set Date and Time\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S)\")\n",
    "print(\"Date and Time: \", timestampStr)\n",
    "# DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M-%S%p\")\n",
    "DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M\")\n",
    "# DateTime = \"2022/11/29/09-48\"\n",
    "DateTime = None ##For Testing\n",
    "\n",
    "#Set Parameters\n",
    "#Need to run at a and b, need 2 arrays to test that this will work\n",
    "CS = 2.2\n",
    "\n",
    "Constants = np.array([[-200,-100,-170,15],\n",
    "                      [-1,-1,-6.5,0.7],\n",
    "                      [0,0,11,0.6],\n",
    "                      [-10,-10,-6.5,0.7],\n",
    "                      [1,0,-0.5,-1],\n",
    "                      [0,0.5,1.5,1]])\n",
    "if CS == 2.2:\n",
    "    skip_param_types = 1 #This is what changes for subpoint\n",
    "    true_p = Constants[skip_param_types:skip_param_types+2].flatten()\n",
    "    param_dict = {0 : 'a_1', 1 : 'a_2', 2 : 'a_3', 3 : 'a_4',\n",
    "                  4 : 'b_1', 5 : 'b_2', 6 : 'b_3', 7 : 'b_4'}\n",
    "    exp_d = 2\n",
    "    n = 15 #Number of experimental data points to use\n",
    "    bounds_x = np.array([[-1.5, -0.5],\n",
    "                     [   1,    2]])\n",
    "    bounds_p = np.array([[-2, -2, -10, -2, -2, -2,  5, -2],\n",
    "                   [ 2,  2,   0,  2,  2,  2, 15,  2]])\n",
    "\n",
    "else:\n",
    "    Constants = true_p = np.array([1,-1])\n",
    "    skip_param_types = 0\n",
    "    param_dict = {0 : '\\\\theta_1', 1 : '\\\\theta_2'}\n",
    "    exp_d = 1\n",
    "    n = 5\n",
    "    bounds_x = np.array([[-2], [2]])\n",
    "    bounds_p = np.array([[-2, -2],\n",
    "                         [ 2,  2]])\n",
    "\n",
    "# print(Theta_True)\n",
    "t = 200\n",
    "d = len(true_p)\n",
    "train_iter = 300\n",
    "noise_std = 0.1\n",
    "sep_fact = np.linspace(1,1,1)\n",
    "set_lengthscale = None\n",
    "explore_bias = 1\n",
    "plot_axis = np.array([1,0])\n",
    "norm = True\n",
    "# norm = False\n",
    "\n",
    "# obj = np.array([\"obj\", \"LN_obj\"])\n",
    "# obj = np.array([\"LN_obj\"])\n",
    "obj = np.array([\"obj\"])\n",
    "\n",
    "# emulator = np.array([False, True])\n",
    "emulator = np.array([True])\n",
    "# emulator =  np.array([False])\n",
    "save_figure = True\n",
    "save_figure = False\n",
    "\n",
    "#Pull Experimental data from CSV\n",
    "exp_data_doc = 'Input_CSVs/Exp_Data/d='+str(exp_d)+'/n='+str(n)+'.csv'\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1:exp_d+1]\n",
    "Yexp = exp_data[:,-1]\n",
    "\n",
    "Xexp = clean_1D_arrays(Xexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da017483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulator = True\n",
      "Objective Function = obj\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'numpy.ndarray' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/GP_Validation_Norm.py:135\u001b[0m, in \u001b[0;36mLOO_Analysis\u001b[0;34m(all_data, Xexp, Yexp, true_model_coefficients, true_p, emulator, obj, Case_Study, skip_param_types, set_lengthscale, train_iter, noise_std, verbose, DateTime, save_figure, plot_axis, normalize, bounds_p, bounds_x)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;66;03m#Train GP\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#         print(train_p[0:5], theta_set, Xexp, true_model_coefficients)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m         train_GP \u001b[38;5;241m=\u001b[39m train_GP_model(model, likelihood, train_p, train_y, train_iter, verbose\u001b[38;5;241m=\u001b[39mverbose)      \n\u001b[0;32m--> 135\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m \u001b[43mLOO_eval_GP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_lengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCase_Study\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;66;03m#If emulator is false, eval_components is the GP mean, StDev, and variance\u001b[39;00m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m emulator \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/GP_Validation_Norm.py:292\u001b[0m, in \u001b[0;36mLOO_eval_GP\u001b[0;34m(theta_set, Xexp, train_y, true_model_coefficients, model, likelihood, verbose, emulator, set_lengthscale, true_p, norm_scalers, CS, train_p, obj, skip_param_types, noise_std)\u001b[0m\n\u001b[1;32m    289\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m LOO_eval_GP_basic_set(theta_set, train_y, model, likelihood, obj, verbose)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m#         eval_components = eval_GP_emulator_tot(Xexp,Yexp, theta_mesh, model, likelihood, sparse_grid, explore_bias, verbose)\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m \u001b[43mLOO_eval_GP_emulator_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m eval_components\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/GP_Validation_Norm.py:416\u001b[0m, in \u001b[0;36mLOO_eval_GP_emulator_set\u001b[0;34m(theta_set, Xexp, true_model_coefficients, model, likelihood, p_true, norm_scalers, CS, verbose, train_p, obj, skip_param_types, noise_std)\u001b[0m\n\u001b[1;32m    410\u001b[0m     calc_exp_point \u001b[38;5;241m=\u001b[39m clean_1D_arrays(Xexp_unscl)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m#     print(calc_exp_point)\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m#     print(true_model_coefficients_unscl)\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m##Compute SSE and SSE variance for that point\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m#Copute Yexp\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m     Yexp \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_y_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_model_coefficients_unscl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_exp_point\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    417\u001b[0m     SSE \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (model_mean \u001b[38;5;241m-\u001b[39m Yexp)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    419\u001b[0m     error_point \u001b[38;5;241m=\u001b[39m (model_mean \u001b[38;5;241m-\u001b[39m Yexp) \u001b[38;5;66;03m#This SSE_variance CAN be negative\u001b[39;00m\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_create_data.py:84\u001b[0m, in \u001b[0;36mcalc_y_exp\u001b[0;34m(true_model_coefficients, x, noise_std, noise_mean, random_seed)\u001b[0m\n\u001b[1;32m     80\u001b[0m     y_exp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(len_x)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(len_x):\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#         print(true_model_coefficients.shape)\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m         y_exp[i] \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_muller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_exp\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_create_data.py:41\u001b[0m, in \u001b[0;36mcalc_muller\u001b[0;34m(x, model_coefficients, noise)\u001b[0m\n\u001b[1;32m     39\u001b[0m     X1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m], X2 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m A, a, b, c, x0, y0 \u001b[38;5;241m=\u001b[39m model_coefficients\n\u001b[0;32m---> 41\u001b[0m Term1 \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     42\u001b[0m Term2 \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m*\u001b[39m(X1 \u001b[38;5;241m-\u001b[39m x0)\u001b[38;5;241m*\u001b[39m(X2 \u001b[38;5;241m-\u001b[39m y0)\n\u001b[1;32m     43\u001b[0m Term3 \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m*\u001b[39m(X2 \u001b[38;5;241m-\u001b[39m y0)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'numpy.ndarray' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Set Date and Time\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S)\")\n",
    "print(\"Date and Time: \", timestampStr)\n",
    "# DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M-%S%p\")\n",
    "DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M\")\n",
    "DateTime = None ##For Testing\n",
    "\n",
    "for emul in emulator:\n",
    "    print(\"Emulator =\", emul)\n",
    "    if emul == False:\n",
    "        t_use = t\n",
    "        obj_use = obj\n",
    "    else:\n",
    "        t_use = t*n\n",
    "        obj_use = np.array([\"obj\"])\n",
    "    for obj_func in obj_use:\n",
    "        print(\"Objective Function =\", obj_func)\n",
    "        all_data_doc = find_train_doc_path(emul, obj_func, d, t_use)\n",
    "        all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\"))\n",
    "#         print(all_data)\n",
    "#         choose_CS(CS)?\n",
    "#         print(all_data)\n",
    "        LOO_Analysis(all_data, Xexp, Yexp, Constants, true_p, emul, obj_func, CS,  \n",
    "                     skip_param_types = skip_param_types, noise_std = noise_std, DateTime = DateTime, \n",
    "                     save_figure= save_figure, plot_axis = plot_axis, normalize = norm, bounds_p = bounds_p, \n",
    "                     bounds_x = bounds_x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca0f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
