{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "from bo_functions import eval_GP_components\n",
    "from bo_functions import calc_ei_point\n",
    "from bo_functions import calc_ei_total_test\n",
    "\n",
    "from bo_plotters import plot_hyperparams\n",
    "from bo_plotters import ei_plotter_adv_test\n",
    "from bo_plotters import ei_plotter\n",
    "from bo_plotters import error_plotter_4D\n",
    "from bo_plotters import y_plotter_4D\n",
    "from bo_plotters import stdev_plotter_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2934c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull x and Y data from CSV\n",
    "#Pull x data from CSV\n",
    "exp_data_doc = \"exp_data.csv\"\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "\n",
    "n = len(Xexp)\n",
    "dim = 3\n",
    "# print(n)\n",
    "Theta_True = np.array([1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test data\n",
    "train_data_doc = \"train_3_in_data.csv\"\n",
    "train_data = np.array(pd.read_csv(train_data_doc, header=0,sep=\",\"))\n",
    "# print(train_data)\n",
    "train_theta = train_data[:,1:dim]\n",
    "train_p = torch.tensor(train_data[:,1:-1])\n",
    "train_y = torch.tensor(train_data[:,-1])\n",
    "# print(train_p)\n",
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ff1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "##Assumes a homoskedastic noise model p(y | f) = f + noise\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "#Defines our model in terms of the class parameters in bo_functions\n",
    "model = ExactGPModel(train_p, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_41912/2677082831.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Set number of training iterations and train GP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_GP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_GP_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnoise_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_GP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlengthscale_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_GP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Toy_Problem\\bo_functions.py\u001b[0m in \u001b[0;36mtrain_GP_model\u001b[1;34m(model, likelihood, train_param, train_data, iterations, verbose)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;31m# Calc loss and backprop gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;31m#Minimizing -logMLL lets us fit hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#A number (tensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m         \u001b[1;31m#computes dloss/dx for every parameter x which has requires_grad=True.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;31m#These are accumulated into x.grad for every parameter x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gpytorch\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# Scale by the amount of data we have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mnum_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Set number of training iterations and train GP\n",
    "iterations = 7000\n",
    "train_GP = train_GP_model(model,likelihood, train_p, train_y, iterations, verbose=False)\n",
    "noise_list = train_GP[0]\n",
    "lengthscale_list = train_GP[1]\n",
    "outputscale_list = train_GP[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd04e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot hyperparameters vs iteration\n",
    "noise_title = \"Noise Hyperparameter\"\n",
    "lengthscale_title = \"Lengthscale Hyperparameter\"\n",
    "outputscale_title = \"Outputscale Hyperparameter\"\n",
    "plot_hyperparams(iterations, noise_list,noise_title)\n",
    "plot_hyperparams(iterations, lengthscale_list,lengthscale_title)\n",
    "plot_hyperparams(iterations, outputscale_list,outputscale_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f58804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change GP Hyperparameters\n",
    "# outputscale = torch.tensor([3.5078])\n",
    "# lengthscale = torch.tensor([1.9804])\n",
    "# noise = torch.tensor([10.0762])\n",
    "\n",
    "# outputscale = torch.tensor([3.5])\n",
    "# lengthscale = torch.tensor([2])\n",
    "# noise = torch.tensor([10])\n",
    "\n",
    "# model.likelihood.noise = noise\n",
    "# model.covar_module.base_kernel.lengthscale =lengthscale\n",
    "# model.covar_module.outputscale = outputscale\n",
    "\n",
    "print(\"Noise Hyperparameter: \", model.likelihood.noise)\n",
    "print(\"Lengthscale Hyperparameter: \", model.covar_module.base_kernel.lengthscale)\n",
    "print(\"Outputscale Hyperparameter: \", model.covar_module.outputscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "#Puts model in evaluation mode\n",
    "model.eval()\n",
    "#Puts likelihood in evaluation mode\n",
    "likelihood.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71daa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Meshgrid\n",
    "p = 10\n",
    "Theta1 = np.linspace(-2,2,p)\n",
    "Theta2 = np.linspace(-2,2,p)\n",
    "\n",
    "theta_mesh = np.array(np.meshgrid(Theta1,Theta2))\n",
    "theta_space = torch.tensor(theta_mesh.T.reshape(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1_mesh = theta_mesh[0]\n",
    "theta2_mesh = theta_mesh[1]\n",
    "\n",
    "# for i in range(p):\n",
    "#     for j in range(p):\n",
    "#         print([theta1_mesh[i,j],theta2_mesh[i,j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41599894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will compare the rigorous solution and approximation later (multidimensional integral over each experiment using a sparse grid)\n",
    "#Calculate EI\n",
    "EI_Components = eval_GP_components(p,n,Xexp,Yexp, theta_mesh, model, likelihood)\n",
    "EI = EI_Components[0]\n",
    "Error =EI_Components[1]\n",
    "y_GP = EI_Components[2]\n",
    "stdev_GP = EI_Components[3]\n",
    "error_GP = EI_Components[4]\n",
    "\n",
    "#Finds the index where sse is the smallest and finds which Theta combination corresponds to that value\n",
    "argmin = np.array(np.where(np.isclose(Error, np.amin(Error),atol=1e-10)==True))\n",
    "Theta_1_Opt = float(theta1_mesh[argmin[0],argmin[1]])\n",
    "Theta_2_Opt = float(theta2_mesh[argmin[0],argmin[1]])\n",
    "Theta_Opt_GP = np.array((Theta_1_Opt,Theta_2_Opt))\n",
    "print(\"The GP predicts that Theta =\",Theta_Opt_GP)\n",
    "\n",
    "#calculates best theta value\n",
    "argmax = np.array(np.where(np.isclose(EI, np.amax(EI),atol=1e-10)==True))\n",
    "#     print(argmax)\n",
    "Theta_1_Best = float(theta1_mesh[argmax[0],argmax[1]])\n",
    "Theta_2_Best = float(theta2_mesh[argmax[0],argmax[1]])\n",
    "Theta_Best = np.array((Theta_1_Best,Theta_2_Best))\n",
    "print(\"The GP estimates the highest EI is at Theta = \",Theta_Best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134aac14",
   "metadata": {},
   "source": [
    "## Analysis of Expected Improvement\n",
    " - Expected Improvement is largest in corners\n",
    "  - This is rational because you can't explore any further than the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Theta_True, Theta_GP_Opt)\n",
    "ei_plotter(theta_mesh, EI, Theta_True, Theta_Opt_GP,train_p,plot_train=True)\n",
    "\n",
    "\n",
    "#SHould I even plot y, stdev, and error? If so, would I plot them in 3D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_sing = calc_ei_total_test(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[0]\n",
    "Error =calc_ei_total_test(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[1]\n",
    "for i in range(n):    \n",
    "    ei_plotter_adv_test(theta_mesh, EI_sing[i], Theta_True, train_p,Xexp[i],Theta_Opt_GP,plot_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99811803",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_3D = np.meshgrid(Theta1,Theta2,Xexp)\n",
    "stdev_plot = stdev_plotter_4D(mesh_3D,stdev_GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16656",
   "metadata": {},
   "source": [
    "## Analysis of Standard Deviation\n",
    " - The GP estimates that the standard deviation is lowest at points that were directly tested\n",
    "  - This can be rationalized by the way that the contour plot is drawn\n",
    " - Standard deviation is smallest away from the edges and larger towards them\n",
    "  - This is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The more points that get tested, the more the standard deviations will decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_plot = error_plotter_4D(mesh_3D,error_GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4a585",
   "metadata": {},
   "source": [
    "## Analysis of Error Magnitude\n",
    " - The GP emulator is most inaccurate when all values of $\\bar{p}$ are at their maximum. \n",
    "  - In general, the GP is less accurate at extreme points, this is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The GP emulator is most accurate when x is at it's maximum, but $\\bar{\\Theta}= 0$\n",
    "  - This is rationalized by the fact that multiple terms become zero if any of the values of $\\bar{p}$ are zero \n",
    " - GP error is mostly very high, as more iterations are added, these will decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38301700",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plot = y_plotter_4D(mesh_3D,y_GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d487",
   "metadata": {},
   "source": [
    "## Analysis of GP Emulator (Model y)\n",
    " - The GP emulator correctly captures that y increases as $\\bar{p}$ increases. This tells us that this GP emulator model could be viable\n",
    "  - The GP emulator correctly estimates where the lowest y is achieved, but not the actual value of y\n",
    "  - The GP emulator slightly mistakes where the most positive value of y is, and does not predict the actual value of y\n",
    " - The model as it is is inaccurate, BO should increase the accuracy of the emulator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
