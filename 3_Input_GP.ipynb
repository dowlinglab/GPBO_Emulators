{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "\n",
    "from bo_functions import best_error_advanced\n",
    "from bo_functions import calc_ei_advanced\n",
    "from bo_functions import LHS_Design\n",
    "from bo_functions import create_y_data\n",
    "from bo_functions import test_train_split\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "from bo_functions import calc_GP_outputs\n",
    "from bo_functions import calc_y_expected\n",
    "from bo_functions import improvement_integral\n",
    "from bo_functions import improvement_int_terms\n",
    "\n",
    "from bo_plotters import plotter_adv\n",
    "from bo_plotters import y_plotter_adv\n",
    "from bo_plotters import stdev_plotter_adv\n",
    "from bo_plotters import error_plotter_adv\n",
    "from bo_plotters import ei_plotter_adv\n",
    "from bo_plotters import improvement_integral_plot\n",
    "from bo_plotters import improvement_int_terms_plot\n",
    "from bo_plotters import plotter_adv_4D\n",
    "from bo_plotters import y_plotter_adv_4D\n",
    "from bo_plotters import stdev_plotter_adv_4D\n",
    "from bo_plotters import error_plotter_adv_4D\n",
    "from bo_plotters import ei_plotter_adv_4D\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.tri as mtri\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8567e+00,  7.6583e-01,  1.2417e+00],\n",
      "        [-1.5359e+00, -1.4589e+00,  4.0733e-01],\n",
      "        [ 1.1929e+00, -1.2549e+00, -1.8451e+00],\n",
      "        [-1.9292e+00,  8.9024e-01,  1.6229e+00],\n",
      "        [ 2.7640e-01,  6.0036e-02,  1.7340e+00],\n",
      "        [ 6.7009e-01, -6.7689e-01,  1.1550e+00],\n",
      "        [-2.6864e-01,  6.1656e-01, -1.7169e+00],\n",
      "        [ 8.2577e-01,  1.3867e+00, -3.5378e-01],\n",
      "        [ 1.0064e+00,  3.3627e-01,  6.2007e-01],\n",
      "        [-1.6244e-03,  1.2003e-01,  7.8550e-01],\n",
      "        [-1.3450e+00,  4.2636e-01, -8.2567e-01],\n",
      "        [-9.8063e-01, -1.3159e-01, -4.0761e-01],\n",
      "        [-1.0562e+00, -1.9284e+00,  3.4419e-01],\n",
      "        [-1.7425e+00,  1.0433e+00, -1.5221e-01],\n",
      "        [-1.3687e+00,  1.9121e+00,  2.0146e-01],\n",
      "        [-1.6021e-01, -7.7287e-01, -6.7441e-01],\n",
      "        [ 1.2909e+00,  1.7409e+00, -1.3370e+00],\n",
      "        [-7.1961e-01, -9.3770e-01,  1.4750e+00],\n",
      "        [-5.2986e-01,  1.5590e+00,  9.2303e-01]], dtype=torch.float64)\n",
      "tensor([  5.4011,  -0.8001, -12.7549,   3.4883,   5.8733,   1.4116,  -2.7820,\n",
      "         -0.1629,   0.9917,   0.5574,   0.8383,   0.3101,  -0.5512,   0.2859,\n",
      "         -0.1900,  -0.5502,  -1.0040,   0.1074,   1.6256], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Set noise parameters and load csv file to generate training data\n",
    "noise_std = 0.1**2\n",
    "all_p = LHS_Design(\"LHS_Toy_3_Input.csv\")\n",
    "all_y = create_y_data(all_p)\n",
    "\n",
    "#Separate training and testing data, uses default of an 80%/20% split\n",
    "train_test_data = test_train_split(all_p,all_y)\n",
    "\n",
    "train_p = train_test_data[0] #1x19\n",
    "train_y = train_test_data[1] #1x19\n",
    "test_p = train_test_data[2] #1x19\n",
    "test_y = train_test_data[3] #1x19\n",
    "print(train_p)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ff1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "##Assumes a homoskedastic noise model p(y | f) = f + noise\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "#Defines our model in terms of the class parameters in bo_functions\n",
    "model = ExactGPModel(train_p, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of training iterations and train GP\n",
    "iterations = 500\n",
    "train_GP_model(model,likelihood, train_p, train_y, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5c9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "#Puts model in evaluation mode\n",
    "model.eval()\n",
    "#Puts likelihood in evaluation mode\n",
    "likelihood.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71daa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Meshgrid\n",
    "point_num = 10  #Any bigger than 10 and the kernel just dies\n",
    "test_p1 = np.linspace(-2,2,point_num)\n",
    "test_p2 = np.linspace(-2,2,point_num)\n",
    "test_p3 = np.linspace(-2,2,point_num)\n",
    "\n",
    "test_p_mesh = np.array(np.meshgrid(test_p1,test_p2,test_p3))\n",
    "test_p_mesh_plot = test_p_mesh.T.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b83a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y ,Z = test_p_mesh\n",
    "# print(X.reshape(-1,4))\n",
    "# data = z.reshape(point_num,point_num,point_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41599894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates GP outputs for mean, variance, standard devaition, and y output\n",
    "GP_Outputs = calc_GP_outputs(model,likelihood,test_p_mesh_plot)\n",
    "\n",
    "model_mean = GP_Outputs[0] #1x6\n",
    "model_variance= GP_Outputs[1] #1x6\n",
    "model_stdev = GP_Outputs[2] #1x6\n",
    "model_y = GP_Outputs[3] #1x6\n",
    "\n",
    "#Calculates expected y\n",
    "y_exp = calc_y_expected(test_p_mesh_plot) #1x6\n",
    "\n",
    "# print(\"Model Mean \\n\", model_mean)\n",
    "# print(\"Model Variance \\n\", model_variance)\n",
    "# print(\"Model Standard Deviation \\n\", model_stdev)\n",
    "# print(\"Model y \\n\", model_y)\n",
    "# print(\"Y Value Expected \\n\", y_exp)\n",
    "\n",
    "# print(test_p_mesh_plot)\n",
    "# print(model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f122f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Error is:  1.7471285030332852e-05\n",
      "argmax is 435\n",
      "The test parameter set that gives the highest expected imrovement is \n",
      "Theta1, Theta2, x = \n",
      "\n",
      "[-0.66666667  0.22222222 -0.22222222]\n"
     ]
    }
   ],
   "source": [
    "#Calculates best_error and expected improvement\n",
    "best_error = best_error_advanced(model_y, y_exp)[0] #Scaler\n",
    "best_x = best_error_advanced(model_y, y_exp)[1] #1x3\n",
    "# print(\"best x\",best_x)\n",
    "# print(test_p[1])\n",
    "ei = calc_ei_advanced(best_error,model_mean,model_variance, y_exp) #1x6\n",
    "\n",
    "error_mag = abs(y_exp - model_y.numpy())\n",
    "print(\"Best Error is: \",best_error)\n",
    "# print(\"EI:\",ei)\n",
    "# print(ei.shape)\n",
    "argmax_ei = np.argmax(ei)\n",
    "print(\"argmax is\", argmax_ei)\n",
    "print(\"The test parameter set that gives the highest expected imrovement is \\nTheta1, Theta2, x = \\n\")\n",
    "print(test_p_mesh_plot[argmax_ei])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b93de80",
   "metadata": {},
   "source": [
    "print(ei_plotter_adv_4D(test_p_mesh, ei, point_num))\n",
    "# for i in range (len(test_p_mesh_plot)):\n",
    "#     print(test_p_mesh_plot[i], ei[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134aac14",
   "metadata": {},
   "source": [
    "## Analysis of Expected Improvement\n",
    " - Expected Improvement is largest farther from the edges\n",
    "  - This is rational because you can't explore any further than the edges\n",
    " - Expected Improvement increases as error decreases\n",
    "  - This is rational because as error decreases, more exploitation is possible\n",
    " - This means we are most likely to sample in the middle, farthet from the edges\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c98657d1",
   "metadata": {},
   "source": [
    "print(stdev_plotter_adv_4D(test_p_mesh, model_stdev, point_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16656",
   "metadata": {},
   "source": [
    "## Analysis of Standard Deviation\n",
    " - The GP estimates that the standard deviation is lowest at points that were directly tested\n",
    "  - This can be rationalized by the way that the contour plot is drawn\n",
    " - Standard deviation is smallest away from the edges and larger towards them\n",
    "  - This is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The more points that get tested, the more the standard deviations will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6491294",
   "metadata": {},
   "source": [
    "print(error_plotter_adv_4D(test_p_mesh, model_y, y_exp, point_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4a585",
   "metadata": {},
   "source": [
    "## Analysis of Error Magnitude\n",
    " - The GP emulator is most inaccurate when all values of $\\bar{p}$ are at their maximum. \n",
    "  - In general, the GP is less accurate at extreme points, this is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The GP emulator is most accurate when x is at it's maximum, but $\\bar{\\Theta}= 0$\n",
    "  - This is rationalized by the fact that multiple terms become zero if any of the values of $\\bar{p}$ are zero \n",
    " - GP error is mostly very high, as more iterations are added, these will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b856d936",
   "metadata": {},
   "source": [
    "y_title = \"Model Y Values\"\n",
    "print(y_plotter_adv_4D(test_p_mesh, model_y, point_num,y_title,yval=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d487",
   "metadata": {},
   "source": [
    "## Analysis of GP Emulator (Model y)\n",
    " - The GP emulator correctly captures that y increases as $\\bar{p}$ increases. This tells us that this GP emulator model could be viable\n",
    "  - The GP emulator correctly estimates where the lowest y is achieved, but not the actual value of y\n",
    "  - The GP emulator slightly mistakes where the most positive value of y is, and does not predict the actual value of y\n",
    " - The model as it is is inaccurate, BO should increase the accuracy of the emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ca1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ei_plotter_adv(test_p_mesh_plot, ei))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69c62ab2",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': '3d'},figsize=(11,8))\n",
    "\n",
    "X, Y, Z = np.array(np.meshgrid(test_p1,test_p2,test_p3))\n",
    "X = X.reshape(-1,point_num)\n",
    "Y = Y.reshape(-1,point_num)\n",
    "Z = Z.reshape(-1,point_num)\n",
    "print(X.shape)\n",
    "C = ei.T.reshape(-1,point_num)\n",
    "print(C.shape)\n",
    "scamap = plt.cm.ScalarMappable(cmap='viridis')\n",
    "fcolors = scamap.to_rgba(C)\n",
    "ax.plot_surface(X, Y, Z, facecolors=fcolors, cmap='viridis')\n",
    "fig.colorbar(scamap, label = \"Yelling\")\n",
    "ax.set_xlabel('$\\Theta_1$')\n",
    "ax.set_ylabel('$\\Theta_2$')\n",
    "ax.set_zlabel('X Coordinate')\n",
    "ax.view_init(40, -30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4da7bae",
   "metadata": {},
   "source": [
    "y_title = \"Model y Value\"\n",
    "print(y_plotter_adv(test_p, model_y, y_title,yval = True))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "067d6ce9",
   "metadata": {},
   "source": [
    "print(stdev_plotter_adv(test_p, model_stdev))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fd7ecc1",
   "metadata": {},
   "source": [
    "print(error_plotter_adv(test_p, model_y, y_exp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
