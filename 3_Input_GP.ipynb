{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bo_functions import best_error_advanced\n",
    "from bo_functions import calc_ei_advanced\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "from bo_functions import calc_GP_outputs\n",
    "from bo_functions import calc_y_expected\n",
    "\n",
    "from bo_plotters import plotter_adv\n",
    "from bo_plotters import basic_plotter\n",
    "from bo_plotters import ei_plotter_basic\n",
    "from bo_plotters import y_plotter_adv\n",
    "from bo_plotters import stdev_plotter_adv\n",
    "from bo_plotters import error_plotter_adv\n",
    "from bo_plotters import ei_plotter_adv\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.tri as mtri\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2934c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#Pull x and Y data from CSV\n",
    "#Pull x data from CSV\n",
    "exp_data_doc = \"exp_data.csv\"\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "\n",
    "n = len(Xexp)\n",
    "print(n)\n",
    "Theta_True = np.array([1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8567e+00,  7.6583e-01,  1.2417e+00],\n",
      "        [-1.5359e+00, -1.4589e+00,  4.0733e-01],\n",
      "        [ 1.1929e+00, -1.2549e+00, -1.8451e+00],\n",
      "        [-1.9292e+00,  8.9024e-01,  1.6229e+00],\n",
      "        [ 2.7640e-01,  6.0036e-02,  1.7340e+00],\n",
      "        [ 6.7009e-01, -6.7689e-01,  1.1550e+00],\n",
      "        [-2.6864e-01,  6.1656e-01, -1.7169e+00],\n",
      "        [ 8.2577e-01,  1.3867e+00, -3.5378e-01],\n",
      "        [ 1.0064e+00,  3.3627e-01,  6.2007e-01],\n",
      "        [-1.6244e-03,  1.2003e-01,  7.8550e-01],\n",
      "        [-1.3450e+00,  4.2636e-01, -8.2567e-01],\n",
      "        [-9.8063e-01, -1.3159e-01, -4.0761e-01],\n",
      "        [-1.0562e+00, -1.9284e+00,  3.4419e-01],\n",
      "        [-1.7425e+00,  1.0433e+00, -1.5221e-01],\n",
      "        [-1.3687e+00,  1.9121e+00,  2.0146e-01],\n",
      "        [-1.6021e-01, -7.7287e-01, -6.7441e-01],\n",
      "        [ 1.2909e+00,  1.7409e+00, -1.3370e+00],\n",
      "        [-7.1961e-01, -9.3770e-01,  1.4750e+00],\n",
      "        [-5.2986e-01,  1.5590e+00,  9.2303e-01]], dtype=torch.float64)\n",
      "tensor([  5.4011,  -0.8001, -12.7549,   3.4883,   5.8733,   1.4116,  -2.7820,\n",
      "         -0.1629,   0.9917,   0.5574,   0.8383,   0.3101,  -0.5512,   0.2859,\n",
      "         -0.1900,  -0.5502,  -1.0040,   0.1074,   1.6256], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Create training and test data\n",
    "train_data_doc = \"train_3_in_data.csv\"\n",
    "train_data = np.array(pd.read_csv(train_data_doc, header=0,sep=\",\"))\n",
    "# print(train_data)\n",
    "train_theta = train_data[:,1:3]\n",
    "train_p = torch.tensor(train_data[:,1:4])\n",
    "train_y = torch.tensor(train_data[:,4])\n",
    "print(train_p)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ff1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "##Assumes a homoskedastic noise model p(y | f) = f + noise\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "#Defines our model in terms of the class parameters in bo_functions\n",
    "model = ExactGPModel(train_p, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of training iterations and train GP\n",
    "iterations = 500\n",
    "train_GP_model(model,likelihood, train_p, train_y, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5c9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "#Puts model in evaluation mode\n",
    "model.eval()\n",
    "#Puts likelihood in evaluation mode\n",
    "likelihood.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71daa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Meshgrid\n",
    "p = 10 #Any bigger than 10 and the kernel just dies\n",
    "Theta1 = np.linspace(-2,2,p)\n",
    "Theta2 = np.linspace(-2,2,p)\n",
    "\n",
    "theta_mesh = np.array(np.meshgrid(Theta1,Theta2))\n",
    "theta_space = torch.tensor(theta_mesh.T.reshape(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba9a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1_mesh = theta_mesh[0]\n",
    "theta2_mesh = theta_mesh[1]\n",
    "\n",
    "# for i in range(p):\n",
    "#     for j in range(p):\n",
    "#         print([theta1_mesh[i,j],theta2_mesh[i,j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41599894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.816586573942472e-07\n",
      "The GP estimates \n",
      "Theta1, Theta2 = \n",
      "\n",
      "[[0.66666667]\n",
      " [0.22222222]]\n",
      "The GP estimates the highest EI is at \n",
      "Theta1, Theta2 = \n",
      " \n",
      "[[ 2.]\n",
      " [-2.]]\n"
     ]
    }
   ],
   "source": [
    "#Define f_bar and f(x)\n",
    "f_bar = Yexp #(1xn)\n",
    "#Will compare the rigorous solution and approximation later (multidimensional integral over each experiment using a sparse grid)\n",
    "\n",
    "#Create an array in which to store expected improvement values\n",
    "EI = np.zeros((p,p)) #(p1 x p2)\n",
    "# Loop over theta 1\n",
    "for i in range(p):\n",
    "    #Loop over theta2\n",
    "    for j in range(p):\n",
    "        #Create array to store error values\n",
    "        error = np.zeros(n)\n",
    "        #Loop over Xexp\n",
    "        for k in range(n):\n",
    "            #Evaluate GP at a point p = [Theta1,Theta2,Xexp]\n",
    "            eval_point = []\n",
    "            eval_point.append([theta1_mesh[i,j],theta2_mesh[i,j],Xexp[k]])\n",
    "            eval_point = np.array(eval_point)\n",
    "            GP_Outputs = calc_GP_outputs(model, likelihood, eval_point[0:1])\n",
    "            model_mean = GP_Outputs[3].numpy()[0] #1xn\n",
    "            model_variance= GP_Outputs[1].numpy()[0] #1xn\n",
    "#             print(eval_point,model_mean,model_variance)\n",
    "            #Compute error for that point\n",
    "#             print(eval_point,model_mean, f_bar[k])\n",
    "            error[k] = -(f_bar[k] - model_mean)**2\n",
    "#             print(error[k])\n",
    "        #Define best_error as the maximum value in the error array\n",
    "        best_error = -max(error)\n",
    "#         print(best_error)\n",
    "        #Loop over Xexp\n",
    "        for k in range(n):\n",
    "            #Caclulate EI for each value n given the best error\n",
    "#             print(i,j,k)\n",
    "            eval_point = []\n",
    "            eval_point.append([theta1_mesh[i,j],theta2_mesh[i,j],Xexp[k]])\n",
    "            eval_point = np.array(eval_point)\n",
    "#             print(eval_point)\n",
    "            GP_Outputs = calc_GP_outputs(model, likelihood, eval_point[0:1])\n",
    "            model_mean = GP_Outputs[3].numpy()[0] #1xn\n",
    "            model_variance= GP_Outputs[1].numpy()[0] #1xn\n",
    "#             print(eval_point,model_mean,model_variance,Yexp[k])\n",
    "            EI[i,j] += calc_ei_advanced(best_error, model_mean, model_variance, Yexp[k])\n",
    "#             print(EI[i,j])\n",
    "\n",
    "\n",
    "print(np.min(EI))\n",
    "argmin = np.array(np.where(EI == np.amin(EI)))\n",
    "Theta_1_Opt = theta1_mesh[argmin[0],argmin[1]]\n",
    "Theta_2_Opt = theta2_mesh[argmin[0],argmin[1]]\n",
    "Theta_GP_Opt = np.array([Theta_1_Opt,Theta_2_Opt])\n",
    "print(\"The GP estimates \\nTheta1, Theta2 = \\n\")\n",
    "print(Theta_GP_Opt)\n",
    "\n",
    "argmax = np.array(np.where(EI == np.amax(EI)))\n",
    "Theta_1_Best = theta1_mesh[argmax[0],argmax[1]]\n",
    "Theta_2_Best = theta2_mesh[argmax[0],argmax[1]]\n",
    "Theta_Best = np.array([Theta_1_Best,Theta_2_Best])\n",
    "print(\"The GP estimates the highest EI is at \\nTheta1, Theta2 = \\n \")\n",
    "print(Theta_Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab2428d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ei_plotter_adv() missing 1 required positional argument: 'train_p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_64008/2015168571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mei_plotter_adv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta_mesh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTheta_True\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTheta_True\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_theta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ei_plotter_adv() missing 1 required positional argument: 'train_p'"
     ]
    }
   ],
   "source": [
    "ei_plotter_adv(theta_mesh, EI, Theta_True, Theta_Best,train_theta,plot_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134aac14",
   "metadata": {},
   "source": [
    "## Analysis of Expected Improvement\n",
    " - Expected Improvement is largest farther from the edges\n",
    "  - This is rational because you can't explore any further than the edges\n",
    " - Expected Improvement increases as error decreases\n",
    "  - This is rational because as error decreases, more exploitation is possible\n",
    " - This means we are most likely to sample in the middle, farthet from the edges\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c98657d1",
   "metadata": {},
   "source": [
    "print(stdev_plotter_adv_4D(test_p_mesh, model_stdev, point_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16656",
   "metadata": {},
   "source": [
    "## Analysis of Standard Deviation\n",
    " - The GP estimates that the standard deviation is lowest at points that were directly tested\n",
    "  - This can be rationalized by the way that the contour plot is drawn\n",
    " - Standard deviation is smallest away from the edges and larger towards them\n",
    "  - This is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The more points that get tested, the more the standard deviations will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6491294",
   "metadata": {},
   "source": [
    "print(error_plotter_adv_4D(test_p_mesh, model_y, y_exp, point_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4a585",
   "metadata": {},
   "source": [
    "## Analysis of Error Magnitude\n",
    " - The GP emulator is most inaccurate when all values of $\\bar{p}$ are at their maximum. \n",
    "  - In general, the GP is less accurate at extreme points, this is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The GP emulator is most accurate when x is at it's maximum, but $\\bar{\\Theta}= 0$\n",
    "  - This is rationalized by the fact that multiple terms become zero if any of the values of $\\bar{p}$ are zero \n",
    " - GP error is mostly very high, as more iterations are added, these will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b856d936",
   "metadata": {},
   "source": [
    "y_title = \"Model Y Values\"\n",
    "print(y_plotter_adv_4D(test_p_mesh, model_y, point_num,y_title,yval=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d487",
   "metadata": {},
   "source": [
    "## Analysis of GP Emulator (Model y)\n",
    " - The GP emulator correctly captures that y increases as $\\bar{p}$ increases. This tells us that this GP emulator model could be viable\n",
    "  - The GP emulator correctly estimates where the lowest y is achieved, but not the actual value of y\n",
    "  - The GP emulator slightly mistakes where the most positive value of y is, and does not predict the actual value of y\n",
    " - The model as it is is inaccurate, BO should increase the accuracy of the emulator"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a246c18a",
   "metadata": {},
   "source": [
    "print(ei_plotter_adv(test_p_mesh_plot, ei))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69c62ab2",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': '3d'},figsize=(11,8))\n",
    "\n",
    "X, Y, Z = np.array(np.meshgrid(test_p1,test_p2,test_p3))\n",
    "X = X.reshape(-1,point_num)\n",
    "Y = Y.reshape(-1,point_num)\n",
    "Z = Z.reshape(-1,point_num)\n",
    "print(X.shape)\n",
    "C = ei.T.reshape(-1,point_num)\n",
    "print(C.shape)\n",
    "scamap = plt.cm.ScalarMappable(cmap='viridis')\n",
    "fcolors = scamap.to_rgba(C)\n",
    "ax.plot_surface(X, Y, Z, facecolors=fcolors, cmap='viridis')\n",
    "fig.colorbar(scamap, label = \"Yelling\")\n",
    "ax.set_xlabel('$\\Theta_1$')\n",
    "ax.set_ylabel('$\\Theta_2$')\n",
    "ax.set_zlabel('X Coordinate')\n",
    "ax.view_init(40, -30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4da7bae",
   "metadata": {},
   "source": [
    "y_title = \"Model y Value\"\n",
    "print(y_plotter_adv(test_p, model_y, y_title,yval = True))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "067d6ce9",
   "metadata": {},
   "source": [
    "print(stdev_plotter_adv(test_p, model_stdev))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fd7ecc1",
   "metadata": {},
   "source": [
    "print(error_plotter_adv(test_p, model_y, y_exp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
