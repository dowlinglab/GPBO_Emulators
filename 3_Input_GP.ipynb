{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bo_functions import best_error_advanced\n",
    "from bo_functions import calc_ei_advanced\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "from bo_functions import calc_GP_outputs\n",
    "from bo_functions import calc_y_expected\n",
    "\n",
    "from bo_plotters import plotter_adv\n",
    "from bo_plotters import y_plotter_adv\n",
    "from bo_plotters import stdev_plotter_adv\n",
    "from bo_plotters import error_plotter_adv\n",
    "from bo_plotters import ei_plotter_adv\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.tri as mtri\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test data\n",
    "train_data_doc = \"train_3_in_data.csv\"\n",
    "train_data = np.array(pd.read_csv(train_data_doc, header=0,sep=\",\"))\n",
    "train_p = torch.tensor(train_data[:,1:4])\n",
    "train_y = torch.tensor(train_data[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ff1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "##Assumes a homoskedastic noise model p(y | f) = f + noise\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "#Defines our model in terms of the class parameters in bo_functions\n",
    "model = ExactGPModel(train_p, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of training iterations and train GP\n",
    "iterations = 500\n",
    "train_GP_model(model,likelihood, train_p, train_y, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5c9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "#Puts model in evaluation mode\n",
    "model.eval()\n",
    "#Puts likelihood in evaluation mode\n",
    "likelihood.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71daa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Meshgrid\n",
    "point_num = 5 #Any bigger than 10 and the kernel just dies\n",
    "Theta1 = np.linspace(-2,2,point_num)\n",
    "Theta2 = np.linspace(-2,2,point_num)\n",
    "\n",
    "theta_mesh = np.array(np.meshgrid(Theta1,Theta2))\n",
    "theta_space = torch.tensor(theta_mesh.T.reshape(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41599894",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 3 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12440/1993585537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Calculates GP outputs for mean, variance, standard devaition, and y output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mGP_Outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_GP_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGP_Outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#1x6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_variance\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGP_Outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#1x6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Toy_Problem\\bo_functions.py\u001b[0m in \u001b[0;36mcalc_GP_outputs\u001b[1;34m(model, likelihood, test_param)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;31m#Good up to 10,000 data points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;31m#Predicts data points for model (sse) by sending the model through the likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mobserved_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_param\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1 x n_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;31m#Calculates model mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gpytorch\\models\\exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m                     \u001b[0mtrain_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mfull_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;31m# Get the joint distribution for training/test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 3 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "#This needs to change to match pseudo code\n",
    "\n",
    "#Calculates GP outputs for mean, variance, standard devaition, and y output\n",
    "GP_Outputs = calc_GP_outputs(model,likelihood,theta_space)\n",
    "\n",
    "model_mean = GP_Outputs[0] #1x6\n",
    "model_variance= GP_Outputs[1] #1x6\n",
    "model_stdev = GP_Outputs[2] #1x6\n",
    "model_y = GP_Outputs[3] #1x6\n",
    "\n",
    "\n",
    "print(\"Model Mean \\n\", model_mean)\n",
    "print(\"Model Variance \\n\", model_variance)\n",
    "print(\"Model Standard Deviation \\n\", model_stdev)\n",
    "print(\"Model y \\n\", model_y)\n",
    "print(\"Y Value Expected \\n\", y_exp)\n",
    "\n",
    "# print(test_p_mesh_plot)\n",
    "# print(model_y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "277929b8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Calculates best_error and expected improvement\n",
    "best_error = best_error_advanced(model_y, y_exp)[0] #Scaler\n",
    "best_x = best_error_advanced(model_y, y_exp)[1] #1x3\n",
    "# print(\"best x\",best_x)\n",
    "# print(test_p[1])\n",
    "ei = calc_ei_advanced(best_error,model_mean,model_variance, y_exp) #1x6\n",
    "\n",
    "error_mag = abs(y_exp - model_y.numpy())\n",
    "print(\"Best Error is: \",best_error)\n",
    "# print(\"EI:\",ei)\n",
    "# print(ei.shape)\n",
    "argmax_ei = np.argmax(ei)\n",
    "print(\"argmax is\", argmax_ei)\n",
    "print(\"The test parameter set that gives the highest expected imrovement is \\nTheta1, Theta2, x = \\n\")\n",
    "print(test_p_mesh_plot[argmax_ei])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b93de80",
   "metadata": {},
   "source": [
    "print(ei_plotter_adv_4D(test_p_mesh, ei, point_num))\n",
    "# for i in range (len(test_p_mesh_plot)):\n",
    "#     print(test_p_mesh_plot[i], ei[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134aac14",
   "metadata": {},
   "source": [
    "## Analysis of Expected Improvement\n",
    " - Expected Improvement is largest farther from the edges\n",
    "  - This is rational because you can't explore any further than the edges\n",
    " - Expected Improvement increases as error decreases\n",
    "  - This is rational because as error decreases, more exploitation is possible\n",
    " - This means we are most likely to sample in the middle, farthet from the edges\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c98657d1",
   "metadata": {},
   "source": [
    "print(stdev_plotter_adv_4D(test_p_mesh, model_stdev, point_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16656",
   "metadata": {},
   "source": [
    "## Analysis of Standard Deviation\n",
    " - The GP estimates that the standard deviation is lowest at points that were directly tested\n",
    "  - This can be rationalized by the way that the contour plot is drawn\n",
    " - Standard deviation is smallest away from the edges and larger towards them\n",
    "  - This is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The more points that get tested, the more the standard deviations will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6491294",
   "metadata": {},
   "source": [
    "print(error_plotter_adv_4D(test_p_mesh, model_y, y_exp, point_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4a585",
   "metadata": {},
   "source": [
    "## Analysis of Error Magnitude\n",
    " - The GP emulator is most inaccurate when all values of $\\bar{p}$ are at their maximum. \n",
    "  - In general, the GP is less accurate at extreme points, this is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The GP emulator is most accurate when x is at it's maximum, but $\\bar{\\Theta}= 0$\n",
    "  - This is rationalized by the fact that multiple terms become zero if any of the values of $\\bar{p}$ are zero \n",
    " - GP error is mostly very high, as more iterations are added, these will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b856d936",
   "metadata": {},
   "source": [
    "y_title = \"Model Y Values\"\n",
    "print(y_plotter_adv_4D(test_p_mesh, model_y, point_num,y_title,yval=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d487",
   "metadata": {},
   "source": [
    "## Analysis of GP Emulator (Model y)\n",
    " - The GP emulator correctly captures that y increases as $\\bar{p}$ increases. This tells us that this GP emulator model could be viable\n",
    "  - The GP emulator correctly estimates where the lowest y is achieved, but not the actual value of y\n",
    "  - The GP emulator slightly mistakes where the most positive value of y is, and does not predict the actual value of y\n",
    " - The model as it is is inaccurate, BO should increase the accuracy of the emulator"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a246c18a",
   "metadata": {},
   "source": [
    "print(ei_plotter_adv(test_p_mesh_plot, ei))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69c62ab2",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': '3d'},figsize=(11,8))\n",
    "\n",
    "X, Y, Z = np.array(np.meshgrid(test_p1,test_p2,test_p3))\n",
    "X = X.reshape(-1,point_num)\n",
    "Y = Y.reshape(-1,point_num)\n",
    "Z = Z.reshape(-1,point_num)\n",
    "print(X.shape)\n",
    "C = ei.T.reshape(-1,point_num)\n",
    "print(C.shape)\n",
    "scamap = plt.cm.ScalarMappable(cmap='viridis')\n",
    "fcolors = scamap.to_rgba(C)\n",
    "ax.plot_surface(X, Y, Z, facecolors=fcolors, cmap='viridis')\n",
    "fig.colorbar(scamap, label = \"Yelling\")\n",
    "ax.set_xlabel('$\\Theta_1$')\n",
    "ax.set_ylabel('$\\Theta_2$')\n",
    "ax.set_zlabel('X Coordinate')\n",
    "ax.view_init(40, -30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4da7bae",
   "metadata": {},
   "source": [
    "y_title = \"Model y Value\"\n",
    "print(y_plotter_adv(test_p, model_y, y_title,yval = True))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "067d6ce9",
   "metadata": {},
   "source": [
    "print(stdev_plotter_adv(test_p, model_stdev))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fd7ecc1",
   "metadata": {},
   "source": [
    "print(error_plotter_adv(test_p, model_y, y_exp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
