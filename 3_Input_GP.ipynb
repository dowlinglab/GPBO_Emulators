{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "from bo_functions import calc_ei_total\n",
    "from bo_functions import calc_ei_total\n",
    "\n",
    "from bo_plotters import plotter_adv\n",
    "from bo_plotters import y_plotter_adv\n",
    "from bo_plotters import stdev_plotter_adv\n",
    "from bo_plotters import error_plotter_adv\n",
    "from bo_plotters import error_plotter_adv_test\n",
    "from bo_plotters import ei_plotter_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2934c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull x and Y data from CSV\n",
    "#Pull x data from CSV\n",
    "exp_data_doc = \"exp_data.csv\"\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "\n",
    "n = len(Xexp)\n",
    "# print(n)\n",
    "Theta_True = np.array([1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test data\n",
    "train_data_doc = \"train_3_in_data.csv\"\n",
    "train_data = np.array(pd.read_csv(train_data_doc, header=0,sep=\",\"))\n",
    "# print(train_data)\n",
    "train_theta = train_data[:,1:3]\n",
    "train_p = torch.tensor(train_data[:,1:4])\n",
    "train_y = torch.tensor(train_data[:,4])\n",
    "# print(train_p)\n",
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ff1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "##Assumes a homoskedastic noise model p(y | f) = f + noise\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "#Defines our model in terms of the class parameters in bo_functions\n",
    "model = ExactGPModel(train_p, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/500 - Loss: 5.832   lengthscale: 0.693   noise: 0.693   output scale: 0.693 \n",
      "Iter 2/500 - Loss: 5.519   lengthscale: 0.744   noise: 0.744   output scale: 0.744 \n",
      "Iter 3/500 - Loss: 5.238   lengthscale: 0.798   noise: 0.798   output scale: 0.798 \n",
      "Iter 4/500 - Loss: 4.985   lengthscale: 0.855   noise: 0.854   output scale: 0.853 \n",
      "Iter 5/500 - Loss: 4.757   lengthscale: 0.914   noise: 0.911   output scale: 0.911 \n",
      "Iter 6/500 - Loss: 4.552   lengthscale: 0.975   noise: 0.970   output scale: 0.970 \n",
      "Iter 7/500 - Loss: 4.369   lengthscale: 1.039   noise: 1.030   output scale: 1.030 \n",
      "Iter 8/500 - Loss: 4.207   lengthscale: 1.105   noise: 1.091   output scale: 1.091 \n",
      "Iter 9/500 - Loss: 4.063   lengthscale: 1.171   noise: 1.154   output scale: 1.153 \n",
      "Iter 10/500 - Loss: 3.936   lengthscale: 1.239   noise: 1.216   output scale: 1.216 \n",
      "Iter 11/500 - Loss: 3.824   lengthscale: 1.305   noise: 1.279   output scale: 1.278 \n",
      "Iter 12/500 - Loss: 3.726   lengthscale: 1.370   noise: 1.342   output scale: 1.340 \n",
      "Iter 13/500 - Loss: 3.640   lengthscale: 1.432   noise: 1.405   output scale: 1.402 \n",
      "Iter 14/500 - Loss: 3.564   lengthscale: 1.490   noise: 1.468   output scale: 1.464 \n",
      "Iter 15/500 - Loss: 3.497   lengthscale: 1.542   noise: 1.530   output scale: 1.525 \n",
      "Iter 16/500 - Loss: 3.437   lengthscale: 1.588   noise: 1.592   output scale: 1.585 \n",
      "Iter 17/500 - Loss: 3.384   lengthscale: 1.628   noise: 1.652   output scale: 1.644 \n",
      "Iter 18/500 - Loss: 3.335   lengthscale: 1.660   noise: 1.713   output scale: 1.702 \n",
      "Iter 19/500 - Loss: 3.291   lengthscale: 1.686   noise: 1.772   output scale: 1.758 \n",
      "Iter 20/500 - Loss: 3.251   lengthscale: 1.705   noise: 1.830   output scale: 1.814 \n",
      "Iter 21/500 - Loss: 3.213   lengthscale: 1.718   noise: 1.887   output scale: 1.868 \n",
      "Iter 22/500 - Loss: 3.179   lengthscale: 1.725   noise: 1.942   output scale: 1.921 \n",
      "Iter 23/500 - Loss: 3.148   lengthscale: 1.727   noise: 1.997   output scale: 1.973 \n",
      "Iter 24/500 - Loss: 3.118   lengthscale: 1.725   noise: 2.050   output scale: 2.024 \n",
      "Iter 25/500 - Loss: 3.091   lengthscale: 1.720   noise: 2.102   output scale: 2.073 \n",
      "Iter 26/500 - Loss: 3.066   lengthscale: 1.711   noise: 2.152   output scale: 2.121 \n",
      "Iter 27/500 - Loss: 3.043   lengthscale: 1.700   noise: 2.201   output scale: 2.167 \n",
      "Iter 28/500 - Loss: 3.022   lengthscale: 1.687   noise: 2.249   output scale: 2.213 \n",
      "Iter 29/500 - Loss: 3.003   lengthscale: 1.673   noise: 2.295   output scale: 2.257 \n",
      "Iter 30/500 - Loss: 2.985   lengthscale: 1.658   noise: 2.340   output scale: 2.300 \n",
      "Iter 31/500 - Loss: 2.968   lengthscale: 1.643   noise: 2.384   output scale: 2.341 \n",
      "Iter 32/500 - Loss: 2.953   lengthscale: 1.628   noise: 2.426   output scale: 2.382 \n",
      "Iter 33/500 - Loss: 2.939   lengthscale: 1.614   noise: 2.467   output scale: 2.422 \n",
      "Iter 34/500 - Loss: 2.926   lengthscale: 1.600   noise: 2.507   output scale: 2.460 \n",
      "Iter 35/500 - Loss: 2.914   lengthscale: 1.588   noise: 2.545   output scale: 2.497 \n",
      "Iter 36/500 - Loss: 2.903   lengthscale: 1.577   noise: 2.583   output scale: 2.534 \n",
      "Iter 37/500 - Loss: 2.892   lengthscale: 1.568   noise: 2.619   output scale: 2.569 \n",
      "Iter 38/500 - Loss: 2.883   lengthscale: 1.560   noise: 2.654   output scale: 2.604 \n",
      "Iter 39/500 - Loss: 2.874   lengthscale: 1.554   noise: 2.687   output scale: 2.638 \n",
      "Iter 40/500 - Loss: 2.865   lengthscale: 1.550   noise: 2.720   output scale: 2.671 \n",
      "Iter 41/500 - Loss: 2.857   lengthscale: 1.547   noise: 2.752   output scale: 2.703 \n",
      "Iter 42/500 - Loss: 2.849   lengthscale: 1.547   noise: 2.783   output scale: 2.734 \n",
      "Iter 43/500 - Loss: 2.842   lengthscale: 1.548   noise: 2.813   output scale: 2.764 \n",
      "Iter 44/500 - Loss: 2.835   lengthscale: 1.550   noise: 2.842   output scale: 2.794 \n",
      "Iter 45/500 - Loss: 2.829   lengthscale: 1.554   noise: 2.870   output scale: 2.823 \n",
      "Iter 46/500 - Loss: 2.822   lengthscale: 1.559   noise: 2.897   output scale: 2.852 \n",
      "Iter 47/500 - Loss: 2.816   lengthscale: 1.566   noise: 2.924   output scale: 2.880 \n",
      "Iter 48/500 - Loss: 2.811   lengthscale: 1.573   noise: 2.949   output scale: 2.907 \n",
      "Iter 49/500 - Loss: 2.805   lengthscale: 1.581   noise: 2.974   output scale: 2.934 \n",
      "Iter 50/500 - Loss: 2.800   lengthscale: 1.590   noise: 2.999   output scale: 2.960 \n",
      "Iter 51/500 - Loss: 2.795   lengthscale: 1.600   noise: 3.023   output scale: 2.986 \n",
      "Iter 52/500 - Loss: 2.790   lengthscale: 1.609   noise: 3.046   output scale: 3.011 \n",
      "Iter 53/500 - Loss: 2.785   lengthscale: 1.619   noise: 3.069   output scale: 3.036 \n",
      "Iter 54/500 - Loss: 2.781   lengthscale: 1.629   noise: 3.091   output scale: 3.061 \n",
      "Iter 55/500 - Loss: 2.777   lengthscale: 1.638   noise: 3.113   output scale: 3.085 \n",
      "Iter 56/500 - Loss: 2.773   lengthscale: 1.648   noise: 3.134   output scale: 3.108 \n",
      "Iter 57/500 - Loss: 2.769   lengthscale: 1.657   noise: 3.154   output scale: 3.132 \n",
      "Iter 58/500 - Loss: 2.765   lengthscale: 1.665   noise: 3.175   output scale: 3.155 \n",
      "Iter 59/500 - Loss: 2.762   lengthscale: 1.673   noise: 3.195   output scale: 3.177 \n",
      "Iter 60/500 - Loss: 2.758   lengthscale: 1.680   noise: 3.214   output scale: 3.200 \n",
      "Iter 61/500 - Loss: 2.755   lengthscale: 1.686   noise: 3.233   output scale: 3.222 \n",
      "Iter 62/500 - Loss: 2.752   lengthscale: 1.692   noise: 3.252   output scale: 3.243 \n",
      "Iter 63/500 - Loss: 2.749   lengthscale: 1.697   noise: 3.270   output scale: 3.265 \n",
      "Iter 64/500 - Loss: 2.746   lengthscale: 1.701   noise: 3.288   output scale: 3.286 \n",
      "Iter 65/500 - Loss: 2.743   lengthscale: 1.705   noise: 3.306   output scale: 3.307 \n",
      "Iter 66/500 - Loss: 2.740   lengthscale: 1.708   noise: 3.323   output scale: 3.327 \n",
      "Iter 67/500 - Loss: 2.737   lengthscale: 1.710   noise: 3.341   output scale: 3.348 \n",
      "Iter 68/500 - Loss: 2.735   lengthscale: 1.711   noise: 3.358   output scale: 3.368 \n",
      "Iter 69/500 - Loss: 2.732   lengthscale: 1.713   noise: 3.374   output scale: 3.388 \n",
      "Iter 70/500 - Loss: 2.730   lengthscale: 1.713   noise: 3.390   output scale: 3.408 \n",
      "Iter 71/500 - Loss: 2.727   lengthscale: 1.713   noise: 3.407   output scale: 3.428 \n",
      "Iter 72/500 - Loss: 2.725   lengthscale: 1.713   noise: 3.422   output scale: 3.447 \n",
      "Iter 73/500 - Loss: 2.723   lengthscale: 1.713   noise: 3.438   output scale: 3.466 \n",
      "Iter 74/500 - Loss: 2.720   lengthscale: 1.713   noise: 3.453   output scale: 3.485 \n",
      "Iter 75/500 - Loss: 2.718   lengthscale: 1.712   noise: 3.469   output scale: 3.504 \n",
      "Iter 76/500 - Loss: 2.716   lengthscale: 1.712   noise: 3.484   output scale: 3.523 \n",
      "Iter 77/500 - Loss: 2.714   lengthscale: 1.711   noise: 3.498   output scale: 3.542 \n",
      "Iter 78/500 - Loss: 2.712   lengthscale: 1.710   noise: 3.513   output scale: 3.560 \n",
      "Iter 79/500 - Loss: 2.710   lengthscale: 1.710   noise: 3.527   output scale: 3.579 \n",
      "Iter 80/500 - Loss: 2.708   lengthscale: 1.710   noise: 3.541   output scale: 3.597 \n",
      "Iter 81/500 - Loss: 2.706   lengthscale: 1.710   noise: 3.555   output scale: 3.615 \n",
      "Iter 82/500 - Loss: 2.704   lengthscale: 1.710   noise: 3.569   output scale: 3.633 \n",
      "Iter 83/500 - Loss: 2.702   lengthscale: 1.710   noise: 3.583   output scale: 3.651 \n",
      "Iter 84/500 - Loss: 2.701   lengthscale: 1.710   noise: 3.596   output scale: 3.668 \n",
      "Iter 85/500 - Loss: 2.699   lengthscale: 1.711   noise: 3.609   output scale: 3.686 \n",
      "Iter 86/500 - Loss: 2.697   lengthscale: 1.712   noise: 3.622   output scale: 3.703 \n",
      "Iter 87/500 - Loss: 2.695   lengthscale: 1.713   noise: 3.635   output scale: 3.721 \n",
      "Iter 88/500 - Loss: 2.694   lengthscale: 1.715   noise: 3.648   output scale: 3.738 \n",
      "Iter 89/500 - Loss: 2.692   lengthscale: 1.716   noise: 3.661   output scale: 3.755 \n",
      "Iter 90/500 - Loss: 2.691   lengthscale: 1.718   noise: 3.673   output scale: 3.772 \n",
      "Iter 91/500 - Loss: 2.689   lengthscale: 1.720   noise: 3.685   output scale: 3.789 \n",
      "Iter 92/500 - Loss: 2.688   lengthscale: 1.722   noise: 3.698   output scale: 3.806 \n",
      "Iter 93/500 - Loss: 2.686   lengthscale: 1.724   noise: 3.710   output scale: 3.822 \n",
      "Iter 94/500 - Loss: 2.685   lengthscale: 1.726   noise: 3.721   output scale: 3.839 \n",
      "Iter 95/500 - Loss: 2.683   lengthscale: 1.728   noise: 3.733   output scale: 3.856 \n",
      "Iter 96/500 - Loss: 2.682   lengthscale: 1.731   noise: 3.745   output scale: 3.872 \n",
      "Iter 97/500 - Loss: 2.681   lengthscale: 1.733   noise: 3.756   output scale: 3.888 \n",
      "Iter 98/500 - Loss: 2.679   lengthscale: 1.735   noise: 3.768   output scale: 3.905 \n",
      "Iter 99/500 - Loss: 2.678   lengthscale: 1.738   noise: 3.779   output scale: 3.921 \n",
      "Iter 100/500 - Loss: 2.677   lengthscale: 1.740   noise: 3.790   output scale: 3.937 \n",
      "Iter 101/500 - Loss: 2.675   lengthscale: 1.742   noise: 3.801   output scale: 3.953 \n",
      "Iter 102/500 - Loss: 2.674   lengthscale: 1.744   noise: 3.812   output scale: 3.969 \n",
      "Iter 103/500 - Loss: 2.673   lengthscale: 1.746   noise: 3.823   output scale: 3.985 \n",
      "Iter 104/500 - Loss: 2.672   lengthscale: 1.748   noise: 3.833   output scale: 4.001 \n",
      "Iter 105/500 - Loss: 2.670   lengthscale: 1.750   noise: 3.844   output scale: 4.016 \n",
      "Iter 106/500 - Loss: 2.669   lengthscale: 1.752   noise: 3.854   output scale: 4.032 \n",
      "Iter 107/500 - Loss: 2.668   lengthscale: 1.754   noise: 3.865   output scale: 4.048 \n",
      "Iter 108/500 - Loss: 2.667   lengthscale: 1.755   noise: 3.875   output scale: 4.063 \n",
      "Iter 109/500 - Loss: 2.666   lengthscale: 1.757   noise: 3.885   output scale: 4.078 \n",
      "Iter 110/500 - Loss: 2.665   lengthscale: 1.758   noise: 3.895   output scale: 4.094 \n",
      "Iter 111/500 - Loss: 2.664   lengthscale: 1.760   noise: 3.905   output scale: 4.109 \n",
      "Iter 112/500 - Loss: 2.663   lengthscale: 1.761   noise: 3.915   output scale: 4.124 \n",
      "Iter 113/500 - Loss: 2.662   lengthscale: 1.762   noise: 3.924   output scale: 4.140 \n",
      "Iter 114/500 - Loss: 2.661   lengthscale: 1.764   noise: 3.934   output scale: 4.155 \n",
      "Iter 115/500 - Loss: 2.660   lengthscale: 1.765   noise: 3.944   output scale: 4.170 \n",
      "Iter 116/500 - Loss: 2.659   lengthscale: 1.766   noise: 3.953   output scale: 4.185 \n",
      "Iter 117/500 - Loss: 2.658   lengthscale: 1.767   noise: 3.962   output scale: 4.200 \n",
      "Iter 118/500 - Loss: 2.657   lengthscale: 1.768   noise: 3.972   output scale: 4.215 \n",
      "Iter 119/500 - Loss: 2.656   lengthscale: 1.769   noise: 3.981   output scale: 4.229 \n",
      "Iter 120/500 - Loss: 2.655   lengthscale: 1.770   noise: 3.990   output scale: 4.244 \n",
      "Iter 121/500 - Loss: 2.654   lengthscale: 1.771   noise: 3.999   output scale: 4.259 \n",
      "Iter 122/500 - Loss: 2.653   lengthscale: 1.772   noise: 4.008   output scale: 4.274 \n",
      "Iter 123/500 - Loss: 2.652   lengthscale: 1.773   noise: 4.017   output scale: 4.288 \n",
      "Iter 124/500 - Loss: 2.651   lengthscale: 1.774   noise: 4.025   output scale: 4.303 \n",
      "Iter 125/500 - Loss: 2.650   lengthscale: 1.775   noise: 4.034   output scale: 4.317 \n",
      "Iter 126/500 - Loss: 2.650   lengthscale: 1.776   noise: 4.042   output scale: 4.332 \n",
      "Iter 127/500 - Loss: 2.649   lengthscale: 1.777   noise: 4.051   output scale: 4.346 \n",
      "Iter 128/500 - Loss: 2.648   lengthscale: 1.778   noise: 4.059   output scale: 4.360 \n",
      "Iter 129/500 - Loss: 2.647   lengthscale: 1.779   noise: 4.068   output scale: 4.375 \n",
      "Iter 130/500 - Loss: 2.646   lengthscale: 1.780   noise: 4.076   output scale: 4.389 \n",
      "Iter 131/500 - Loss: 2.645   lengthscale: 1.782   noise: 4.084   output scale: 4.403 \n",
      "Iter 132/500 - Loss: 2.645   lengthscale: 1.783   noise: 4.092   output scale: 4.417 \n",
      "Iter 133/500 - Loss: 2.644   lengthscale: 1.784   noise: 4.100   output scale: 4.431 \n",
      "Iter 134/500 - Loss: 2.643   lengthscale: 1.785   noise: 4.108   output scale: 4.445 \n",
      "Iter 135/500 - Loss: 2.642   lengthscale: 1.787   noise: 4.116   output scale: 4.459 \n",
      "Iter 136/500 - Loss: 2.642   lengthscale: 1.788   noise: 4.123   output scale: 4.473 \n",
      "Iter 137/500 - Loss: 2.641   lengthscale: 1.789   noise: 4.131   output scale: 4.487 \n",
      "Iter 138/500 - Loss: 2.640   lengthscale: 1.790   noise: 4.139   output scale: 4.501 \n",
      "Iter 139/500 - Loss: 2.639   lengthscale: 1.792   noise: 4.146   output scale: 4.515 \n",
      "Iter 140/500 - Loss: 2.639   lengthscale: 1.793   noise: 4.153   output scale: 4.528 \n",
      "Iter 141/500 - Loss: 2.638   lengthscale: 1.794   noise: 4.161   output scale: 4.542 \n",
      "Iter 142/500 - Loss: 2.637   lengthscale: 1.795   noise: 4.168   output scale: 4.556 \n",
      "Iter 143/500 - Loss: 2.637   lengthscale: 1.796   noise: 4.175   output scale: 4.569 \n",
      "Iter 144/500 - Loss: 2.636   lengthscale: 1.798   noise: 4.182   output scale: 4.583 \n",
      "Iter 145/500 - Loss: 2.635   lengthscale: 1.799   noise: 4.190   output scale: 4.597 \n",
      "Iter 146/500 - Loss: 2.635   lengthscale: 1.800   noise: 4.197   output scale: 4.610 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 147/500 - Loss: 2.634   lengthscale: 1.801   noise: 4.203   output scale: 4.624 \n",
      "Iter 148/500 - Loss: 2.633   lengthscale: 1.802   noise: 4.210   output scale: 4.637 \n",
      "Iter 149/500 - Loss: 2.633   lengthscale: 1.803   noise: 4.217   output scale: 4.650 \n",
      "Iter 150/500 - Loss: 2.632   lengthscale: 1.805   noise: 4.224   output scale: 4.664 \n",
      "Iter 151/500 - Loss: 2.632   lengthscale: 1.806   noise: 4.231   output scale: 4.677 \n",
      "Iter 152/500 - Loss: 2.631   lengthscale: 1.807   noise: 4.237   output scale: 4.690 \n",
      "Iter 153/500 - Loss: 2.630   lengthscale: 1.808   noise: 4.244   output scale: 4.703 \n",
      "Iter 154/500 - Loss: 2.630   lengthscale: 1.809   noise: 4.250   output scale: 4.717 \n",
      "Iter 155/500 - Loss: 2.629   lengthscale: 1.810   noise: 4.257   output scale: 4.730 \n",
      "Iter 156/500 - Loss: 2.629   lengthscale: 1.811   noise: 4.263   output scale: 4.743 \n",
      "Iter 157/500 - Loss: 2.628   lengthscale: 1.812   noise: 4.269   output scale: 4.756 \n",
      "Iter 158/500 - Loss: 2.627   lengthscale: 1.813   noise: 4.275   output scale: 4.769 \n",
      "Iter 159/500 - Loss: 2.627   lengthscale: 1.814   noise: 4.282   output scale: 4.782 \n",
      "Iter 160/500 - Loss: 2.626   lengthscale: 1.815   noise: 4.288   output scale: 4.795 \n",
      "Iter 161/500 - Loss: 2.626   lengthscale: 1.816   noise: 4.294   output scale: 4.808 \n",
      "Iter 162/500 - Loss: 2.625   lengthscale: 1.817   noise: 4.300   output scale: 4.821 \n",
      "Iter 163/500 - Loss: 2.625   lengthscale: 1.818   noise: 4.305   output scale: 4.833 \n",
      "Iter 164/500 - Loss: 2.624   lengthscale: 1.819   noise: 4.311   output scale: 4.846 \n",
      "Iter 165/500 - Loss: 2.624   lengthscale: 1.820   noise: 4.317   output scale: 4.859 \n",
      "Iter 166/500 - Loss: 2.623   lengthscale: 1.821   noise: 4.323   output scale: 4.872 \n",
      "Iter 167/500 - Loss: 2.623   lengthscale: 1.822   noise: 4.328   output scale: 4.884 \n",
      "Iter 168/500 - Loss: 2.622   lengthscale: 1.823   noise: 4.334   output scale: 4.897 \n",
      "Iter 169/500 - Loss: 2.622   lengthscale: 1.824   noise: 4.340   output scale: 4.910 \n",
      "Iter 170/500 - Loss: 2.621   lengthscale: 1.825   noise: 4.345   output scale: 4.922 \n",
      "Iter 171/500 - Loss: 2.621   lengthscale: 1.826   noise: 4.351   output scale: 4.935 \n",
      "Iter 172/500 - Loss: 2.620   lengthscale: 1.827   noise: 4.356   output scale: 4.947 \n",
      "Iter 173/500 - Loss: 2.620   lengthscale: 1.828   noise: 4.361   output scale: 4.960 \n",
      "Iter 174/500 - Loss: 2.619   lengthscale: 1.829   noise: 4.367   output scale: 4.972 \n",
      "Iter 175/500 - Loss: 2.619   lengthscale: 1.829   noise: 4.372   output scale: 4.985 \n",
      "Iter 176/500 - Loss: 2.618   lengthscale: 1.830   noise: 4.377   output scale: 4.997 \n",
      "Iter 177/500 - Loss: 2.618   lengthscale: 1.831   noise: 4.382   output scale: 5.010 \n",
      "Iter 178/500 - Loss: 2.617   lengthscale: 1.832   noise: 4.387   output scale: 5.022 \n",
      "Iter 179/500 - Loss: 2.617   lengthscale: 1.833   noise: 4.392   output scale: 5.034 \n",
      "Iter 180/500 - Loss: 2.616   lengthscale: 1.834   noise: 4.397   output scale: 5.047 \n",
      "Iter 181/500 - Loss: 2.616   lengthscale: 1.835   noise: 4.402   output scale: 5.059 \n",
      "Iter 182/500 - Loss: 2.616   lengthscale: 1.836   noise: 4.407   output scale: 5.071 \n",
      "Iter 183/500 - Loss: 2.615   lengthscale: 1.837   noise: 4.411   output scale: 5.083 \n",
      "Iter 184/500 - Loss: 2.615   lengthscale: 1.838   noise: 4.416   output scale: 5.096 \n",
      "Iter 185/500 - Loss: 2.614   lengthscale: 1.839   noise: 4.421   output scale: 5.108 \n",
      "Iter 186/500 - Loss: 2.614   lengthscale: 1.840   noise: 4.425   output scale: 5.120 \n",
      "Iter 187/500 - Loss: 2.613   lengthscale: 1.841   noise: 4.430   output scale: 5.132 \n",
      "Iter 188/500 - Loss: 2.613   lengthscale: 1.842   noise: 4.435   output scale: 5.144 \n",
      "Iter 189/500 - Loss: 2.613   lengthscale: 1.842   noise: 4.439   output scale: 5.156 \n",
      "Iter 190/500 - Loss: 2.612   lengthscale: 1.843   noise: 4.443   output scale: 5.168 \n",
      "Iter 191/500 - Loss: 2.612   lengthscale: 1.844   noise: 4.448   output scale: 5.180 \n",
      "Iter 192/500 - Loss: 2.611   lengthscale: 1.845   noise: 4.452   output scale: 5.192 \n",
      "Iter 193/500 - Loss: 2.611   lengthscale: 1.846   noise: 4.456   output scale: 5.204 \n",
      "Iter 194/500 - Loss: 2.611   lengthscale: 1.847   noise: 4.461   output scale: 5.216 \n",
      "Iter 195/500 - Loss: 2.610   lengthscale: 1.848   noise: 4.465   output scale: 5.228 \n",
      "Iter 196/500 - Loss: 2.610   lengthscale: 1.849   noise: 4.469   output scale: 5.239 \n",
      "Iter 197/500 - Loss: 2.609   lengthscale: 1.849   noise: 4.473   output scale: 5.251 \n",
      "Iter 198/500 - Loss: 2.609   lengthscale: 1.850   noise: 4.477   output scale: 5.263 \n",
      "Iter 199/500 - Loss: 2.609   lengthscale: 1.851   noise: 4.481   output scale: 5.275 \n",
      "Iter 200/500 - Loss: 2.608   lengthscale: 1.852   noise: 4.485   output scale: 5.287 \n",
      "Iter 201/500 - Loss: 2.608   lengthscale: 1.853   noise: 4.489   output scale: 5.298 \n",
      "Iter 202/500 - Loss: 2.608   lengthscale: 1.854   noise: 4.493   output scale: 5.310 \n",
      "Iter 203/500 - Loss: 2.607   lengthscale: 1.854   noise: 4.496   output scale: 5.322 \n",
      "Iter 204/500 - Loss: 2.607   lengthscale: 1.855   noise: 4.500   output scale: 5.333 \n",
      "Iter 205/500 - Loss: 2.607   lengthscale: 1.856   noise: 4.504   output scale: 5.345 \n",
      "Iter 206/500 - Loss: 2.606   lengthscale: 1.857   noise: 4.507   output scale: 5.357 \n",
      "Iter 207/500 - Loss: 2.606   lengthscale: 1.858   noise: 4.511   output scale: 5.368 \n",
      "Iter 208/500 - Loss: 2.606   lengthscale: 1.858   noise: 4.515   output scale: 5.380 \n",
      "Iter 209/500 - Loss: 2.605   lengthscale: 1.859   noise: 4.518   output scale: 5.391 \n",
      "Iter 210/500 - Loss: 2.605   lengthscale: 1.860   noise: 4.522   output scale: 5.403 \n",
      "Iter 211/500 - Loss: 2.604   lengthscale: 1.861   noise: 4.525   output scale: 5.414 \n",
      "Iter 212/500 - Loss: 2.604   lengthscale: 1.862   noise: 4.528   output scale: 5.426 \n",
      "Iter 213/500 - Loss: 2.604   lengthscale: 1.862   noise: 4.532   output scale: 5.437 \n",
      "Iter 214/500 - Loss: 2.603   lengthscale: 1.863   noise: 4.535   output scale: 5.449 \n",
      "Iter 215/500 - Loss: 2.603   lengthscale: 1.864   noise: 4.538   output scale: 5.460 \n",
      "Iter 216/500 - Loss: 2.603   lengthscale: 1.865   noise: 4.542   output scale: 5.471 \n",
      "Iter 217/500 - Loss: 2.603   lengthscale: 1.866   noise: 4.545   output scale: 5.483 \n",
      "Iter 218/500 - Loss: 2.602   lengthscale: 1.866   noise: 4.548   output scale: 5.494 \n",
      "Iter 219/500 - Loss: 2.602   lengthscale: 1.867   noise: 4.551   output scale: 5.505 \n",
      "Iter 220/500 - Loss: 2.602   lengthscale: 1.868   noise: 4.554   output scale: 5.517 \n",
      "Iter 221/500 - Loss: 2.601   lengthscale: 1.869   noise: 4.557   output scale: 5.528 \n",
      "Iter 222/500 - Loss: 2.601   lengthscale: 1.869   noise: 4.560   output scale: 5.539 \n",
      "Iter 223/500 - Loss: 2.601   lengthscale: 1.870   noise: 4.563   output scale: 5.551 \n",
      "Iter 224/500 - Loss: 2.600   lengthscale: 1.871   noise: 4.566   output scale: 5.562 \n",
      "Iter 225/500 - Loss: 2.600   lengthscale: 1.872   noise: 4.569   output scale: 5.573 \n",
      "Iter 226/500 - Loss: 2.600   lengthscale: 1.872   noise: 4.571   output scale: 5.584 \n",
      "Iter 227/500 - Loss: 2.599   lengthscale: 1.873   noise: 4.574   output scale: 5.595 \n",
      "Iter 228/500 - Loss: 2.599   lengthscale: 1.874   noise: 4.577   output scale: 5.606 \n",
      "Iter 229/500 - Loss: 2.599   lengthscale: 1.875   noise: 4.580   output scale: 5.618 \n",
      "Iter 230/500 - Loss: 2.599   lengthscale: 1.875   noise: 4.582   output scale: 5.629 \n",
      "Iter 231/500 - Loss: 2.598   lengthscale: 1.876   noise: 4.585   output scale: 5.640 \n",
      "Iter 232/500 - Loss: 2.598   lengthscale: 1.877   noise: 4.587   output scale: 5.651 \n",
      "Iter 233/500 - Loss: 2.598   lengthscale: 1.878   noise: 4.590   output scale: 5.662 \n",
      "Iter 234/500 - Loss: 2.597   lengthscale: 1.878   noise: 4.592   output scale: 5.673 \n",
      "Iter 235/500 - Loss: 2.597   lengthscale: 1.879   noise: 4.595   output scale: 5.684 \n",
      "Iter 236/500 - Loss: 2.597   lengthscale: 1.880   noise: 4.597   output scale: 5.695 \n",
      "Iter 237/500 - Loss: 2.597   lengthscale: 1.880   noise: 4.600   output scale: 5.706 \n",
      "Iter 238/500 - Loss: 2.596   lengthscale: 1.881   noise: 4.602   output scale: 5.717 \n",
      "Iter 239/500 - Loss: 2.596   lengthscale: 1.882   noise: 4.604   output scale: 5.728 \n",
      "Iter 240/500 - Loss: 2.596   lengthscale: 1.883   noise: 4.607   output scale: 5.739 \n",
      "Iter 241/500 - Loss: 2.595   lengthscale: 1.883   noise: 4.609   output scale: 5.750 \n",
      "Iter 242/500 - Loss: 2.595   lengthscale: 1.884   noise: 4.611   output scale: 5.760 \n",
      "Iter 243/500 - Loss: 2.595   lengthscale: 1.885   noise: 4.613   output scale: 5.771 \n",
      "Iter 244/500 - Loss: 2.595   lengthscale: 1.885   noise: 4.615   output scale: 5.782 \n",
      "Iter 245/500 - Loss: 2.594   lengthscale: 1.886   noise: 4.617   output scale: 5.793 \n",
      "Iter 246/500 - Loss: 2.594   lengthscale: 1.887   noise: 4.619   output scale: 5.804 \n",
      "Iter 247/500 - Loss: 2.594   lengthscale: 1.887   noise: 4.621   output scale: 5.815 \n",
      "Iter 248/500 - Loss: 2.594   lengthscale: 1.888   noise: 4.623   output scale: 5.825 \n",
      "Iter 249/500 - Loss: 2.593   lengthscale: 1.889   noise: 4.625   output scale: 5.836 \n",
      "Iter 250/500 - Loss: 2.593   lengthscale: 1.889   noise: 4.627   output scale: 5.847 \n",
      "Iter 251/500 - Loss: 2.593   lengthscale: 1.890   noise: 4.629   output scale: 5.858 \n",
      "Iter 252/500 - Loss: 2.593   lengthscale: 1.891   noise: 4.631   output scale: 5.868 \n",
      "Iter 253/500 - Loss: 2.592   lengthscale: 1.891   noise: 4.633   output scale: 5.879 \n",
      "Iter 254/500 - Loss: 2.592   lengthscale: 1.892   noise: 4.634   output scale: 5.890 \n",
      "Iter 255/500 - Loss: 2.592   lengthscale: 1.893   noise: 4.636   output scale: 5.900 \n",
      "Iter 256/500 - Loss: 2.592   lengthscale: 1.893   noise: 4.638   output scale: 5.911 \n",
      "Iter 257/500 - Loss: 2.591   lengthscale: 1.894   noise: 4.639   output scale: 5.922 \n",
      "Iter 258/500 - Loss: 2.591   lengthscale: 1.895   noise: 4.641   output scale: 5.932 \n",
      "Iter 259/500 - Loss: 2.591   lengthscale: 1.895   noise: 4.643   output scale: 5.943 \n",
      "Iter 260/500 - Loss: 2.591   lengthscale: 1.896   noise: 4.644   output scale: 5.953 \n",
      "Iter 261/500 - Loss: 2.590   lengthscale: 1.897   noise: 4.646   output scale: 5.964 \n",
      "Iter 262/500 - Loss: 2.590   lengthscale: 1.897   noise: 4.647   output scale: 5.975 \n",
      "Iter 263/500 - Loss: 2.590   lengthscale: 1.898   noise: 4.649   output scale: 5.985 \n",
      "Iter 264/500 - Loss: 2.590   lengthscale: 1.898   noise: 4.650   output scale: 5.996 \n",
      "Iter 265/500 - Loss: 2.589   lengthscale: 1.899   noise: 4.651   output scale: 6.006 \n",
      "Iter 266/500 - Loss: 2.589   lengthscale: 1.900   noise: 4.653   output scale: 6.017 \n",
      "Iter 267/500 - Loss: 2.589   lengthscale: 1.900   noise: 4.654   output scale: 6.027 \n",
      "Iter 268/500 - Loss: 2.589   lengthscale: 1.901   noise: 4.655   output scale: 6.038 \n",
      "Iter 269/500 - Loss: 2.588   lengthscale: 1.902   noise: 4.657   output scale: 6.048 \n",
      "Iter 270/500 - Loss: 2.588   lengthscale: 1.902   noise: 4.658   output scale: 6.059 \n",
      "Iter 271/500 - Loss: 2.588   lengthscale: 1.903   noise: 4.659   output scale: 6.069 \n",
      "Iter 272/500 - Loss: 2.588   lengthscale: 1.903   noise: 4.660   output scale: 6.079 \n",
      "Iter 273/500 - Loss: 2.588   lengthscale: 1.904   noise: 4.661   output scale: 6.090 \n",
      "Iter 274/500 - Loss: 2.587   lengthscale: 1.905   noise: 4.662   output scale: 6.100 \n",
      "Iter 275/500 - Loss: 2.587   lengthscale: 1.905   noise: 4.663   output scale: 6.111 \n",
      "Iter 276/500 - Loss: 2.587   lengthscale: 1.906   noise: 4.664   output scale: 6.121 \n",
      "Iter 277/500 - Loss: 2.587   lengthscale: 1.906   noise: 4.665   output scale: 6.131 \n",
      "Iter 278/500 - Loss: 2.586   lengthscale: 1.907   noise: 4.666   output scale: 6.142 \n",
      "Iter 279/500 - Loss: 2.586   lengthscale: 1.908   noise: 4.667   output scale: 6.152 \n",
      "Iter 280/500 - Loss: 2.586   lengthscale: 1.908   noise: 4.668   output scale: 6.162 \n",
      "Iter 281/500 - Loss: 2.586   lengthscale: 1.909   noise: 4.669   output scale: 6.173 \n",
      "Iter 282/500 - Loss: 2.586   lengthscale: 1.909   noise: 4.670   output scale: 6.183 \n",
      "Iter 283/500 - Loss: 2.585   lengthscale: 1.910   noise: 4.671   output scale: 6.193 \n",
      "Iter 284/500 - Loss: 2.585   lengthscale: 1.910   noise: 4.672   output scale: 6.203 \n",
      "Iter 285/500 - Loss: 2.585   lengthscale: 1.911   noise: 4.672   output scale: 6.214 \n",
      "Iter 286/500 - Loss: 2.585   lengthscale: 1.912   noise: 4.673   output scale: 6.224 \n",
      "Iter 287/500 - Loss: 2.584   lengthscale: 1.912   noise: 4.674   output scale: 6.234 \n",
      "Iter 288/500 - Loss: 2.584   lengthscale: 1.913   noise: 4.674   output scale: 6.244 \n",
      "Iter 289/500 - Loss: 2.584   lengthscale: 1.913   noise: 4.675   output scale: 6.255 \n",
      "Iter 290/500 - Loss: 2.584   lengthscale: 1.914   noise: 4.676   output scale: 6.265 \n",
      "Iter 291/500 - Loss: 2.584   lengthscale: 1.914   noise: 4.676   output scale: 6.275 \n",
      "Iter 292/500 - Loss: 2.583   lengthscale: 1.915   noise: 4.677   output scale: 6.285 \n",
      "Iter 293/500 - Loss: 2.583   lengthscale: 1.916   noise: 4.677   output scale: 6.295 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 294/500 - Loss: 2.583   lengthscale: 1.916   noise: 4.678   output scale: 6.306 \n",
      "Iter 295/500 - Loss: 2.583   lengthscale: 1.917   noise: 4.678   output scale: 6.316 \n",
      "Iter 296/500 - Loss: 2.583   lengthscale: 1.917   noise: 4.679   output scale: 6.326 \n",
      "Iter 297/500 - Loss: 2.582   lengthscale: 1.918   noise: 4.679   output scale: 6.336 \n",
      "Iter 298/500 - Loss: 2.582   lengthscale: 1.918   noise: 4.679   output scale: 6.346 \n",
      "Iter 299/500 - Loss: 2.582   lengthscale: 1.919   noise: 4.680   output scale: 6.356 \n",
      "Iter 300/500 - Loss: 2.582   lengthscale: 1.919   noise: 4.680   output scale: 6.366 \n",
      "Iter 301/500 - Loss: 2.582   lengthscale: 1.920   noise: 4.680   output scale: 6.376 \n",
      "Iter 302/500 - Loss: 2.581   lengthscale: 1.920   noise: 4.681   output scale: 6.386 \n",
      "Iter 303/500 - Loss: 2.581   lengthscale: 1.921   noise: 4.681   output scale: 6.396 \n",
      "Iter 304/500 - Loss: 2.581   lengthscale: 1.921   noise: 4.681   output scale: 6.406 \n",
      "Iter 305/500 - Loss: 2.581   lengthscale: 1.922   noise: 4.681   output scale: 6.416 \n",
      "Iter 306/500 - Loss: 2.581   lengthscale: 1.922   noise: 4.681   output scale: 6.426 \n",
      "Iter 307/500 - Loss: 2.580   lengthscale: 1.923   noise: 4.681   output scale: 6.436 \n",
      "Iter 308/500 - Loss: 2.580   lengthscale: 1.924   noise: 4.682   output scale: 6.446 \n",
      "Iter 309/500 - Loss: 2.580   lengthscale: 1.924   noise: 4.682   output scale: 6.456 \n",
      "Iter 310/500 - Loss: 2.580   lengthscale: 1.925   noise: 4.682   output scale: 6.466 \n",
      "Iter 311/500 - Loss: 2.580   lengthscale: 1.925   noise: 4.682   output scale: 6.476 \n",
      "Iter 312/500 - Loss: 2.579   lengthscale: 1.926   noise: 4.682   output scale: 6.486 \n",
      "Iter 313/500 - Loss: 2.579   lengthscale: 1.926   noise: 4.682   output scale: 6.496 \n",
      "Iter 314/500 - Loss: 2.579   lengthscale: 1.927   noise: 4.682   output scale: 6.506 \n",
      "Iter 315/500 - Loss: 2.579   lengthscale: 1.927   noise: 4.681   output scale: 6.516 \n",
      "Iter 316/500 - Loss: 2.579   lengthscale: 1.928   noise: 4.681   output scale: 6.526 \n",
      "Iter 317/500 - Loss: 2.578   lengthscale: 1.928   noise: 4.681   output scale: 6.536 \n",
      "Iter 318/500 - Loss: 2.578   lengthscale: 1.929   noise: 4.681   output scale: 6.546 \n",
      "Iter 319/500 - Loss: 2.578   lengthscale: 1.929   noise: 4.681   output scale: 6.556 \n",
      "Iter 320/500 - Loss: 2.578   lengthscale: 1.929   noise: 4.681   output scale: 6.566 \n",
      "Iter 321/500 - Loss: 2.578   lengthscale: 1.930   noise: 4.680   output scale: 6.576 \n",
      "Iter 322/500 - Loss: 2.578   lengthscale: 1.930   noise: 4.680   output scale: 6.585 \n",
      "Iter 323/500 - Loss: 2.577   lengthscale: 1.931   noise: 4.680   output scale: 6.595 \n",
      "Iter 324/500 - Loss: 2.577   lengthscale: 1.931   noise: 4.679   output scale: 6.605 \n",
      "Iter 325/500 - Loss: 2.577   lengthscale: 1.932   noise: 4.679   output scale: 6.615 \n",
      "Iter 326/500 - Loss: 2.577   lengthscale: 1.932   noise: 4.679   output scale: 6.625 \n",
      "Iter 327/500 - Loss: 2.577   lengthscale: 1.933   noise: 4.678   output scale: 6.635 \n",
      "Iter 328/500 - Loss: 2.576   lengthscale: 1.933   noise: 4.678   output scale: 6.644 \n",
      "Iter 329/500 - Loss: 2.576   lengthscale: 1.934   noise: 4.677   output scale: 6.654 \n",
      "Iter 330/500 - Loss: 2.576   lengthscale: 1.934   noise: 4.677   output scale: 6.664 \n",
      "Iter 331/500 - Loss: 2.576   lengthscale: 1.935   noise: 4.676   output scale: 6.674 \n",
      "Iter 332/500 - Loss: 2.576   lengthscale: 1.935   noise: 4.676   output scale: 6.684 \n",
      "Iter 333/500 - Loss: 2.576   lengthscale: 1.936   noise: 4.675   output scale: 6.693 \n",
      "Iter 334/500 - Loss: 2.575   lengthscale: 1.936   noise: 4.675   output scale: 6.703 \n",
      "Iter 335/500 - Loss: 2.575   lengthscale: 1.937   noise: 4.674   output scale: 6.713 \n",
      "Iter 336/500 - Loss: 2.575   lengthscale: 1.937   noise: 4.674   output scale: 6.723 \n",
      "Iter 337/500 - Loss: 2.575   lengthscale: 1.937   noise: 4.673   output scale: 6.732 \n",
      "Iter 338/500 - Loss: 2.575   lengthscale: 1.938   noise: 4.672   output scale: 6.742 \n",
      "Iter 339/500 - Loss: 2.575   lengthscale: 1.938   noise: 4.672   output scale: 6.752 \n",
      "Iter 340/500 - Loss: 2.574   lengthscale: 1.939   noise: 4.671   output scale: 6.762 \n",
      "Iter 341/500 - Loss: 2.574   lengthscale: 1.939   noise: 4.670   output scale: 6.771 \n",
      "Iter 342/500 - Loss: 2.574   lengthscale: 1.940   noise: 4.669   output scale: 6.781 \n",
      "Iter 343/500 - Loss: 2.574   lengthscale: 1.940   noise: 4.669   output scale: 6.791 \n",
      "Iter 344/500 - Loss: 2.574   lengthscale: 1.940   noise: 4.668   output scale: 6.800 \n",
      "Iter 345/500 - Loss: 2.573   lengthscale: 1.941   noise: 4.667   output scale: 6.810 \n",
      "Iter 346/500 - Loss: 2.573   lengthscale: 1.941   noise: 4.666   output scale: 6.820 \n",
      "Iter 347/500 - Loss: 2.573   lengthscale: 1.942   noise: 4.665   output scale: 6.829 \n",
      "Iter 348/500 - Loss: 2.573   lengthscale: 1.942   noise: 4.664   output scale: 6.839 \n",
      "Iter 349/500 - Loss: 2.573   lengthscale: 1.943   noise: 4.663   output scale: 6.849 \n",
      "Iter 350/500 - Loss: 2.573   lengthscale: 1.943   noise: 4.662   output scale: 6.858 \n",
      "Iter 351/500 - Loss: 2.572   lengthscale: 1.943   noise: 4.661   output scale: 6.868 \n",
      "Iter 352/500 - Loss: 2.572   lengthscale: 1.944   noise: 4.660   output scale: 6.878 \n",
      "Iter 353/500 - Loss: 2.572   lengthscale: 1.944   noise: 4.659   output scale: 6.887 \n",
      "Iter 354/500 - Loss: 2.572   lengthscale: 1.945   noise: 4.658   output scale: 6.897 \n",
      "Iter 355/500 - Loss: 2.572   lengthscale: 1.945   noise: 4.657   output scale: 6.906 \n",
      "Iter 356/500 - Loss: 2.572   lengthscale: 1.946   noise: 4.656   output scale: 6.916 \n",
      "Iter 357/500 - Loss: 2.571   lengthscale: 1.946   noise: 4.655   output scale: 6.926 \n",
      "Iter 358/500 - Loss: 2.571   lengthscale: 1.946   noise: 4.654   output scale: 6.935 \n",
      "Iter 359/500 - Loss: 2.571   lengthscale: 1.947   noise: 4.653   output scale: 6.945 \n",
      "Iter 360/500 - Loss: 2.571   lengthscale: 1.947   noise: 4.652   output scale: 6.954 \n",
      "Iter 361/500 - Loss: 2.571   lengthscale: 1.948   noise: 4.650   output scale: 6.964 \n",
      "Iter 362/500 - Loss: 2.571   lengthscale: 1.948   noise: 4.649   output scale: 6.974 \n",
      "Iter 363/500 - Loss: 2.570   lengthscale: 1.948   noise: 4.648   output scale: 6.983 \n",
      "Iter 364/500 - Loss: 2.570   lengthscale: 1.949   noise: 4.647   output scale: 6.993 \n",
      "Iter 365/500 - Loss: 2.570   lengthscale: 1.949   noise: 4.645   output scale: 7.002 \n",
      "Iter 366/500 - Loss: 2.570   lengthscale: 1.949   noise: 4.644   output scale: 7.012 \n",
      "Iter 367/500 - Loss: 2.570   lengthscale: 1.950   noise: 4.643   output scale: 7.021 \n",
      "Iter 368/500 - Loss: 2.570   lengthscale: 1.950   noise: 4.642   output scale: 7.031 \n",
      "Iter 369/500 - Loss: 2.569   lengthscale: 1.951   noise: 4.640   output scale: 7.040 \n",
      "Iter 370/500 - Loss: 2.569   lengthscale: 1.951   noise: 4.639   output scale: 7.050 \n",
      "Iter 371/500 - Loss: 2.569   lengthscale: 1.951   noise: 4.637   output scale: 7.059 \n",
      "Iter 372/500 - Loss: 2.569   lengthscale: 1.952   noise: 4.636   output scale: 7.069 \n",
      "Iter 373/500 - Loss: 2.569   lengthscale: 1.952   noise: 4.634   output scale: 7.078 \n",
      "Iter 374/500 - Loss: 2.569   lengthscale: 1.952   noise: 4.633   output scale: 7.088 \n",
      "Iter 375/500 - Loss: 2.568   lengthscale: 1.953   noise: 4.632   output scale: 7.097 \n",
      "Iter 376/500 - Loss: 2.568   lengthscale: 1.953   noise: 4.630   output scale: 7.107 \n",
      "Iter 377/500 - Loss: 2.568   lengthscale: 1.954   noise: 4.628   output scale: 7.116 \n",
      "Iter 378/500 - Loss: 2.568   lengthscale: 1.954   noise: 4.627   output scale: 7.126 \n",
      "Iter 379/500 - Loss: 2.568   lengthscale: 1.954   noise: 4.625   output scale: 7.135 \n",
      "Iter 380/500 - Loss: 2.568   lengthscale: 1.955   noise: 4.624   output scale: 7.145 \n",
      "Iter 381/500 - Loss: 2.568   lengthscale: 1.955   noise: 4.622   output scale: 7.154 \n",
      "Iter 382/500 - Loss: 2.567   lengthscale: 1.955   noise: 4.621   output scale: 7.163 \n",
      "Iter 383/500 - Loss: 2.567   lengthscale: 1.956   noise: 4.619   output scale: 7.173 \n",
      "Iter 384/500 - Loss: 2.567   lengthscale: 1.956   noise: 4.617   output scale: 7.182 \n",
      "Iter 385/500 - Loss: 2.567   lengthscale: 1.956   noise: 4.616   output scale: 7.192 \n",
      "Iter 386/500 - Loss: 2.567   lengthscale: 1.957   noise: 4.614   output scale: 7.201 \n",
      "Iter 387/500 - Loss: 2.567   lengthscale: 1.957   noise: 4.612   output scale: 7.211 \n",
      "Iter 388/500 - Loss: 2.566   lengthscale: 1.957   noise: 4.610   output scale: 7.220 \n",
      "Iter 389/500 - Loss: 2.566   lengthscale: 1.958   noise: 4.609   output scale: 7.229 \n",
      "Iter 390/500 - Loss: 2.566   lengthscale: 1.958   noise: 4.607   output scale: 7.239 \n",
      "Iter 391/500 - Loss: 2.566   lengthscale: 1.958   noise: 4.605   output scale: 7.248 \n",
      "Iter 392/500 - Loss: 2.566   lengthscale: 1.959   noise: 4.603   output scale: 7.258 \n",
      "Iter 393/500 - Loss: 2.566   lengthscale: 1.959   noise: 4.601   output scale: 7.267 \n",
      "Iter 394/500 - Loss: 2.565   lengthscale: 1.959   noise: 4.600   output scale: 7.276 \n",
      "Iter 395/500 - Loss: 2.565   lengthscale: 1.960   noise: 4.598   output scale: 7.286 \n",
      "Iter 396/500 - Loss: 2.565   lengthscale: 1.960   noise: 4.596   output scale: 7.295 \n",
      "Iter 397/500 - Loss: 2.565   lengthscale: 1.960   noise: 4.594   output scale: 7.305 \n",
      "Iter 398/500 - Loss: 2.565   lengthscale: 1.961   noise: 4.592   output scale: 7.314 \n",
      "Iter 399/500 - Loss: 2.565   lengthscale: 1.961   noise: 4.590   output scale: 7.323 \n",
      "Iter 400/500 - Loss: 2.565   lengthscale: 1.961   noise: 4.588   output scale: 7.333 \n",
      "Iter 401/500 - Loss: 2.564   lengthscale: 1.962   noise: 4.586   output scale: 7.342 \n",
      "Iter 402/500 - Loss: 2.564   lengthscale: 1.962   noise: 4.584   output scale: 7.351 \n",
      "Iter 403/500 - Loss: 2.564   lengthscale: 1.962   noise: 4.582   output scale: 7.361 \n",
      "Iter 404/500 - Loss: 2.564   lengthscale: 1.963   noise: 4.580   output scale: 7.370 \n",
      "Iter 405/500 - Loss: 2.564   lengthscale: 1.963   noise: 4.578   output scale: 7.379 \n",
      "Iter 406/500 - Loss: 2.564   lengthscale: 1.963   noise: 4.576   output scale: 7.389 \n",
      "Iter 407/500 - Loss: 2.563   lengthscale: 1.964   noise: 4.574   output scale: 7.398 \n",
      "Iter 408/500 - Loss: 2.563   lengthscale: 1.964   noise: 4.572   output scale: 7.407 \n",
      "Iter 409/500 - Loss: 2.563   lengthscale: 1.964   noise: 4.569   output scale: 7.417 \n",
      "Iter 410/500 - Loss: 2.563   lengthscale: 1.964   noise: 4.567   output scale: 7.426 \n",
      "Iter 411/500 - Loss: 2.563   lengthscale: 1.965   noise: 4.565   output scale: 7.435 \n",
      "Iter 412/500 - Loss: 2.563   lengthscale: 1.965   noise: 4.563   output scale: 7.445 \n",
      "Iter 413/500 - Loss: 2.563   lengthscale: 1.965   noise: 4.561   output scale: 7.454 \n",
      "Iter 414/500 - Loss: 2.562   lengthscale: 1.966   noise: 4.558   output scale: 7.463 \n",
      "Iter 415/500 - Loss: 2.562   lengthscale: 1.966   noise: 4.556   output scale: 7.472 \n",
      "Iter 416/500 - Loss: 2.562   lengthscale: 1.966   noise: 4.554   output scale: 7.482 \n",
      "Iter 417/500 - Loss: 2.562   lengthscale: 1.966   noise: 4.552   output scale: 7.491 \n",
      "Iter 418/500 - Loss: 2.562   lengthscale: 1.967   noise: 4.549   output scale: 7.500 \n",
      "Iter 419/500 - Loss: 2.562   lengthscale: 1.967   noise: 4.547   output scale: 7.510 \n",
      "Iter 420/500 - Loss: 2.562   lengthscale: 1.967   noise: 4.545   output scale: 7.519 \n",
      "Iter 421/500 - Loss: 2.561   lengthscale: 1.968   noise: 4.542   output scale: 7.528 \n",
      "Iter 422/500 - Loss: 2.561   lengthscale: 1.968   noise: 4.540   output scale: 7.537 \n",
      "Iter 423/500 - Loss: 2.561   lengthscale: 1.968   noise: 4.538   output scale: 7.547 \n",
      "Iter 424/500 - Loss: 2.561   lengthscale: 1.968   noise: 4.535   output scale: 7.556 \n",
      "Iter 425/500 - Loss: 2.561   lengthscale: 1.969   noise: 4.533   output scale: 7.565 \n",
      "Iter 426/500 - Loss: 2.561   lengthscale: 1.969   noise: 4.531   output scale: 7.574 \n",
      "Iter 427/500 - Loss: 2.560   lengthscale: 1.969   noise: 4.528   output scale: 7.584 \n",
      "Iter 428/500 - Loss: 2.560   lengthscale: 1.969   noise: 4.526   output scale: 7.593 \n",
      "Iter 429/500 - Loss: 2.560   lengthscale: 1.970   noise: 4.523   output scale: 7.602 \n",
      "Iter 430/500 - Loss: 2.560   lengthscale: 1.970   noise: 4.521   output scale: 7.611 \n",
      "Iter 431/500 - Loss: 2.560   lengthscale: 1.970   noise: 4.518   output scale: 7.621 \n",
      "Iter 432/500 - Loss: 2.560   lengthscale: 1.971   noise: 4.516   output scale: 7.630 \n",
      "Iter 433/500 - Loss: 2.560   lengthscale: 1.971   noise: 4.513   output scale: 7.639 \n",
      "Iter 434/500 - Loss: 2.559   lengthscale: 1.971   noise: 4.511   output scale: 7.648 \n",
      "Iter 435/500 - Loss: 2.559   lengthscale: 1.971   noise: 4.508   output scale: 7.658 \n",
      "Iter 436/500 - Loss: 2.559   lengthscale: 1.972   noise: 4.505   output scale: 7.667 \n",
      "Iter 437/500 - Loss: 2.559   lengthscale: 1.972   noise: 4.503   output scale: 7.676 \n",
      "Iter 438/500 - Loss: 2.559   lengthscale: 1.972   noise: 4.500   output scale: 7.685 \n",
      "Iter 439/500 - Loss: 2.559   lengthscale: 1.972   noise: 4.498   output scale: 7.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440/500 - Loss: 2.559   lengthscale: 1.973   noise: 4.495   output scale: 7.704 \n",
      "Iter 441/500 - Loss: 2.558   lengthscale: 1.973   noise: 4.492   output scale: 7.713 \n",
      "Iter 442/500 - Loss: 2.558   lengthscale: 1.973   noise: 4.490   output scale: 7.722 \n",
      "Iter 443/500 - Loss: 2.558   lengthscale: 1.973   noise: 4.487   output scale: 7.731 \n",
      "Iter 444/500 - Loss: 2.558   lengthscale: 1.973   noise: 4.484   output scale: 7.740 \n",
      "Iter 445/500 - Loss: 2.558   lengthscale: 1.974   noise: 4.482   output scale: 7.750 \n",
      "Iter 446/500 - Loss: 2.558   lengthscale: 1.974   noise: 4.479   output scale: 7.759 \n",
      "Iter 447/500 - Loss: 2.558   lengthscale: 1.974   noise: 4.476   output scale: 7.768 \n",
      "Iter 448/500 - Loss: 2.557   lengthscale: 1.974   noise: 4.473   output scale: 7.777 \n",
      "Iter 449/500 - Loss: 2.557   lengthscale: 1.975   noise: 4.471   output scale: 7.786 \n",
      "Iter 450/500 - Loss: 2.557   lengthscale: 1.975   noise: 4.468   output scale: 7.796 \n",
      "Iter 451/500 - Loss: 2.557   lengthscale: 1.975   noise: 4.465   output scale: 7.805 \n",
      "Iter 452/500 - Loss: 2.557   lengthscale: 1.975   noise: 4.462   output scale: 7.814 \n",
      "Iter 453/500 - Loss: 2.557   lengthscale: 1.976   noise: 4.459   output scale: 7.823 \n",
      "Iter 454/500 - Loss: 2.557   lengthscale: 1.976   noise: 4.457   output scale: 7.832 \n",
      "Iter 455/500 - Loss: 2.556   lengthscale: 1.976   noise: 4.454   output scale: 7.841 \n",
      "Iter 456/500 - Loss: 2.556   lengthscale: 1.976   noise: 4.451   output scale: 7.851 \n",
      "Iter 457/500 - Loss: 2.556   lengthscale: 1.976   noise: 4.448   output scale: 7.860 \n",
      "Iter 458/500 - Loss: 2.556   lengthscale: 1.977   noise: 4.445   output scale: 7.869 \n",
      "Iter 459/500 - Loss: 2.556   lengthscale: 1.977   noise: 4.442   output scale: 7.878 \n",
      "Iter 460/500 - Loss: 2.556   lengthscale: 1.977   noise: 4.439   output scale: 7.887 \n",
      "Iter 461/500 - Loss: 2.556   lengthscale: 1.977   noise: 4.436   output scale: 7.896 \n",
      "Iter 462/500 - Loss: 2.555   lengthscale: 1.977   noise: 4.433   output scale: 7.906 \n",
      "Iter 463/500 - Loss: 2.555   lengthscale: 1.978   noise: 4.430   output scale: 7.915 \n",
      "Iter 464/500 - Loss: 2.555   lengthscale: 1.978   noise: 4.427   output scale: 7.924 \n",
      "Iter 465/500 - Loss: 2.555   lengthscale: 1.978   noise: 4.424   output scale: 7.933 \n",
      "Iter 466/500 - Loss: 2.555   lengthscale: 1.978   noise: 4.421   output scale: 7.942 \n",
      "Iter 467/500 - Loss: 2.555   lengthscale: 1.978   noise: 4.418   output scale: 7.951 \n",
      "Iter 468/500 - Loss: 2.555   lengthscale: 1.979   noise: 4.415   output scale: 7.960 \n",
      "Iter 469/500 - Loss: 2.554   lengthscale: 1.979   noise: 4.412   output scale: 7.970 \n",
      "Iter 470/500 - Loss: 2.554   lengthscale: 1.979   noise: 4.409   output scale: 7.979 \n",
      "Iter 471/500 - Loss: 2.554   lengthscale: 1.979   noise: 4.406   output scale: 7.988 \n",
      "Iter 472/500 - Loss: 2.554   lengthscale: 1.979   noise: 4.403   output scale: 7.997 \n",
      "Iter 473/500 - Loss: 2.554   lengthscale: 1.980   noise: 4.400   output scale: 8.006 \n",
      "Iter 474/500 - Loss: 2.554   lengthscale: 1.980   noise: 4.397   output scale: 8.015 \n",
      "Iter 475/500 - Loss: 2.554   lengthscale: 1.980   noise: 4.394   output scale: 8.024 \n",
      "Iter 476/500 - Loss: 2.553   lengthscale: 1.980   noise: 4.391   output scale: 8.034 \n",
      "Iter 477/500 - Loss: 2.553   lengthscale: 1.980   noise: 4.387   output scale: 8.043 \n",
      "Iter 478/500 - Loss: 2.553   lengthscale: 1.980   noise: 4.384   output scale: 8.052 \n",
      "Iter 479/500 - Loss: 2.553   lengthscale: 1.981   noise: 4.381   output scale: 8.061 \n",
      "Iter 480/500 - Loss: 2.553   lengthscale: 1.981   noise: 4.378   output scale: 8.070 \n",
      "Iter 481/500 - Loss: 2.553   lengthscale: 1.981   noise: 4.375   output scale: 8.079 \n",
      "Iter 482/500 - Loss: 2.553   lengthscale: 1.981   noise: 4.371   output scale: 8.088 \n",
      "Iter 483/500 - Loss: 2.552   lengthscale: 1.981   noise: 4.368   output scale: 8.097 \n",
      "Iter 484/500 - Loss: 2.552   lengthscale: 1.981   noise: 4.365   output scale: 8.106 \n",
      "Iter 485/500 - Loss: 2.552   lengthscale: 1.982   noise: 4.362   output scale: 8.116 \n",
      "Iter 486/500 - Loss: 2.552   lengthscale: 1.982   noise: 4.359   output scale: 8.125 \n",
      "Iter 487/500 - Loss: 2.552   lengthscale: 1.982   noise: 4.355   output scale: 8.134 \n",
      "Iter 488/500 - Loss: 2.552   lengthscale: 1.982   noise: 4.352   output scale: 8.143 \n",
      "Iter 489/500 - Loss: 2.552   lengthscale: 1.982   noise: 4.349   output scale: 8.152 \n",
      "Iter 490/500 - Loss: 2.551   lengthscale: 1.982   noise: 4.345   output scale: 8.161 \n",
      "Iter 491/500 - Loss: 2.551   lengthscale: 1.983   noise: 4.342   output scale: 8.170 \n",
      "Iter 492/500 - Loss: 2.551   lengthscale: 1.983   noise: 4.339   output scale: 8.179 \n",
      "Iter 493/500 - Loss: 2.551   lengthscale: 1.983   noise: 4.335   output scale: 8.188 \n",
      "Iter 494/500 - Loss: 2.551   lengthscale: 1.983   noise: 4.332   output scale: 8.198 \n",
      "Iter 495/500 - Loss: 2.551   lengthscale: 1.983   noise: 4.329   output scale: 8.207 \n",
      "Iter 496/500 - Loss: 2.551   lengthscale: 1.983   noise: 4.325   output scale: 8.216 \n",
      "Iter 497/500 - Loss: 2.550   lengthscale: 1.983   noise: 4.322   output scale: 8.225 \n",
      "Iter 498/500 - Loss: 2.550   lengthscale: 1.984   noise: 4.319   output scale: 8.234 \n",
      "Iter 499/500 - Loss: 2.550   lengthscale: 1.984   noise: 4.315   output scale: 8.243 \n",
      "Iter 500/500 - Loss: 2.550   lengthscale: 1.984   noise: 4.312   output scale: 8.252 \n"
     ]
    }
   ],
   "source": [
    "#Set number of training iterations and train GP\n",
    "iterations = 500\n",
    "train_GP_model(model,likelihood, train_p, train_y, iterations, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5c9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "#Puts model in evaluation mode\n",
    "model.eval()\n",
    "#Puts likelihood in evaluation mode\n",
    "likelihood.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71daa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Meshgrid\n",
    "p = 10\n",
    "Theta1 = np.linspace(-2,2,p)\n",
    "Theta2 = np.linspace(-2,2,p)\n",
    "\n",
    "theta_mesh = np.array(np.meshgrid(Theta1,Theta2))\n",
    "theta_space = torch.tensor(theta_mesh.T.reshape(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba9a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1_mesh = theta_mesh[0]\n",
    "theta2_mesh = theta_mesh[1]\n",
    "\n",
    "# for i in range(p):\n",
    "#     for j in range(p):\n",
    "#         print([theta1_mesh[i,j],theta2_mesh[i,j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41599894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.87762272e-01 4.52375169e-01 1.81228375e-01 2.04051831e-03\n",
      "  6.30671154e-01 2.71424624e+00 3.01976867e+00 3.34045691e+00\n",
      "  3.64757492e+00 3.88345846e+00]\n",
      " [2.47552278e-02 1.02264517e-01 4.37033933e-01 5.85000099e-05\n",
      "  4.48207971e-01 9.29343006e-01 1.10714949e+00 1.31538449e+00\n",
      "  1.54694807e+00 1.77785400e+00]\n",
      " [3.20539068e-05 1.09430622e-03 3.66317621e-02 3.69948215e-02\n",
      "  4.99775967e-02 7.70218406e-02 1.20658231e-01 1.84763339e-01\n",
      "  2.73816795e-01 3.91745596e-01]\n",
      " [2.17647659e-04 4.51695462e-04 2.46560755e-04 1.31375171e-02\n",
      "  2.21227084e-05 1.04665672e-02 3.89082943e-03 4.13048099e-04\n",
      "  1.63981357e-05 2.89725450e-03]\n",
      " [1.80064002e-02 8.99494493e-02 8.15836347e-02 7.94322862e-03\n",
      "  1.46725833e-03 6.45120845e-03 4.28394103e-01 4.25978087e-01\n",
      "  2.67484947e-01 1.19892213e-01]\n",
      " [1.00800745e-01 3.17254512e-01 3.18375092e-01 1.56345698e-01\n",
      "  3.67764039e-02 9.30139524e-04 2.81658657e-07 2.62012539e-02\n",
      "  6.73906208e-02 8.41862858e-02]\n",
      " [1.40441756e-01 4.19092002e-01 4.74529401e-01 3.64826954e-01\n",
      "  2.27374776e-01 1.16583866e-01 5.11697417e-02 2.07074733e-02\n",
      "  8.35816141e-03 3.30596072e-03]\n",
      " [7.33019749e-02 2.64601313e-01 3.79168149e-01 3.75863502e-01\n",
      "  3.45801386e-01 3.10940843e-01 2.82627702e-01 2.59575745e-01\n",
      "  2.31540854e-01 1.87262723e-01]\n",
      " [5.76426849e-03 5.56003775e-02 1.52351494e-01 1.95760196e-01\n",
      "  2.46290929e-01 3.12070544e-01 3.92937145e-01 4.70947054e-01\n",
      "  5.08826019e-01 4.69393971e-01]\n",
      " [1.31648655e-03 3.50078868e-06 7.56241267e-03 3.66279520e-02\n",
      "  7.70154393e-02 1.50086947e-01 2.61681733e-01 3.92176421e-01\n",
      "  4.88570977e-01 4.91265241e-01]]\n",
      "The GP estimates \n",
      "Theta1, Theta2 = \n",
      "\n",
      "[0.66666667 0.22222222]\n",
      "The GP estimates the highest EI is at \n",
      "Theta1, Theta2 = \n",
      " \n",
      "[ 2. -2.]\n"
     ]
    }
   ],
   "source": [
    "#Will compare the rigorous solution and approximation later (multidimensional integral over each experiment using a sparse grid)\n",
    "\n",
    "#Calculate EI\n",
    "EI = calc_ei_total(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[0]\n",
    "print(EI)\n",
    "Error =calc_ei_total(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[1]\n",
    "\n",
    "#Find Optimal Point (How should I actually be doing this?)\n",
    "argmin = np.array(np.where(Error == np.amin(Error)))\n",
    "Theta_1_Opt = float(theta1_mesh[argmin[0],argmin[1]])\n",
    "Theta_2_Opt = float(theta2_mesh[argmin[0],argmin[1]])\n",
    "Theta_GP_Opt = np.array((Theta_1_Opt,Theta_2_Opt))\n",
    "print(\"The GP estimates \\nTheta1, Theta2 = \\n\")\n",
    "print(Theta_GP_Opt)\n",
    "\n",
    "#Find point w/ best EI\n",
    "argmax = np.array(np.where(EI == np.amax(EI)))\n",
    "Theta_1_Best = float(theta1_mesh[argmax[0],argmax[1]])\n",
    "Theta_2_Best = float(theta2_mesh[argmax[0],argmax[1]])\n",
    "Theta_Best = np.array((Theta_1_Best,Theta_2_Best))\n",
    "print(\"The GP estimates the highest EI is at \\nTheta1, Theta2 = \\n \")\n",
    "print(Theta_Best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134aac14",
   "metadata": {},
   "source": [
    "## Analysis of Expected Improvement\n",
    " - Expected Improvement is largest in corners\n",
    "  - This is rational because you can't explore any further than the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295d8ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(Theta_True, Theta_GP_Opt)\n",
    "ei_plotter_adv(theta_mesh, EI, Theta_True, train_theta, Theta_GP_Opt, plot_train=True)\n",
    "\n",
    "\n",
    "#SHould I even plot y, stdev, and error? If so, would I plot them in 3D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc69e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.11229850e-05 5.26365201e-02 6.82555775e-02 6.06198056e-02\n",
      "  6.20924588e-03]\n",
      " [1.54986275e-04 1.36077309e-01 1.58552251e-01 1.43528851e-01\n",
      "  1.40617710e-02]\n",
      " [1.14776356e-04 5.95999075e-02 5.94939686e-02 5.65165020e-02\n",
      "  5.50322094e-03]\n",
      " [2.97709188e-06 7.20240155e-04 6.12678031e-04 6.37417812e-04\n",
      "  6.72052175e-05]\n",
      " [2.79315802e-03 2.23337021e-01 1.73608415e-01 2.03979062e-01\n",
      "  2.69534982e-02]\n",
      " [3.61877902e-02 8.92085428e-01 6.99114276e-01 9.26117646e-01\n",
      "  1.60741102e-01]\n",
      " [8.68859928e-02 8.85455660e-01 7.34869459e-01 1.08756075e+00\n",
      "  2.24996811e-01]\n",
      " [1.58027774e-01 8.81115003e-01 7.78761183e-01 1.23038268e+00\n",
      "  2.92170275e-01]\n",
      " [2.11543475e-01 9.27967016e-01 8.36305075e-01 1.32636836e+00\n",
      "  3.45390988e-01]\n",
      " [2.11306163e-01 1.03636152e+00 9.04775513e-01 1.35977126e+00\n",
      "  3.71243998e-01]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ei_plotter_adv_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_60632/297922708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Find point w/ best EI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEI_sing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mei_plotter_adv_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta_mesh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEI_sing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTheta_True\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXexp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTheta_GP_Opt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ei_plotter_adv_test' is not defined"
     ]
    }
   ],
   "source": [
    "EI_sing = calc_ei_total_test(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[0]\n",
    "Error =calc_ei_total_test(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[1]\n",
    "for i in range(n):    \n",
    "    #Find point w/ best EI\n",
    "    print(EI_sing[i])\n",
    "    ei_plotter_adv_test(theta_mesh, EI_sing[i], Theta_True, train_p,Xexp[i],Theta_GP_Opt,plot_train=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c98657d1",
   "metadata": {},
   "source": [
    "print(stdev_plotter_adv_4D(test_p_mesh, model_stdev, point_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16656",
   "metadata": {},
   "source": [
    "## Analysis of Standard Deviation\n",
    " - The GP estimates that the standard deviation is lowest at points that were directly tested\n",
    "  - This can be rationalized by the way that the contour plot is drawn\n",
    " - Standard deviation is smallest away from the edges and larger towards them\n",
    "  - This is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The more points that get tested, the more the standard deviations will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6491294",
   "metadata": {},
   "source": [
    "print(error_plotter_adv_4D(test_p_mesh, model_y, y_exp, point_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4a585",
   "metadata": {},
   "source": [
    "## Analysis of Error Magnitude\n",
    " - The GP emulator is most inaccurate when all values of $\\bar{p}$ are at their maximum. \n",
    "  - In general, the GP is less accurate at extreme points, this is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The GP emulator is most accurate when x is at it's maximum, but $\\bar{\\Theta}= 0$\n",
    "  - This is rationalized by the fact that multiple terms become zero if any of the values of $\\bar{p}$ are zero \n",
    " - GP error is mostly very high, as more iterations are added, these will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b856d936",
   "metadata": {},
   "source": [
    "y_title = \"Model Y Values\"\n",
    "print(y_plotter_adv_4D(test_p_mesh, model_y, point_num,y_title,yval=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d487",
   "metadata": {},
   "source": [
    "## Analysis of GP Emulator (Model y)\n",
    " - The GP emulator correctly captures that y increases as $\\bar{p}$ increases. This tells us that this GP emulator model could be viable\n",
    "  - The GP emulator correctly estimates where the lowest y is achieved, but not the actual value of y\n",
    "  - The GP emulator slightly mistakes where the most positive value of y is, and does not predict the actual value of y\n",
    " - The model as it is is inaccurate, BO should increase the accuracy of the emulator"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a246c18a",
   "metadata": {},
   "source": [
    "print(ei_plotter_adv(test_p_mesh_plot, ei))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69c62ab2",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': '3d'},figsize=(11,8))\n",
    "\n",
    "X, Y, Z = np.array(np.meshgrid(test_p1,test_p2,test_p3))\n",
    "X = X.reshape(-1,point_num)\n",
    "Y = Y.reshape(-1,point_num)\n",
    "Z = Z.reshape(-1,point_num)\n",
    "print(X.shape)\n",
    "C = ei.T.reshape(-1,point_num)\n",
    "print(C.shape)\n",
    "scamap = plt.cm.ScalarMappable(cmap='viridis')\n",
    "fcolors = scamap.to_rgba(C)\n",
    "ax.plot_surface(X, Y, Z, facecolors=fcolors, cmap='viridis')\n",
    "fig.colorbar(scamap, label = \"Yelling\")\n",
    "ax.set_xlabel('$\\Theta_1$')\n",
    "ax.set_ylabel('$\\Theta_2$')\n",
    "ax.set_zlabel('X Coordinate')\n",
    "ax.view_init(40, -30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4da7bae",
   "metadata": {},
   "source": [
    "y_title = \"Model y Value\"\n",
    "print(y_plotter_adv(test_p, model_y, y_title,yval = True))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "067d6ce9",
   "metadata": {},
   "source": [
    "print(stdev_plotter_adv(test_p, model_stdev))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fd7ecc1",
   "metadata": {},
   "source": [
    "print(error_plotter_adv(test_p, model_y, y_exp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
