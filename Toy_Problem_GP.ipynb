{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "\n",
    "from bo_functions import calc_ei_basic\n",
    "from bo_functions import create_y_data_basic\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import calc_GP_parameters_basic\n",
    "\n",
    "from bo_plotters import y_plotter_basic\n",
    "from bo_plotters import stdev_plotter_basic\n",
    "from bo_plotters import ei_plotter_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16408/1394711744.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mTheta1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1x10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mTheta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1x10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1x5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Creates a mesh for training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Training data is 10^2 points in [-2,2] inclusive regularly spaced\n",
    "Theta1 = np.linspace(-2,2,10) #1x10\n",
    "Theta2 = np.linspace(-2,2,10) #1x10\n",
    "x = torch.tensor(np.linspace(-2,2,5)) #1x5\n",
    "\n",
    "#Creates a mesh for training data\n",
    "train_mesh = np.array(np.meshgrid(Theta1, Theta2)) #2 Uniform Arrays 10x10 (.T turns this into 10 10x2 arrays)\n",
    "\n",
    "#Lists every combination of training Theta1 and Theta2\n",
    "train_T = torch.tensor(train_mesh.T.reshape(-1, 2))#100x2\n",
    "\n",
    "#Set noise parameters and true value of Theta to generate training data\n",
    "noise_std = 0.1**2\n",
    "Theta_True = torch.tensor([1,-1]) #1x2\n",
    "train_y = create_y_data_basic(Theta_True, train_T, x, noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "##Assumes a homoskedastic noise model p(y | f) = f + noise\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "#Defines our model in terms of the class parameters in bo_functions\n",
    "model = ExactGPModel(train_T, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal model hyperparameters\n",
    "training_iter = 300\n",
    "\n",
    "#Puts the model in training mode\n",
    "model.train()\n",
    "\n",
    "#Puts the likelihood in training mode\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "    #algorithm for first-order gradient-based optimization of stochastic objective functions\n",
    "    # The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. \n",
    "    #The hyper-parameters have intuitive interpretations and typically require little tuning.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  #Needs GaussianLikelihood parameters, and a learning rate\n",
    "    #lr default is 0.001\n",
    "\n",
    "# Calculate\"Loss\" for GPs\n",
    "\n",
    "#The marginal log likelihood (the evidence: quantifies joint probability of the data under the prior)\n",
    "#returns an exact MLL for an exact Gaussian process with Gaussian likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model) #Takes a Gaussian likelihood and a model, a bound Method\n",
    "#iterates a give number of times\n",
    "for i in range(training_iter): #0-299\n",
    "    # Zero gradients from previous iteration - Prevents past gradients from influencing the next iteration\n",
    "    optimizer.zero_grad() \n",
    "    # Output from model\n",
    "    output = model(train_T) # A multivariate norm of a 1 x 100 tensor\n",
    "    # Calc loss and backprop gradients\n",
    "    #Minimizing -logMLL lets us fit hyperparameters\n",
    "    loss = -mll(output, train_y) #A number (tensor)\n",
    "    #computes dloss/dx for every parameter x which has requires_grad=True. \n",
    "    #These are accumulated into x.grad for every parameter x\n",
    "    loss.backward()\n",
    "#     print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "#         i + 1, training_iter, loss.item(),\n",
    "#         model.covar_module.base_kernel.lengthscale.item(),\n",
    "#          model.likelihood.noise.item()\n",
    "#     ))\n",
    "    #optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs:\n",
    "    #x += -lr * x.grad\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "#Puts model in evaluation mode\n",
    "model.eval()\n",
    "#Puts likelihood in evaluation mode\n",
    "likelihood.eval()\n",
    "\n",
    "#Define Testing Data\n",
    "test_Theta1 =  np.linspace(-1,1,5) #1x5\n",
    "test_Theta2 =  np.linspace(-1,1,5) #1x5\n",
    "test_mesh = np.array(np.meshgrid(test_Theta1, test_Theta2)) #2 Uniform 5x5 arrays\n",
    "test_T = torch.tensor(test_mesh.T.reshape(-1, 2)) #25 x 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41599894",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_Output = calc_GP_parameters_basic(model, likelihood, test_T)\n",
    "\n",
    "model_mean = GP_Output[0]\n",
    "model_variance = GP_Output[1]\n",
    "model_stdev = GP_Output[2]\n",
    "model_sse = GP_Output[3]\n",
    "\n",
    "#Finds the index where sse is the smallest and finds which Theta combination corresponds to that value\n",
    "Theta_Opt_GP = test_T[np.argmin(model_sse)].numpy() #1x2\n",
    "print(\"The GP predicts that Theta1 =\",Theta_Opt_GP[0],\"and Theta2 =\", Theta_Opt_GP[1])\n",
    "\n",
    "#calculates best_error and expected improvement\n",
    "best_error = np.argmax(model_sse)\n",
    "ei = calc_ei_basic(best_error,model_mean,model_variance)\n",
    "print(ei)\n",
    "\n",
    "#Formats ei points into a suitable graphing form    \n",
    "ei_map = ei.reshape(len(test_Theta1),-1) # 5x5\n",
    "#Formats sse data points into a suitable graphing form    \n",
    "sse_map = model_sse.reshape(len(test_Theta1),-1) #5 x 5\n",
    "#Formats stdev data points into suitable graphing form\n",
    "stdev_map = model_stdev.reshape(len(test_Theta1),-1) #5 x 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"SSE\"\n",
    "y_plotter_basic(test_mesh, sse_map, Theta_True, Theta_Opt_GP, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18100b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev_plotter_basic(test_mesh, stdev_map,Theta_True, Theta_Opt_GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aecc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ei_plotter_basic(test_mesh, ei_map, Theta_True, Theta_Opt_GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26281f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
