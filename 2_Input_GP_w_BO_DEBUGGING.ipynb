{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "from bo_functions import calc_y_exp\n",
    "from bo_functions import create_y_data\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "from bo_functions import calc_GP_outputs\n",
    "from bo_functions import calc_ei_basic\n",
    "from bo_functions import eval_GP_basic_tot\n",
    "from bo_functions import create_sse_data\n",
    "from bo_functions import eval_GP_basic_tot_scipy\n",
    "\n",
    "from bo_plotters import plot_hyperparams\n",
    "from bo_plotters import plot_xy\n",
    "from bo_plotters import y_plotter\n",
    "from bo_plotters import stdev_plotter\n",
    "from bo_plotters import ei_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull x data from CSV\n",
    "Theta_True = np.array([1,-1])\n",
    "noise_std = 0.1**2\n",
    "q = 2\n",
    "\n",
    "exp_data_doc = \"exp_data.csv\"\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "n = len(Xexp)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afaf0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull training data from CSV\n",
    "train_data_doc = \"train_2_in_data.csv\"\n",
    "train_data = np.array(pd.read_csv(train_data_doc, header=0,sep=\",\"))\n",
    "train_T = torch.tensor(train_data[:,1:3])\n",
    "train_sse = torch.tensor(train_data[:,3])\n",
    "# print(train_sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fcaa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce Number of Training Points\n",
    "t =len(train_T) #Desired number of training points\n",
    "t = 3 #Set t=5 to show changing EI\n",
    "train_T = train_T[0:t]\n",
    "train_sse = train_sse[0:t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdff16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aae45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GP Testing space\n",
    "#Define Testing Space\n",
    "p=20\n",
    "# Theta1 =  np.linspace(0.5,1.5,p) #1x10\n",
    "# Theta2 =  np.linspace(-1.5,-0.5,p) #1x10\n",
    "Theta1 =  np.linspace(-2,2,p) #1x10\n",
    "Theta2 =  np.linspace(-2,2,p) #1x10\n",
    "theta_mesh = np.array(np.meshgrid(Theta1, Theta2)) #2 Uniform 5x5 arrays\n",
    "theta1_mesh = theta_mesh[0]\n",
    "theta2_mesh = theta_mesh[1]\n",
    "# print(theta_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:130: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "failed in converting 4th argument `xl' of _slsqp.slsqp to C/Fortran array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: unexpected array size: new_size=1, got array with arr_size=0\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m     ei_sse_choice \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mei\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m#     Best_Solution = optimize.least_squares(eval_GP_basic_tot_scipy, theta0_b,bounds=bnds, method='trf',args=((train_sse, model, likelihood, explore_bias, ei_sse_choice)))\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     Best_Solution \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_GP_basic_tot_scipy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta0_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSLSQP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mei_sse_choice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m#     print(Solution)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     theta_b \u001b[38;5;241m=\u001b[39m Best_Solution\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_minimize.py:690\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    687\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cobyla(fun, x0, args, constraints, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    688\u001b[0m                             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslsqp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 690\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_slsqp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-constr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    694\u001b[0m                                        bounds, constraints,\n\u001b[1;32m    695\u001b[0m                                        callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/scipy/optimize/_slsqp_py.py:422\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    418\u001b[0m a \u001b[38;5;241m=\u001b[39m _eval_con_normals(x, cons, la, n, m, meq, mieq)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Call SLSQP\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     \u001b[43mslsqp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m          \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m          \u001b[49m\u001b[43miexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mireset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitermx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m          \u001b[49m\u001b[43mn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# objective and constraint evaluation required\u001b[39;00m\n\u001b[1;32m    428\u001b[0m         fx \u001b[38;5;241m=\u001b[39m wrapped_fun(x)\n",
      "\u001b[0;31mValueError\u001b[0m: failed in converting 4th argument `xl' of _slsqp.slsqp to C/Fortran array"
     ]
    }
   ],
   "source": [
    "#Training the GP Model\n",
    "iterations = 300\n",
    "explore_bias = 0\n",
    "verbose = True\n",
    "\n",
    "BO_iter = 50\n",
    "train_T_dict = {}\n",
    "train_sse_dict = {}\n",
    "ei_dict = {}\n",
    "sse_dict ={}\n",
    "var_dict ={}\n",
    "GP_mean_best_dict = {}\n",
    "GP_var_best_dict = {}\n",
    "GP_mean_min_dict ={}\n",
    "GP_var_min_dict = {}\n",
    "Theta_Opt_dict = {}\n",
    "Theta_Best_dict = {}\n",
    "Best_Error_dict = {}\n",
    "if verbose == True:\n",
    "    z_dict = {}\n",
    "    ei_term_1_dict = {}\n",
    "    ei_term_2_dict = {}\n",
    "    CDF_dict = {}\n",
    "    PDF_dict = {}\n",
    "\n",
    "for i in range(BO_iter):\n",
    "    print(i+1)\n",
    "    if torch.is_tensor(train_T) != True:\n",
    "        train_T = torch.from_numpy(train_T)\n",
    "    if torch.is_tensor(train_sse) != True:\n",
    "        train_sse = torch.from_numpy(train_sse)\n",
    "    \n",
    "    train_T_dict[i+1] = train_T\n",
    "    train_sse_dict[i+1] = train_sse\n",
    "    # initialize likelihood and model\n",
    "    ##Assumes a homoskedastic noise model p(y | f) = f + noise\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "    # We will use the simplest form of GP model, exact inference\n",
    "    #Defines our model in terms of the class parameters in bo_functions\n",
    "    model = ExactGPModel(train_T, train_sse, likelihood)\n",
    "    train_GP = train_GP_model(model, likelihood, train_T, train_sse, iterations, verbose = False)\n",
    "    \n",
    "    ##Set Hyperparameters to 1\n",
    "    outputscale = torch.tensor([1])\n",
    "    lengthscale = torch.tensor([1])\n",
    "    noise = torch.tensor([0.1])\n",
    "\n",
    "    model.likelihood.noise = noise\n",
    "    model.covar_module.base_kernel.lengthscale =lengthscale\n",
    "    model.covar_module.outputscale = outputscale\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    #Puts likelihood in evaluation mode\n",
    "    likelihood.eval()\n",
    "\n",
    "    #Same point keeps being selected, should I remove that point by force?\n",
    "    ei_components = eval_GP_basic_tot(p,theta_mesh, train_sse, model, likelihood, explore_bias, verbose)\n",
    "    ei = ei_components[0]\n",
    "    sse = ei_components[1]\n",
    "#     print(sse)\n",
    "    var = ei_components[2]\n",
    "    stdev = ei_components[3]\n",
    "    best_error = ei_components[4]\n",
    "    if verbose == True:\n",
    "        z = ei_components[5]\n",
    "        ei_term_1 = ei_components[6]\n",
    "        ei_term_2 = ei_components[7]\n",
    "        CDF = ei_components[8]\n",
    "        PDF = ei_components[9]\n",
    "    \n",
    "    ei_dict[i+1] = ei\n",
    "    sse_dict[i+1] = sse\n",
    "    var_dict[i+1] = var\n",
    "    z_dict[i+1]=z\n",
    "    \n",
    "    Best_Error_dict[i+1] = best_error\n",
    "    ei_term_1_dict[i+1] = ei_term_1\n",
    "    ei_term_2_dict[i+1] = ei_term_2\n",
    "    CDF_dict[i+1] = CDF\n",
    "    PDF_dict[i+1] = PDF\n",
    "\n",
    "    argmin = np.array(np.where(np.isclose(sse, np.amin(sse),atol=np.amin(sse)*1e-6)==True))\n",
    "    Theta_1_Opt = float(theta1_mesh[argmin[0],argmin[1]])\n",
    "    Theta_2_Opt = float(theta2_mesh[argmin[0],argmin[1]])\n",
    "    Theta_Opt_GP = np.array((Theta_1_Opt,Theta_2_Opt))\n",
    "\n",
    "    \n",
    "    #calculates best theta value\n",
    "    argmax = np.array(np.where(np.isclose(ei, np.amax(ei),atol=np.amax(ei)*1e-6)==True))\n",
    "#     print(argmax)\n",
    "    if len(argmax[0]) != 1:\n",
    "        argmax = np.array([[argmax[0,1]],[argmax[1,1]]])\n",
    "    \n",
    "    Theta_1_Best = float(theta1_mesh[argmax[0],argmax[1]])\n",
    "    Theta_2_Best = float(theta2_mesh[argmax[0],argmax[1]])\n",
    "    Theta_Best = np.array((Theta_1_Best,Theta_2_Best))    \n",
    "    \n",
    "    #Finds the index where sse is the smallest and finds which Theta combination corresponds to that value\n",
    "    theta0_b = Theta_Best\n",
    "    theta0_o = Theta_Opt_GP\n",
    "#     theta0_b = theta0_o = [1.5,-1.5] #Causes only this point to be repeated\n",
    "\n",
    "    ## specify bounds\n",
    "    # first array: lower bounds\n",
    "    # second array: upper bounds\n",
    "#     bnds = ([np.min(Theta1), np.min(Theta2)], [np.max(Theta1), np.max(Theta2)])\n",
    "    bnds = [[np.min(Theta1), np.min(Theta2)], [np.max(Theta1), np.max(Theta2)]]\n",
    "\n",
    "    ## use least squares optimizer in scipy?? IS LEAST SQUARES APPROPRIATE?\n",
    "    # argument 1: function that takes theta as input, returns residual\n",
    "    # argument 2: initial guess for theta\n",
    "    # optional arguments 'bounds': bounds for theta\n",
    "    # optional arugment 'args': additional arguments to pass to residual function\n",
    "    # optional argument 'method': select the numerical method\n",
    "    #   if you want to consider bounds, choose 'trf'\n",
    "    #   if you do not want to consider bounds, try either 'lm' or 'trf'\n",
    "    ei_sse_choice =\"ei\"\n",
    "#     Best_Solution = optimize.least_squares(eval_GP_basic_tot_scipy, theta0_b,bounds=bnds, method='trf',args=((train_sse, model, likelihood, explore_bias, ei_sse_choice)))\n",
    "    Best_Solution = optimize.minimize(eval_GP_basic_tot_scipy, theta0_b,bounds=bnds, method='Nelder-Mead',args=((train_sse, model, likelihood, explore_bias, ei_sse_choice)))\n",
    "\n",
    "    #     print(Solution)\n",
    "    theta_b = Best_Solution.x\n",
    "    print(\"Theta Best = \",theta_b)\n",
    "    print(\"Argmax Theta Best = \",Theta_Best)\n",
    "    \n",
    "    ei_sse_choice2 = \"sse\"\n",
    "#     Opt_Solution = optimize.least_squares(eval_GP_basic_tot_scipy, theta0_o,bounds=bnds, method='trf',args=((train_sse, model, likelihood, explore_bias, ei_sse_choice2)))\n",
    "    Opt_Solution = optimize.minimize(eval_GP_basic_tot_scipy, theta0_o,bounds=bnds, method='Nelder-Mead',args=((train_sse, model, likelihood, explore_bias, ei_sse_choice2)))\n",
    "\n",
    "    theta_o = Opt_Solution.x\n",
    "    print(\"Theta Opt = \",theta_o)\n",
    "    print(\"Argmin Theta_Opt_GP = \",Theta_Opt_GP)\n",
    "    ##Using this method allows for small changes, but these points aren't reflected by the graphs (innacurate?)\n",
    "    \n",
    "    Theta_Opt_dict[i+1] = Theta_Opt_GP\n",
    "    Theta_Best_dict[i+1] = Theta_Best\n",
    "\n",
    "    GP_mean_min = sse[argmin[0],argmin[1]]\n",
    "    GP_var_min = (stdev[argmin[0],argmin[1]])**2\n",
    "    GP_mean_best = sse[argmax[0],argmax[1]]\n",
    "    GP_var_best = (stdev[argmax[0],argmax[1]])**2\n",
    "    \n",
    "    GP_mean_best_dict[i+1] = GP_mean_best\n",
    "    GP_var_best_dict[i+1] = GP_var_best\n",
    "    GP_mean_min_dict[i+1] = GP_mean_min\n",
    "    GP_var_min_dict[i+1] = GP_var_min\n",
    "    \n",
    "    sse_title = \"SSE\"\n",
    "    ei_plotter(theta_mesh, ei, Theta_True, theta_o, theta_b,train_T,plot_train=True)\n",
    "#     y_plotter(theta_mesh, sse, Theta_True, theta_o, theta_b, train_T,sse_title,plot_train=True)\n",
    "#     ei_plotter(theta_mesh, ei, Theta_True, Theta_Opt_GP, Theta_Best,train_T,plot_train=True)\n",
    "#     y_plotter(theta_mesh, sse, Theta_True, Theta_Opt_GP, Theta_Best, train_T,sse_title,plot_train=True)\n",
    "    ##Append best values to training data \n",
    "    #Convert training data to numpy arrays to allow concatenation to work\n",
    "    train_T = train_T.numpy() #(q x t)\n",
    "    train_sse = train_sse.numpy() #(1 x t)\n",
    "\n",
    "    #Call the expensive function and evaluate at Theta_Best\n",
    "    sse_Best = create_sse_data(q,theta_b, Xexp, Yexp) #(1 x 1)\n",
    "#     sse_Best = create_sse_data(q,Theta_Best, Xexp, Yexp) #(1 x 1)\n",
    " \n",
    "    #Add Theta_Best to train_p and y_best to train_y\n",
    "    train_T = np.concatenate((train_T, [theta_b]), axis=0) #(q x t)\n",
    "#     train_T = np.concatenate((train_T, [Theta_Best]), axis=0) #(q x t)\n",
    "    train_sse = np.concatenate((train_sse, [sse_Best]),axis=0) #(1 x t)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79ca785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_T_dict)\n",
    "print(train_sse_dict)\n",
    "print(Best_Error_dict)\n",
    "print(\"\\n\",ei_dict)\n",
    "#This is Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMax EIs\")\n",
    "for i in range(BO_iter):\n",
    "    j=i+1\n",
    "    print(np.amax(ei_dict[j]))\n",
    "\n",
    "print(\"\\nMin SSEs\")\n",
    "for i in range(BO_iter):\n",
    "    j=i+1\n",
    "    print(np.amin(sse_dict[j]))\n",
    "\n",
    "##These are expected\n",
    "\n",
    "print(\"\\nBest EI GP Mean/Var\")\n",
    "print(GP_mean_best_dict)\n",
    "print(GP_var_best_dict)\n",
    "\n",
    "#GP Mean and EI Best vs Opt is the same. What does this mean?\n",
    "\n",
    "print(\"\\nLowest SSE GP Mean/Var\")\n",
    "print(GP_mean_min_dict)\n",
    "print(GP_var_min_dict)\n",
    "#Expected based on results above\n",
    "\n",
    "for i in range(BO_iter):\n",
    "    j = i+1\n",
    "    argmax = np.array(np.where(np.isclose(ei_dict[j], np.amax(ei_dict[j]),atol=np.amax(ei_dict[j])*1e-6)==True))\n",
    "    \n",
    "    f_Best_a = Best_Error_dict[j][argmax[0],argmax[1]][0]\n",
    "    print(\"\\n f_Best\",f_Best_a)\n",
    "    print(\"EI_max:\",np.amax(ei_dict[j]))\n",
    "    print(\"GP Mean/Var:\",GP_mean_best_dict[j],GP_var_best_dict[j])\n",
    "    \n",
    "    print(\"EI:\",calc_ei_basic(f_Best_a,-GP_mean_best_dict[j],GP_var_best_dict[j], explore_bias))\n",
    "#Max EIs are expected\n",
    "\n",
    "\n",
    "print(\"\\nTheta @ Lowest SSE\")\n",
    "print(Theta_Opt_dict)\n",
    "\n",
    "#Expected based on results above\n",
    "print(\"\\nTheta @ Highest EI\")\n",
    "print(Theta_Best_dict)\n",
    "\n",
    "\n",
    "# print(\"z values\")\n",
    "# print(z_dict[1],\"\\n\", z_dict[2],\"\\n\",z_dict[3])\n",
    "\n",
    "\n",
    "# print(\"Term 1 values\")\n",
    "# print(ei_term_1_dict[1],\"\\n\", ei_term_1_dict[2],\"\\n\",ei_term_1_dict[3])\n",
    "\n",
    "# print(\"Term 2 values\")\n",
    "# print(ei_term_2_dict[1],\"\\n\", ei_term_2_dict[2],\"\\n\",ei_term_2_dict[3])\n",
    "\n",
    "# print(\"CDF\")\n",
    "# print(CDF[1],\"\\n\", CDF[2],\"\\n\",CDF[3])\n",
    "\n",
    "# print(\"PDF\")\n",
    "# print(PDF[1],\"\\n\", PDF[2],\"\\n\",PDF[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_y = 3\n",
    "y_GP_input = np.zeros((n,3))\n",
    "for j in range(n):\n",
    "    y_GP_input[j] = np.array([Theta_Best[0],Theta_Best[1],Xexp[j]])\n",
    "\n",
    "y_GP_Opt = create_y_data(q_y,y_GP_input)\n",
    "print(Theta_Opt_GP)\n",
    "print(y_GP_Opt)\n",
    "print(Yexp)\n",
    "\n",
    "title = \"XY Comparison\"\n",
    "plot_xy(Xexp, Yexp, y_GP_Opt,Theta_True,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ae3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e57cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
