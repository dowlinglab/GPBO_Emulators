{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d9c0f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date and Time:  15-Dec-2022 (15:28:00)\n",
      "(400, 2)\n",
      "Runs: 1\n",
      "BO Iterations: 10\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Normalizing?: True\n",
      "-------------------\n",
      "Emulator?: True\n",
      "______________________________\n",
      "Sparse Grid?: True\n",
      "Objective Function: obj\n",
      "-  -  -  -  -  -  -  -  -  -  -\n",
      "Separation Factor Train/Test: 0.7\n",
      "Lengthscale Set To: None\n",
      "Explore Bias Multiplier: 1.0\n",
      "Run Number:  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:123\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:1303\u001b[0m, in \u001b[0;36mbo_iter_w_runs\u001b[0;34m(BO_iters, all_data_doc, t, theta_set, Theta_True, train_iter, explore_bias, Xexp, Yexp, noise_std, obj, runs, sparse_grid, emulator, set_lengthscale, true_model_coefficients, param_dict, bounds_p, bounds_x, verbose, save_fig, shuffle_seed, DateTime, sep_fact, LHS, skip_param_types, eval_all_pairs, normalize, case_study)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             bounds_p_scl, train_p_scl, test_p_scl, bounds_x_scl, Xexp_scl, theta_set_scl, Theta_True_scl, true_model_coefficients_scl \u001b[38;5;241m=\u001b[39m  bounds_p, train_p, test_p, bounds_x, Xexp, theta_set, Theta_True, true_model_coefficients\n\u001b[1;32m   1279\u001b[0m         \u001b[38;5;66;03m#Testing that normalization is happening correctly\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m#         norm = False\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m#         train_p_unscl = train_p_scl.clone()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                              \n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;66;03m#Run BO Iteration\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m         BO_results \u001b[38;5;241m=\u001b[39m \u001b[43mbo_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBO_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtheta_set_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTheta_True_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_lengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDateTime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_p_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep_fact\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msep_fact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLHS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_all_pairs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_all_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_study\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcase_study\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m         \u001b[38;5;66;03m#Add all SSE/theta results at each BO iteration for that run\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m         Theta_Best_matrix[i,:,:] \u001b[38;5;241m=\u001b[39m BO_results[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:995\u001b[0m, in \u001b[0;36mbo_iter\u001b[0;34m(BO_iters, train_p, train_y, theta_set, Theta_True, train_iter, explore_bias, Xexp, Yexp, noise_std, obj, run, sparse_grid, emulator, set_lengthscale, true_model_coefficients, param_dict, bounds_p, verbose, save_fig, tot_runs, DateTime, test_p, sep_fact, LHS, skip_param_types, eval_all_pairs, normalize, norm_scalers, case_study)\u001b[0m\n\u001b[1;32m    991\u001b[0m         explore_bias \u001b[38;5;241m=\u001b[39m ep_init \u001b[38;5;66;03m#Sets ep to the multiplicative scaler between 0.1 and 1\u001b[39;00m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;66;03m#Evaluate GP to find sse and ei for optimization step\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m#         print(theta_set[0:5], train_p[0:5], Xexp[0:5], true_model_coefficients)\u001b[39;00m\n\u001b[0;32m--> 995\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m \u001b[43meval_GP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_lengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m         \u001b[38;5;66;03m#Determine which parameters will be plotted given the method type and whether verbose is T/F. Save parameters to plot to a list\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m#eval_GP will also save internal parameters used in the calculation of EI if the standard approach is used and verbose is true. These are useful in critically analyzing which components of EI have a large effect, but are tedious to save and take up a lot of space. Therefore, they are only saved when verbose == True    \u001b[39;00m\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m emulator \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:865\u001b[0m, in \u001b[0;36meval_GP\u001b[0;34m(theta_set, train_y, explore_bias, Xexp, Yexp, true_model_coefficients, model, likelihood, verbose, emulator, sparse_grid, set_lengthscale, train_p, obj, skip_param_types, norm_scalers)\u001b[0m\n\u001b[1;32m    862\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m eval_GP_basic_set(theta_set, train_y, model, likelihood, explore_bias, verbose)\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m#         eval_components = eval_GP_emulator_tot(Xexp,Yexp, theta_mesh, model, likelihood, sparse_grid, explore_bias, verbose)\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         eval_components \u001b[38;5;241m=\u001b[39m \u001b[43meval_GP_emulator_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m eval_components\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_bo_functions_multi_dim.py:354\u001b[0m, in \u001b[0;36meval_GP_emulator_set\u001b[0;34m(Xexp, Yexp, theta_set, true_model_coefficients, model, likelihood, sparse_grid, emulator, explore_bias, verbose, train_p, obj, skip_param_types, norm_scalers)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m##Calculate Best Error\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;66;03m# Loop over theta 1\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(len_set):\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;66;03m#Caclulate best error and initialize arrays to store GP mean and variance in\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m         best_error \u001b[38;5;241m=\u001b[39m \u001b[43meval_GP_emulator_BE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_scalers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m#         print(best_error)\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         GP_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n)\n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/CS2_create_data.py:326\u001b[0m, in \u001b[0;36meval_GP_emulator_BE\u001b[0;34m(Xexp, Yexp, train_p, true_model_coefficients, emulator, obj, skip_param_types, norm_scalers)\u001b[0m\n\u001b[1;32m    324\u001b[0m         train_p_unscl \u001b[38;5;241m=\u001b[39m train_p\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    325\u001b[0m         scaler_x, scaler_theta, scaler_C_before, scaler_C_after \u001b[38;5;241m=\u001b[39m norm_scalers\n\u001b[0;32m--> 326\u001b[0m         true_model_coefficients_unscl \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_constants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_model_coefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_p_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_theta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_param_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_C_before\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_C_after\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m#         train_p_unscl = normalize_p_data(train_p, scaler_theta, norm)[0]\u001b[39;00m\n\u001b[1;32m    328\u001b[0m         train_p_unscl[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39mm] \u001b[38;5;241m=\u001b[39m normalize_p_data(train_p[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39mm], m, emulator, norm, scaler_theta) \n",
      "File \u001b[0;32m/scratch365/mcarlozo/Toy_Problem/bo_methods_lib/normalize.py:244\u001b[0m, in \u001b[0;36mnormalize_constants\u001b[0;34m(Constants, p_true, scaler_theta, skip_params, CS, norm, scaler_C_before, scaler_C_after)\u001b[0m\n\u001b[1;32m    241\u001b[0m     Constants_after_scl, scaler_C_after \u001b[38;5;241m=\u001b[39m norm_unnorm(Constants_after\u001b[38;5;241m.\u001b[39mT, norm, scaler_C_after)\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m#Restack scaled constants and return their value and necessary scalers\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     Constants_scl \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConstants_before_scl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConstants_theta_scl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConstants_after_scl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Constants_scl, scaler_C_before, scaler_C_after\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_functions_generic import gen_theta_set, clean_1D_arrays\n",
    "from bo_methods_lib.CS2_bo_functions_multi_dim import bo_iter_w_runs, find_train_doc_path, set_ep\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "#----------------------------------------------\n",
    "import warnings\n",
    "warnings.simplefilter(action='error', category=FutureWarning)\n",
    "np.warnings.filterwarnings('error', category=np.VisibleDeprecationWarning)\n",
    "\n",
    "CS = 1\n",
    "#Set Date and Time\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S)\")\n",
    "print(\"Date and Time: \", timestampStr)\n",
    "# DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M-%S%p\")\n",
    "DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M\")\n",
    "DateTime = None ##For Testing\n",
    "\n",
    "#Set Parameters\n",
    "Theta_True = np.array([1,-1])\n",
    "param_dict = {0 : '\\\\theta_1', 1 : '\\\\theta_2'}\n",
    "d = len(Theta_True)\n",
    "BO_iters = 10 #make 20\n",
    "runs = 1 #Make 1\n",
    "train_iter = 300\n",
    "noise_std = 0.1\n",
    "shuffle_seed = 9\n",
    "sep_fact = [0.7]\n",
    "# sep_fact = np.linspace(0.7,1,1)\n",
    "set_lengthscale = None\n",
    "skip_param_types = 0\n",
    "\n",
    "obj = np.array([\"obj\"])\n",
    "# obj = np.array([\"LN_obj\"])\n",
    "# obj = np.array([\"obj\",\"LN_obj\"])\n",
    "emulator = np.array([True])\n",
    "# emulator = np.array([False])\n",
    "sparse_grid = np.array([True])\n",
    "# sparse_grid = np.array([False])\n",
    "eval_all_pairs = True\n",
    "# eval_all_pairs = False\n",
    "# normalize = [False, True]\n",
    "normalize = [True]\n",
    "# normalize = [False]\n",
    "# sparse_grid = np.array([False,True])\n",
    "verbose = False\n",
    "# save_fig = True\n",
    "save_fig = False\n",
    "\n",
    "#Pull Experimental data from CSV\n",
    "exp_data_doc = 'Input_CSVs/Exp_Data/d=2/n=5.csv'\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "n = len(Xexp)\n",
    "# print(len(Xexp) == len(Yexp))\n",
    "\n",
    "Xexp = clean_1D_arrays(Xexp)\n",
    "bounds_x = np.array([[-2],[2]])\n",
    "# print(bounds_x.shape)\n",
    "\n",
    "#Define GP Testing space\n",
    "LHS = False\n",
    "p=20\n",
    "bounds_p = np.array([[-2,-2],\n",
    "                     [2 , 2]])\n",
    "# Theta1 =  np.linspace(-2,2,p) #1x10\n",
    "# Theta2 =  np.linspace(-2,2,p) #1x10\n",
    "# theta_mesh = np.array(np.meshgrid(Theta1, Theta2)) #2 Uniform 5x5 arrays \n",
    "theta_mesh = gen_theta_set(LHS = LHS, n_points = p, dimensions = d, bounds = bounds_p)\n",
    "print(theta_mesh.shape)\n",
    "\n",
    "print(\"Runs:\", runs)\n",
    "print(\"BO Iterations:\",BO_iters)\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "for norm in normalize:\n",
    "    print(\"Normalizing?:\", norm)\n",
    "    for emul in emulator: \n",
    "        sys.stdout.flush()\n",
    "        obj_use = obj\n",
    "        print(\"-------------------\")\n",
    "        print(\"Emulator?:\", emul)\n",
    "        if emul == True:\n",
    "            t = 100\n",
    "            sparse_grid_use = sparse_grid\n",
    "        else:\n",
    "            t = 20\n",
    "            sparse_grid_use = np.array([sparse_grid[0]]) #Sparse Grid will always be False for 2-Input\n",
    "\n",
    "        for sparse in sparse_grid_use:\n",
    "    #         #Can set ep to 1 for sparse grid if wanted\n",
    "            if sparse == True:\n",
    "                obj_use =  np.array([\"obj\"])\n",
    "            else:\n",
    "                obj_use =  obj\n",
    "    #             ep_use = torch.tensor([1]) \n",
    "    #         else:\n",
    "    #             ep_use = explore_bias\n",
    "            print(\"______________________________\")\n",
    "            print(\"Sparse Grid?:\", sparse)  \n",
    "\n",
    "            for obj_func in obj_use:\n",
    "                all_data_doc = find_train_doc_path(emul, obj_func, d, t)\n",
    "                all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\")) \n",
    "                print(\"Objective Function:\", obj_func)\n",
    "                print(\"-  -  -  -  -  -  -  -  -  -  -\")\n",
    "                for i in range(len(sep_fact)):\n",
    "                    explore_bias = set_ep(emul, obj_func, sparse)\n",
    "                    ep = torch.tensor([float(explore_bias)])\n",
    "                    print(\"Separation Factor Train/Test:\", str(np.round(sep_fact[i],3)))\n",
    "                    print(\"Lengthscale Set To:\", set_lengthscale)\n",
    "                    print(\"Explore Bias Multiplier:\", str(np.round(float(ep),3)))\n",
    "                    results = bo_iter_w_runs(BO_iters,all_data_doc,t,theta_mesh,Theta_True,train_iter,ep, Xexp, Yexp,\n",
    "                                                 noise_std, obj_func, runs, sparse, emul, set_lengthscale, Theta_True, \n",
    "                                                 param_dict, bounds_p, bounds_x, verbose, save_fig, shuffle_seed, DateTime, \n",
    "                                                 sep_fact = sep_fact[i], LHS = LHS, skip_param_types = skip_param_types, \n",
    "                                                 eval_all_pairs = eval_all_pairs, normalize = norm, case_study = CS)\n",
    "                    print(\"The GP predicts the lowest SSE of\", \"{:.3e}\".format(np.exp(results[3])), \"occurs at \\u03B8 =\", \n",
    "                          results[2], \"during run\", results[1], \"at BO iteration\", results[0])\n",
    "                    print(\"At this point, the highest EI occurs at \\u03B8 =\", results[4])\n",
    "                    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384bc88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2b725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
