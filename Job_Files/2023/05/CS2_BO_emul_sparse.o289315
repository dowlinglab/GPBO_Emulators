Date and Time:  04-May-2023 (15:34:07)
Case Study:  2.2
Bounds On X Cut (T) or Normal (F)?  True
Dense Grid for Xexp? True
Number of Training Thetas:  200
Number of Experimental Data Points:  30
GP Training Package:  scikit_learn
GP Training Iterations (Gpytorch only):  300
GP Kernel Function:  Mat_52
GP Kernel lengthscale:  1
GP Kernel Has Trained outputscale?:  True
GP Training Restarts (when lengthscale not set):  5
Training Data Noise st.dev:  0.01
Runs: 3
BO Iterations: 30
%%%%%%%%%%%%%%%%%%%%%%%%%%
Norm: False
-------------------
GP Emulating Function Output (T) or SSE (F)? True
______________________________
Sparse Grid?: True
Scaling of Objective Function?  obj
-  -  -  -  -  -  -  -  -  -  -
Separation Factor Train/Test: 1
Lengthscale Set To: 1
Explore Bias Multiplier: 1.0
The GP predicts the lowest SSE of 2.148e+05 occurs at θ = [-1.63587415  1.24386668 -5.36552525 -1.9457134  -1.23928297 -1.51787865
  9.43195915  1.94140351] during run 1 at BO iteration 1
At this point, the highest EI occurs at θ = [-1.03533494 -1.74325848 -0.47707725  1.95306718 -1.0572691  -0.07808274
 14.92232609  1.8301121 ]
True p:  [-1.  -1.  -6.5  0.7  0.   0.  11.   0.6]


