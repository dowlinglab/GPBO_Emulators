{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF, WhiteKernel, Matern\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# from sklearn.metrics import r2_score\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "from scipy.stats import norm, yeojohnson, rankdata, boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Training data\n",
    "df = pd.read_csv('x0_500.csv')\n",
    "# print(df.head())\n",
    "df = df.to_numpy()\n",
    "\n",
    "num_state_pts = 25\n",
    "\n",
    "#extract data\n",
    "X = df[:,:-2]\n",
    "y = df[:, -2].reshape(-1,1)\n",
    "\n",
    "#define scaler, (x-mean(x)) / std(x)\n",
    "X_scaler = preprocessing.StandardScaler().fit(X)\n",
    "# y_scaler = preprocessing.StandardScaler().fit(y)\n",
    "y_scaler = preprocessing.PowerTransformer(method='yeo-johnson').fit(y.reshape(-1,1))\n",
    "# y_scaler = preprocessing.MinMaxScaler().fit(y)\n",
    "# y = y_scaler.transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create histogram for V_scaled\n",
    "# y = y_scaler.transform(y)\n",
    "plt.hist(y, bins=100, density=True, edgecolor='black')  # Adjust the number of bins as needed\n",
    "xmin, xmax = plt.xlim() \n",
    "mu, std = norm.fit(y[~np.isnan(y)])\n",
    "print(mu, std)\n",
    "x = np.linspace(xmin, xmax, 100) \n",
    "p = norm.pdf(x, mu, std) \n",
    "plt.plot(x, p, 'r', linewidth=2) \n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Histogram of ln(V(y0) - V_min(y0) + jitter)')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run LOO in theta\n",
    "def LOO_theta(X, X_scaler, y, y_scaler, num_state_pts):\n",
    "    n_samples = len(X)\n",
    "    predict_mean = []\n",
    "    predict_std = []\n",
    "    for i in range(0, n_samples, num_state_pts):\n",
    "        test_indices = np.arange(i, i + num_state_pts)\n",
    "        X_leave_one = X[test_indices,:]\n",
    "        y_leave_one = y[test_indices,:]\n",
    "\n",
    "        X_rest = np.delete(X,test_indices,axis=0)\n",
    "        y_rest = np.delete(y,test_indices,axis=0)\n",
    "\n",
    "        X_scaled_train = X_scaler.transform(X_rest)\n",
    "        y_scaled_train = y_rest\n",
    "        # y_scaled_train = y_scaler.transform(y_rest)\n",
    "\n",
    "        X_scaled_test = X_scaler.transform(X_leave_one)\n",
    "\n",
    "        #fit GP model\n",
    "        #build and train GP\n",
    "        noise_std = 0.01\n",
    "        retrain_GP =1\n",
    "        seed = 1\n",
    "\n",
    "        #Set noise kernel\n",
    "        noise_kern = WhiteKernel(noise_level=noise_std**2, noise_level_bounds= \"fixed\") #bounds = \"fixed\"\n",
    "        #Set Constant Kernel\n",
    "        cont_kern = ConstantKernel(constant_value = 1, constant_value_bounds = (1e-3,1e4)) #(1e-3,1e4)\n",
    "        #Create full kernel\n",
    "        kernel = cont_kern*Matern(length_scale_bounds=(1e-03, 1e3), nu=2.5) + noise_kern #Matern Kernel\n",
    "        #Set initial model lengthscale to 1\n",
    "        kernel.k1.k2.length_scale = np.ones(X.shape[1])\n",
    "\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-4, n_restarts_optimizer=retrain_GP, \n",
    "                                            random_state = seed, optimizer = \"fmin_l_bfgs_b\", normalize_y = True)\n",
    "\n",
    "        #Fit GP Model\n",
    "        # print(X_scaled_train.shape, y_scaled_train.shape)\n",
    "        gpr.fit(X_scaled_train, y_scaled_train)\n",
    "        print(gpr.kernel_)\n",
    "\n",
    "        #get mean, variance\n",
    "        y_scaled_train_mean, y_scaled_train_std = gpr.predict(X_scaled_train, return_std=True)\n",
    "        y_scaled_test_mean, y_scaled_test_std = gpr.predict(X_scaled_test, return_std=True)\n",
    "        \n",
    "        #inverse transform predicted result\n",
    "        # y_train_mean = y_scaler.inverse_transform(y_scaled_train_mean.reshape(-1,1))\n",
    "        # y_train_std = np.sqrt(y_scaler.var_) * y_scaled_train_std.reshape(-1,1)\n",
    "        y_test_mean = y_scaled_test_mean.reshape(-1,1)\n",
    "        y_test_std = y_scaled_test_std.reshape(-1,1)\n",
    "\n",
    "        #Calc SSE given \"True\" values\n",
    "        # print(y_test_mean, y_leave_one)\n",
    "        SSE = np.sum((y_test_mean - y_leave_one)**2)\n",
    "        errors = 2*(y_test_mean - y_leave_one)**2\n",
    "        SSE_stdev = np.sqrt(errors.T@y_test_std**2)\n",
    "\n",
    "        #record result\n",
    "        predict_mean.append(SSE.flatten())\n",
    "        predict_std.append(SSE_stdev.flatten())\n",
    "\n",
    "    predict_mean = np.array(predict_mean)\n",
    "    predict_std = np.array(predict_std)\n",
    "\n",
    "    R2_score = r2_score(np.zeros(len(predict_mean)), predict_mean)\n",
    "\n",
    "    # print(predict_mean)\n",
    "    # print(predict_std)\n",
    "    # print(R2_score)\n",
    "    \n",
    "    return R2_score, predict_mean, predict_std\n",
    "\n",
    "R2_score, predict_mean, predict_std = LOO_theta(X, X_scaler, y, y_scaler, num_state_pts)\n",
    "\n",
    "text = 'LOO-$R^2$ score: ' + str(np.round(R2_score,2))\n",
    "plt.scatter(np.arange(len(predict_mean)), predict_mean, 30,c='b', marker='D', label='LOO-test point')\n",
    "plt.errorbar(np.arange(len(predict_mean)), predict_mean.flatten(), predict_std.flatten(), c='k', fmt = ' ')\n",
    "\n",
    "plt.xlabel('Experimental SSE',fontdict={'size':15})\n",
    "plt.ylabel('Predicted SSE', fontdict={'size':15})\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run LOO\n",
    "def LOO(X, X_scaler, y, y_scaler):\n",
    "    n_samples = len(X)\n",
    "    predict_mean = []\n",
    "    predict_std = []\n",
    "    for i in range(n_samples):\n",
    "        X_leave_one = X[i]\n",
    "        y_leave_one = y[i]\n",
    "        X_rest = np.delete(X,i,axis=0)\n",
    "        y_rest = np.delete(y,i,axis=0)\n",
    "\n",
    "        X_scaled_train = X_scaler.transform(X_rest)\n",
    "        y_scaled_train = y_rest\n",
    "        # y_scaled_train = y_scaler.transform(y_rest)\n",
    "\n",
    "        X_scaled_test = X_scaler.transform(X_leave_one.reshape(1,-1))\n",
    "\n",
    "        #fit GP model\n",
    "        #build and train GP\n",
    "        noise_std = 0.01\n",
    "        retrain_GP =1\n",
    "        seed = 1\n",
    "\n",
    "        #Set noise kernel\n",
    "        noise_kern = WhiteKernel(noise_level=noise_std**2, noise_level_bounds= \"fixed\") #bounds = \"fixed\"\n",
    "        #Set Constant Kernel\n",
    "        cont_kern = ConstantKernel(constant_value = 1, constant_value_bounds = (1e-3,1e4)) #(1e-3,1e4)\n",
    "        #Create full kernel\n",
    "        kernel = cont_kern*Matern(length_scale_bounds=(1e-03, 1e3), nu=2.5) + noise_kern #Matern Kernel\n",
    "        #Set initial model lengthscale to 1\n",
    "        kernel.k1.k2.length_scale = np.ones(X.shape[1])\n",
    "\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-4, n_restarts_optimizer=retrain_GP, \n",
    "                                            random_state = seed, optimizer = \"fmin_l_bfgs_b\", normalize_y = True)\n",
    "\n",
    "        #Fit GP Model\n",
    "        gpr.fit(X_scaled_train, y_scaled_train)\n",
    "\n",
    "        #get mean, variance\n",
    "        y_scaled_train_mean, y_scaled_train_std = gpr.predict(X_scaled_train, return_std=True)\n",
    "        y_scaled_test_mean, y_scaled_test_std = gpr.predict(X_scaled_test, return_std=True)\n",
    "        \n",
    "        #inverse transform predicted result\n",
    "        # y_train_mean = y_scaler.inverse_transform(y_scaled_train_mean.reshape(-1,1))\n",
    "        # y_train_std = np.sqrt(y_scaler.var_) * y_scaled_train_std.reshape(-1,1)\n",
    "        y_test_mean = y_scaled_test_mean.reshape(-1,1) \n",
    "        y_test_std = y_scaled_test_std.reshape(-1,1)\n",
    "\n",
    "        #record result\n",
    "        predict_mean.append(y_test_mean[0][0])\n",
    "        predict_std.append(y_test_std[0][0])\n",
    "\n",
    "    predict_mean = np.array(predict_mean)\n",
    "    predict_std = np.array(predict_std)\n",
    "\n",
    "    R2_score = r2_score(y, predict_mean)\n",
    "\n",
    "    # print(predict_mean)\n",
    "    # print(predict_std)\n",
    "    # print(R2_score)\n",
    "    \n",
    "    return R2_score, predict_mean, predict_std\n",
    "\n",
    "R2_score, predict_mean, predict_std = LOO(X, X_scaler, y, y_scaler)\n",
    "text = 'LOO-$R^2$ score: ' + str(np.round(R2_score,2))\n",
    "print(text)\n",
    "plt.scatter(y, predict_mean, 30,c='b', marker='D', label='LOO-test point')\n",
    "plt.errorbar(y, predict_mean, predict_std, c='k', fmt = ' ')\n",
    "\n",
    "plt.plot([np.amin(predict_mean),np.amax(predict_mean)],[np.amin(predict_mean),np.amax(predict_mean)],'k--', label='parity line')\n",
    "plt.xlabel('Experimental Scaled Muller Potential',fontdict={'size':15})\n",
    "plt.ylabel('Predicted Scaled Muller Potential', fontdict={'size':15})\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
