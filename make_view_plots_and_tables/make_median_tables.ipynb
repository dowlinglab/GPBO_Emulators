{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc37f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_functions_generic import gen_theta_set\n",
    "\n",
    "from bo_methods_lib.CS2_bo_plotters import plot_obj_abs_min, value_plotter, plot_obj, plot_Theta, plot_Theta_min,path_name, plot_org_train, save_fig, plot_EI_abs_max\n",
    "\n",
    "from bo_methods_lib.CS2_bo_functions_multi_dim import set_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06801f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html\n",
    "\n",
    "def csv_to_array(csv_path):\n",
    "    \"\"\"\n",
    "    Turn a csv file into a numpy array so that it can be used with bo_plotters\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        csv_path: str, path of csv you want to turn into an array\n",
    "    Returns:\n",
    "    --------\n",
    "        csv_array: np.ndarray, array on values in the CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    csv_pd = pd.read_csv(csv_path, index_col = False)\n",
    "    csv_pd.drop(columns=csv_pd.columns[0], \n",
    "        axis=1, \n",
    "        inplace=True)\n",
    "    csv_array = csv_pd.to_numpy()\n",
    "    \n",
    "    return csv_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba0f97ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Method', 'Separation Factor', 'Run', 'Iteration', 'SSE',\n",
      "       'Max Eval', 'Minimum SSE', 'Theta 1', 'Min Theta 1', 'Theta 2',\n",
      "       'Min Theta 2', 'Time/Iter (Minutes)', 'Total Run Time'],\n",
      "      dtype='object')\n",
      "['1A' '1B' '2A' '2B' '2C']\n",
      "[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"CS1_results_by_iter.csv\", header = 0, index_col = None)\n",
    "# print(df.head)\n",
    "print(df.columns)\n",
    "# # print(df.head())\n",
    "\n",
    "# # sort the dataframe\n",
    "df.sort_values(by=['Method', \"Separation Factor\", \"Run\"], axis=0, inplace=True)\n",
    "\n",
    "print(df['Method'].unique())\n",
    "print(df['Separation Factor'].unique())\n",
    "print(df['Run'].unique())\n",
    "\n",
    "best_indecies = []\n",
    "for meth in df['Method'].unique():\n",
    "    for SF in df['Separation Factor'].unique():\n",
    "        for run in df['Run'].unique():\n",
    "            sse_run_best_value = df[\"Minimum SSE\"][(df['Method'] == meth) & (df['Separation Factor'] == SF) & (df['Run'] == run) \n",
    "                                          & (df['Iteration'] == df[\"Max Eval\"]) ]\n",
    "#             print(\"Method\", meth, \"SF\", SF, \"Run\", run)\n",
    "#             print(sse_run_best_value)\n",
    "            index = df.index[(df['Method'] == meth) & (df[\"Run\"] == run) & (df[\"Separation Factor\"] == SF) & (np.isclose(df[\"SSE\"],sse_run_best_value))]\n",
    "            best_indecies.append(index[0])\n",
    "print(len(best_indecies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f74af029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "93.33333333333333\n",
      "100.0\n",
      "100.0\n",
      "53.333333333333336\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_best_run_sse = df.iloc[df.index.isin(best_indecies)]\n",
    "# print(df_best_run_sse.head())\n",
    "\n",
    "names=df_best_run_sse['Method'].unique().tolist()\n",
    "\n",
    "for name in names:\n",
    "    count = 0\n",
    "    sparse_best_sses = df_best_run_sse[\"Minimum SSE\"].loc[(df_best_run_sse['Method'] == name) & (df_best_run_sse['Separation Factor'] >= 1.0)]\n",
    "#     print(sparse_best_sses)\n",
    "    sparse_best_sses = sparse_best_sses.reset_index(drop=True)\n",
    "#     print(sparse_best_sses.head())\n",
    "    for i in range(len(sparse_best_sses)):\n",
    "#         print(sparse_best_sses[i])\n",
    "        if sparse_best_sses[i] >= 0.01:\n",
    "            count +=1\n",
    "    print(((1-(count/len(sparse_best_sses))))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "55d7bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Pred: [99.33333333  5.33333333  0.66666667  2.66666667 62.        ]\n",
      "Good Pred: [ 0.66666667 94.66666667 99.33333333 97.33333333 38.        ]\n",
      "Early Termination: [ 48.           4.66666667   0.           0.         100.        ]\n"
     ]
    }
   ],
   "source": [
    "#Check for early Termination\n",
    "Early_Term = []\n",
    "Bad_Pred = []\n",
    "\n",
    "names=df_best_run_sse['Method'].unique().tolist()\n",
    "\n",
    "for name in names:\n",
    "    df_meth = df_best_run_sse.loc[df_best_run_sse.Method==name]\n",
    "    \n",
    "    early_term_count = 0\n",
    "    Last_iter_count = len(df_meth)\n",
    "    bad_pred_count = 0\n",
    "    df_meth = df_meth.reset_index(drop=True)\n",
    "    for i in range(len(df_meth)):        \n",
    "        if df_meth[\"Minimum SSE\"][i] > 1e-2:\n",
    "#                 print(df[\"SSE\"][i])\n",
    "            bad_pred_count += 1\n",
    "        if df_meth[\"Max Eval\"][i] < 100:\n",
    "            early_term_count += 1\n",
    "\n",
    "#     print(bad_pred_count, Last_iter_count, early_term_count)\n",
    "    if Last_iter_count != 0:\n",
    "        bad_percent = bad_pred_count/Last_iter_count\n",
    "        Bad_Pred.append(bad_percent)\n",
    "        Early_Term.append(early_term_count/Last_iter_count)\n",
    "    else:\n",
    "        Bad_Pred.append(0)\n",
    "        \n",
    "Good_Pred = (1-np.array(Bad_Pred))        \n",
    "print(\"Bad Pred:\", np.array(Bad_Pred)*100)\n",
    "print(\"Good Pred:\", np.array(Good_Pred)*100)\n",
    "print(\"Early Termination:\",np.array(Early_Term)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2380f7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A : 1.111\n",
      "1B : 100.0\n",
      "2A : 100.0\n",
      "2B : 100.0\n",
      "2C : 91.111\n"
     ]
    }
   ],
   "source": [
    "names=df_best_run_sse['Method'].unique().tolist()\n",
    "\n",
    "for name in names:\n",
    "    df_meth = df_best_run_sse.loc[df_best_run_sse.Method==name]\n",
    "\n",
    "    good_pred_count = 0\n",
    "    Last_iter_count = 0\n",
    "    for i in range(len(df_meth)):\n",
    "        df_meth = df_meth.reset_index(drop=True)\n",
    "        if df_meth[\"Separation Factor\"][i] >= 0.5:\n",
    "            if df_meth[\"Min Theta 1\"][i] == df_meth[\"Theta 1\"][i] and df_meth[\"Min Theta 2\"][i] == df_meth[\"Theta 2\"][i]:\n",
    "                Last_iter_count +=1\n",
    "                theta_1_i = df_meth[\"Min Theta 1\"][i]\n",
    "                theta_2_i = df_meth[\"Min Theta 2\"][i]\n",
    "                percent_error = ((((theta_1_i-1)/1)**2 + ((theta_2_i+1)/-1)**2)/2)*100\n",
    "                if percent_error <= 5.0:\n",
    "                    good_pred_count += 1\n",
    "\n",
    "    # print(bad_pred_count, Last_iter_count, early_term_count)\n",
    "    if Last_iter_count != 0:\n",
    "        good_pred_percent = good_pred_count/Last_iter_count\n",
    "\n",
    "    print(name, \":\", np.round(good_pred_percent*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5229af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Method  Separation Factor  Iteration        SSE  Max Eval  Minimum SSE  \\\n",
      "2117      1A                0.4          5  14.474867        17    14.474867   \n",
      "20576     1B                0.9         68   0.000181       100     0.000181   \n",
      "34040     2A                0.8         32   0.002791       100     0.002791   \n",
      "45017     2B                0.6          9   0.002619       100     0.002619   \n",
      "52644     2C                0.5          2   0.279945         2     0.279945   \n",
      "\n",
      "        Theta 1   Theta 2  \n",
      "2117   1.396950 -1.618143  \n",
      "20576  0.995873 -1.005198  \n",
      "34040  0.994391 -0.994333  \n",
      "45017  0.994747 -0.994625  \n",
      "52644  0.887138 -0.933537  \n"
     ]
    }
   ],
   "source": [
    "#create unique list of names\n",
    "# get a list of names\n",
    "names=df_best_run_sse['Method'].unique().tolist()\n",
    "# print(names)\n",
    "# Create a list containing 1 dataframe for each method\n",
    "df_list = []\n",
    "for name in names:\n",
    "    df_meth = df_best_run_sse.loc[df_best_run_sse.Method==name]   \n",
    "    df_list.append(df_meth)\n",
    "\n",
    "#Create new df for median values\n",
    "df_median = pd.DataFrame()\n",
    "\n",
    "#Loop over all method dataframes\n",
    "for df_meth in df_list:\n",
    "    #Add the row corresponding to the median value of SSE to the list\n",
    "    df_median = pd.concat([df_median,df_meth[df_meth['SSE']==df_meth['SSE'].quantile(interpolation='nearest')]])\n",
    "#Drop unneeded columns\n",
    "df_median = df_median.drop([\"Run\", \"Time/Iter (Minutes)\", \"Min Theta 1\", \"Min Theta 2\", \"Unnamed: 0\", \"Total Run Time\"], axis =1)\n",
    "\n",
    "print(df_median)\n",
    "df_median.to_csv(\"CS1_results_best_sse_median.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4477687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Method  Separation Factor  Iteration        SSE  Max Eval  Minimum SSE  \\\n",
      "7718      1A                1.0         34  11.301864       100    11.301864   \n",
      "8353      1B                0.1         69   0.005777       100     0.000855   \n",
      "28934     2A                0.5         26   0.003013       100     0.000771   \n",
      "40847     2B                0.3         39   0.002895       100     0.002710   \n",
      "52669     2C                0.5          5   0.198062         8     0.198062   \n",
      "\n",
      "        Theta 1   Theta 2  \n",
      "7718   1.042161 -1.579298  \n",
      "8353   1.005438 -1.014776  \n",
      "28934  0.993380 -0.993982  \n",
      "40847  0.993693 -0.994164  \n",
      "52669  0.865306 -0.972494  \n"
     ]
    }
   ],
   "source": [
    "#Fiind median SSE over all runs, check for early termination, and number of good predictions\n",
    "df = pd.read_csv(\"CS1_results_by_iter.csv\", header = 0)\n",
    "\n",
    "# print(df.columns)\n",
    "# # print(df.head())\n",
    "\n",
    "# # sort the dataframe\n",
    "df.sort_values(by=['Method', \"Separation Factor\", \"Run\"], axis=0, inplace=True)\n",
    "df = df.drop( ['Unnamed: 0'], axis =1)\n",
    "# print(df['Method'].unique())\n",
    "# print(df['Separation Factor'].unique())\n",
    "# print(df['Run'].unique())\n",
    "\n",
    "names=df['Method'].unique().tolist()\n",
    "# Create a list containing 1 dataframe for each method\n",
    "df_list = []\n",
    "for name in names:\n",
    "    df_meth = df.loc[df.Method==name]   \n",
    "    df_list.append(df_meth)\n",
    "\n",
    "#Create new df for median values\n",
    "df_median = pd.DataFrame()\n",
    "\n",
    "#Loop over all method dataframes\n",
    "for df_meth in df_list:\n",
    "    #Add the row corresponding to the median value of SSE to the list\n",
    "    df_median = pd.concat([df_median,df_meth[df_meth['SSE']==df_meth['SSE'].quantile(interpolation='nearest')]])\n",
    "df_median = df_median.drop([\"Run\", \"Time/Iter (Minutes)\", \"Min Theta 1\", \"Min Theta 2\", \"Total Run Time\"], axis =1)\n",
    "\n",
    "print(df_median)\n",
    "df_median.to_csv(\"CS1_results_true_median.csv\", index=False)\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0da710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Pred: [99.33333333  5.33333333  0.66666667  2.66666667 62.        ]\n",
      "Good Pred: [ 0.66666667 94.66666667 99.33333333 97.33333333 38.        ]\n",
      "Early Termination: [ 48.           4.66666667   0.           0.         100.        ]\n"
     ]
    }
   ],
   "source": [
    "#Check for early Termination\n",
    "Early_Term = []\n",
    "Bad_Pred = []\n",
    "\n",
    "names=df['Method'].unique().tolist()\n",
    "\n",
    "for name in names:\n",
    "    df_meth = df.loc[df.Method==name]\n",
    "    \n",
    "    early_term_count = 0\n",
    "    Last_iter_count = 0\n",
    "    bad_pred_count = 0\n",
    "    df_meth = df_meth.reset_index(drop=True)\n",
    "    for i in range(len(df_meth)):        \n",
    "        if df_meth[\"Iteration\"][i] == df_meth[\"Max Eval\"][i]:\n",
    "            Last_iter_count +=1\n",
    "            if df_meth[\"Minimum SSE\"][i] > 1e-2:\n",
    "    #                 print(df[\"SSE\"][i])\n",
    "                bad_pred_count += 1\n",
    "            if df_meth[\"Max Eval\"][i] != 100:\n",
    "                early_term_count += 1\n",
    "\n",
    "#     print(bad_pred_count, Last_iter_count, early_term_count)\n",
    "    if Last_iter_count != 0:\n",
    "        bad_percent = bad_pred_count/Last_iter_count\n",
    "        Bad_Pred.append(bad_percent)\n",
    "        Early_Term.append(early_term_count/Last_iter_count)\n",
    "    else:\n",
    "        Bad_Pred.append(0)\n",
    "        \n",
    "Good_Pred = (1-np.array(Bad_Pred))        \n",
    "print(\"Bad Pred:\", np.array(Bad_Pred)*100)\n",
    "print(\"Good Pred:\", np.array(Good_Pred)*100)\n",
    "print(\"Early Termination:\",np.array(Early_Term)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dafdd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
