{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-17 16:26:05.430176: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-17 16:26:05.430233: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-17 16:26:05.431693: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-17 16:26:05.439678: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 16:26:06.842169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.analyze_data import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pympler\n",
    "import pickle\n",
    "import signac\n",
    "\n",
    "from pympler import asizeof\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "#Ignore inconcistent version warning\n",
    "import warnings\n",
    "# from sklearn.exceptions import InconsistentVersionWarning\n",
    "# warnings.filterwarnings(action='ignore', category=InconsistentVersionWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤════════════════════════╕\n",
      "│ name                               │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │ value                  │\n",
      "╞════════════════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪════════════════════════╡\n",
      "│ GPR.kernel.kernels[0].variance     │ Parameter │ Softplus         │         │ False       │ ()      │ float64 │ 1.0                    │\n",
      "├────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼────────────────────────┤\n",
      "│ GPR.kernel.kernels[0].lengthscales │ Parameter │ Softplus         │         │ False       │ (3,)    │ float64 │ [1. 1. 1.]             │\n",
      "├────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼────────────────────────┤\n",
      "│ GPR.kernel.kernels[1].variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 0.9999999999999999     │\n",
      "├────────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼────────────────────────┤\n",
      "│ GPR.likelihood.variance            │ Parameter │ Softplus + Shift │         │ False       │ ()      │ float64 │ 1.0000000000000004e-05 │\n",
      "╘════════════════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧════════════════════════╛\n",
      "[89.12735044]\n",
      "[[5200.89608643]]\n"
     ]
    }
   ],
   "source": [
    "#Set Date and Time\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S)\")\n",
    "# print(\"Date and Time: \", timestampStr)\n",
    "# DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M-%S%p\")\n",
    "DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M\")\n",
    "DateTime = None ##For Testing\n",
    "\n",
    "cs_name1  = CS_name_enum(1)\n",
    "cs_name2  = CS_name_enum(2)\n",
    "\n",
    "# #Define small case study\n",
    "# num_x_data = 5\n",
    "# gen_meth_x = Gen_meth_enum(2)\n",
    "# num_theta_data1 = 20\n",
    "# num_theta_data2 = 20\n",
    "# gen_meth_theta = Gen_meth_enum(1)\n",
    "\n",
    "# ep0 = 1\n",
    "# sep_fact = 0.8\n",
    "# normalize = True\n",
    "# noise_mean = 0\n",
    "# noise_std = 0.01\n",
    "# kernel = Kernel_enum(1)\n",
    "# lenscl = None\n",
    "# outputscl = None\n",
    "# retrain_GP = 1\n",
    "# seed = 1\n",
    "# method = GPBO_Methods(Method_name_enum(1)) #1A\n",
    "\n",
    "#Define cs_params, simulator, and exp_data for CS1\n",
    "# simulator1 = simulator_helper_test_fxns(cs_name1.value, noise_mean, noise_std, seed)\n",
    "# exp_data1 = simulator1.gen_exp_data(num_x_data, gen_meth_x)\n",
    "# sim_data1 = simulator1.gen_sim_data(num_theta_data1, num_x_data, gen_meth_theta, gen_meth_x, sep_fact)\n",
    "# sim_sse_data1 = simulator1.sim_data_to_sse_sim_data(method, sim_data1, exp_data1, sep_fact)\n",
    "# val_data1 = simulator1.gen_sim_data(num_theta_data1, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, True)\n",
    "# val_sse_data1 = simulator1.sim_data_to_sse_sim_data(method, val_data1, exp_data1, sep_fact, True)\n",
    "# gp_emulator1_s = Type_1_GP_Emulator(sim_sse_data1, val_sse_data1, None, None, None, kernel, lenscl, noise_std, outputscl, retrain_GP, seed, normalize, None, None, None, None)\n",
    "\n",
    "# #Define cs_params, simulator, and exp_data for CS2\n",
    "# simulator2 = simulator_helper_test_fxns(cs_name2.value, noise_mean, noise_std, seed)\n",
    "# exp_data2 = simulator2.gen_exp_data(num_x_data, gen_meth_x)\n",
    "# sim_data2 = simulator2.gen_sim_data(num_theta_data2, num_x_data, gen_meth_theta, gen_meth_x, sep_fact)\n",
    "# sim_sse_data2 = simulator2.sim_data_to_sse_sim_data(method, sim_data2, exp_data2, sep_fact)\n",
    "# val_data2 = simulator2.gen_sim_data(num_theta_data2, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, True)\n",
    "# val_sse_data2 = simulator2.sim_data_to_sse_sim_data(method, val_data2, exp_data2, sep_fact, True)\n",
    "# gp_emulator2_s = Type_1_GP_Emulator(sim_sse_data2, val_sse_data2, None, None, None, kernel, lenscl, noise_std, outputscl, retrain_GP, seed, normalize, None, None, None, None)\n",
    "\n",
    "#Define small case study\n",
    "num_x_data = 5\n",
    "gen_meth_x = Gen_meth_enum(2)\n",
    "num_theta_data1 = 10\n",
    "num_theta_data2 = 5\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "\n",
    "ep0 = 1\n",
    "sep_fact = 0.8\n",
    "normalize = True\n",
    "noise_mean = 0\n",
    "noise_std = 0.01\n",
    "kernel = Kernel_enum(1)\n",
    "lenscl = 1\n",
    "outputscl = 1\n",
    "retrain_GP = 0\n",
    "seed = 1\n",
    "method = GPBO_Methods(Method_name_enum(5)) #2C\n",
    "\n",
    "#Define cs_params, simulator, and exp_data for CS1\n",
    "simulator1 = simulator_helper_test_fxns(cs_name1.value, noise_mean, noise_std, seed)\n",
    "exp_data1 = simulator1.gen_exp_data(num_x_data, gen_meth_x)\n",
    "sim_data1 = simulator1.gen_sim_data(num_theta_data1, num_x_data, gen_meth_theta, gen_meth_x, sep_fact)\n",
    "val_data1 = simulator1.gen_sim_data(num_theta_data1, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, True)\n",
    "gp_emulator1_e = Type_2_GP_Emulator(sim_data1, val_data1, None, None, None, kernel, lenscl, noise_std, outputscl, retrain_GP, seed, normalize, None, None, None, None)\n",
    "\n",
    "#Define cs_params, simulator, and exp_data for CS2\n",
    "simulator2 = simulator_helper_test_fxns(cs_name2.value, noise_mean, noise_std, seed)\n",
    "exp_data2 = simulator2.gen_exp_data(num_x_data, gen_meth_x)\n",
    "sim_data2 = simulator2.gen_sim_data(num_theta_data2, num_x_data, gen_meth_theta, gen_meth_x, sep_fact)\n",
    "val_data2 = simulator2.gen_sim_data(num_theta_data2, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, True)\n",
    "gp_emulator2_e = Type_2_GP_Emulator(sim_data2, val_data2, None, None, None, kernel, lenscl, noise_std, outputscl, retrain_GP, seed, normalize, None, None, None, None)\n",
    "\n",
    "gp_emulator = gp_emulator1_e\n",
    "exp_data = exp_data1\n",
    "simulator = simulator1\n",
    "covar = False\n",
    "train_data, test_data = gp_emulator.set_train_test_data(sep_fact, seed)\n",
    "gp_emulator.train_gp()\n",
    "misc_data = Data(None, exp_data.x_vals, None, None,None,None,None,None, simulator.bounds_theta_reg, simulator.bounds_x, sep_fact, seed)\n",
    "theta = gp_emulator.gp_val_data.theta_vals[0].reshape(1,-1) #Set \"candidate thetas\"\n",
    "theta_vals = np.repeat(theta.reshape(1,-1), exp_data.get_num_x_vals() , axis =0)\n",
    "misc_data.theta_vals = theta_vals #Set misc thetas\n",
    "feature_misc_data = gp_emulator.featurize_data(misc_data) #Set feature vals\n",
    "misc_data.gp_mean, misc_data.gp_var = gp_emulator.eval_gp_mean_var_misc(misc_data, feature_misc_data) #Calc mean, var of gp \n",
    "sse_mean, sse_var = gp_emulator.eval_gp_sse_var_misc(misc_data, method, exp_data, covar) #Calc mean, var of gp sse\n",
    "print(sse_mean)\n",
    "print(sse_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Make GP and Simulator class\n",
    "results = open_file_helper(\"workspace/e31ffa2021732474e0e522d4a7a03aee/BO_Results.gz\")\n",
    "#95d031378d09ba17c4c6b58f8ac05a60\n",
    "#4ad8f582072ab96cee11bc3b6aca30f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 1\n",
    "biter = 50\n",
    "gp_object = copy.copy(results[run-1].list_gp_emulator_class[biter-1])\n",
    "simulator = copy.copy(results[run-1].simulator_class)\n",
    "exp_data = copy.copy(results[run-1].exp_data_class)\n",
    "meth_name = Method_name_enum(results[0].configuration[\"Method Name Enum Value\"])\n",
    "method = GPBO_Methods(meth_name)\n",
    "# print(gp_object.train_data_init)\n",
    "# print(gp_object.noise_std)\n",
    "# print(simulator.noise_std)\n",
    "# print(float(scipy.special.polygamma(1, (4*simulator.noise_std**2)/2)))\n",
    "# print(gp_object.scalerY.lambdas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale training data if necessary\n",
    "feature_train_data_scaled = gp_object.scalerX.transform(gp_object.feature_train_data)\n",
    "y_train_data_scaled = gp_object.scalerY.transform(gp_object.train_data.y_vals.reshape(-1,1))\n",
    "y = y_train_data_scaled\n",
    "# y = gp_object.train_data.y_vals.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=int(len(y)/10), density=True, stacked= True, edgecolor='black')  # Adjust the number of bins as needed\n",
    "xmin, xmax = plt.xlim() \n",
    "mu, std = norm.fit(y[~np.isnan(y)])\n",
    "x = np.linspace(xmin, xmax, 100) \n",
    "p = norm.pdf(x, mu, std) \n",
    "plt.plot(x, p, 'r', linewidth=2) \n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(r'y^{sim}' +' Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Histogram of Müller ' + r'$y_0$' ' Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate gp_mean over x values\n",
    "#Generate validation data\n",
    "val_data = simulator.gen_sim_data(15, exp_data.get_num_x_vals(), Gen_meth_enum(1), Gen_meth_enum(2), 1.0, simulator.seed, False)\n",
    "if method.emulator == False:\n",
    "    val_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, 1.0, False)\n",
    "feat_val = gp_object.featurize_data(val_data)\n",
    "\n",
    "gp_object.retrain_GP = 25\n",
    "\n",
    "#Get gp mean\n",
    "#Change hps of fit gp model or retrain GP\n",
    "# simulator.noise_std = np.sqrt(float(scipy.special.polygamma(1, (4*simulator.noise_std**2)/2)))\n",
    "# gp_object.noise_std = None\n",
    "# new_gp_model.kernel.kernels[0].variance.assign(1.19**2)\n",
    "# new_gp_model.kernel.kernels[0].lengthscales.assign([4.45,4.45,0.417])\n",
    "# new_gp_model.kernel.kernels[1].variance.assign(0.0013140374228778637)\n",
    "# gpflow.utilities.set_trainable(new_gp_model.kernel.kernels[0].variance, False)\n",
    "# gpflow.utilities.set_trainable(new_gp_model.kernel.kernels[0].lengthscales, False)\n",
    "# gpflow.utilities.set_trainable(new_gp_model.kernel.kernels[1].variance, False)\n",
    "gp_object.train_gp()\n",
    "gpflow.utilities.print_summary(gp_object.fit_gp_model)\n",
    "# gp_object.fit_gp_model.kernel.kernels[0].variance.assign(1.73)\n",
    "# gp_object.fit_gp_model.kernel.kernels[0].lengthscales.assign([3.45,3.45])\n",
    "# gp_object.fit_gp_model.kernel_.k1.k2.length_scale = np.array([3.46, 3.34, 0.708, 3.74, 0.444, 3.5])\n",
    "# gp_object.fit_gp_model.kernel_.k2.noise_level = 0.0577\n",
    "# gp_object.fit_gp_model.kernel_.k1.k1.constant_value = 4\n",
    "\n",
    "misc_gp_mean, misc_var_return = gp_object.eval_gp_mean_var_misc(val_data, feat_val, covar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(misc_var_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gp_object.trained_hyperparams)\n",
    "gpflow.utilities.print_summary(gp_object.fit_gp_model)\n",
    "#0.976**2 * Matern(length_scale=[3.46, 3.34, 0.708, 3.74, 0.444, 0.464], nu=2.5) + WhiteKernel(noise_level=0.0577)\n",
    "#0.965**2 * Matern(length_scale=[3.31, 2.83, 0.667, 2.2, 0.365, 0.395], nu=2.5) + WhiteKernel(noise_level=0.00259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse= np.sum((val_data.y_vals - misc_gp_mean)**2)/len(val_data.y_vals)\n",
    "print(\"MSE:\", mse)\n",
    "plt.figure()\n",
    "plt.plot(val_data.y_vals, val_data.y_vals, color='red', alpha=0.7)\n",
    "plt.scatter(val_data.y_vals, misc_gp_mean, color='blue', alpha=0.7)\n",
    "plt.errorbar(val_data.y_vals, misc_gp_mean, yerr = 1.96*np.sqrt(abs(misc_var_return)), alpha=0.3, fmt = 'o', color = \"blue\")\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Parity Plot')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
