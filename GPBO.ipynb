{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9c0f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_functions_generic import gen_theta_set, clean_1D_arrays\n",
    "from bo_methods_lib.CS2_bo_functions_multi_dim import bo_iter_w_runs, find_train_doc_path, set_ep\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "#----------------------------------------------\n",
    "CS = 1\n",
    "\n",
    "#Set Date and Time\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d-%b-%Y (%H:%M:%S)\")\n",
    "print(\"Date and Time: \", timestampStr)\n",
    "# DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M-%S%p\")\n",
    "DateTime = dateTimeObj.strftime(\"%Y/%m/%d/%H-%M\")\n",
    "# DateTime = None ##For Testing\n",
    "\n",
    "#Set Parameters\n",
    "#Need to run at a and b, need 2 arrays to test that this will work\n",
    "if CS == 2.2:\n",
    "    Bound_Cut = True\n",
    "    denseX = True\n",
    "    Constants = np.array([[-200,-100,-170,15],\n",
    "                          [-1,-1,-6.5,0.7],\n",
    "                          [0,0,11,0.6],\n",
    "                          [-10,-10,-6.5,0.7],\n",
    "                          [1,0,-0.5,-1],\n",
    "                          [0,0.5,1.5,1]])\n",
    "\n",
    "    skip_param_types = 1 #This is what changes for subpoint\n",
    "    true_p = Constants[skip_param_types:skip_param_types+2].flatten()\n",
    "    param_dict = {0 : 'a_1', 1 : 'a_2', 2 : 'a_3', 3 : 'a_4',\n",
    "                  4 : 'b_1', 5 : 'b_2', 6 : 'b_3', 7 : 'b_4'}\n",
    "    exp_d = 2\n",
    "\n",
    "    if Bound_Cut == True:\n",
    "        bounds_x = np.array([[-1.0, 0.0],\n",
    "                            [   0.5, 1.5]])\n",
    "        if denseX == True:\n",
    "            n = 30\n",
    "        else:\n",
    "            n = 25 #Number of experimental data points to use\n",
    "    else:    \n",
    "        bounds_x = np.array([[-1.5, -0.5],\n",
    "                     [   1,    2]])\n",
    "        n = 27 #Number of experimental data points to use\n",
    "    bounds_p = np.array([[-2, -2, -10, -2, -2, -2,  5, -2],\n",
    "                   [ 2,  2,   0,  2,  2,  2, 15,  2]])\n",
    "else:\n",
    "    Bound_Cut = False\n",
    "    denseX = False\n",
    "    Constants = true_p = np.array([1,-1])\n",
    "    skip_param_types = 0\n",
    "    param_dict = {0 : '\\\\theta_1', 1 : '\\\\theta_2'}\n",
    "    exp_d = 1\n",
    "    n = 5\n",
    "    bounds_x = np.array([[-2], [2]])\n",
    "    bounds_p = np.array([[-2, -2],\n",
    "                         [ 2,  2]])\n",
    "\n",
    "d = len(true_p)\n",
    "BO_iters = 2\n",
    "runs = 2\n",
    "train_iter = 300\n",
    "noise_std = 0.01\n",
    "shuffle_seed = 9\n",
    "sep_fact = [1]\n",
    "set_lengthscale = None\n",
    "explore_bias = 1\n",
    "\n",
    "skip_param_types = 1\n",
    "eval_all_pairs = True\n",
    "# eval_all_pairs = False\n",
    "package = \"scikit_learn\"\n",
    "kernel = \"Mat_52\"\n",
    "outputscl = True \n",
    "initialize = 1\n",
    "\n",
    "obj = np.array([\"LN_obj\"])\n",
    "# obj = np.array([\"obj\"])\n",
    "# obj = np.array([\"obj\",\"LN_obj\"])\n",
    "# emulator = False\n",
    "emulator = np.array([False])\n",
    "# emulator = np.array([True])\n",
    "sparse_grid = np.array([False])\n",
    "# sparse_grid = np.array([True])\n",
    "norm = False\n",
    "# norm = False\n",
    "# sparse_grid = np.array([False,True])\n",
    "verbose = False\n",
    "# verbose = True\n",
    "# save_fig = True\n",
    "save_fig = False\n",
    "save_CSV = False\n",
    "\n",
    "if Bound_Cut == True:\n",
    "    cut_bounds = '_cut_bounds'\n",
    "else:\n",
    "    cut_bounds = \"\"\n",
    "\n",
    "if denseX == True:\n",
    "    dense = \"_dense\"\n",
    "else:\n",
    "    dense = \"\"\n",
    "\n",
    "#Pull Experimental data from CSV\n",
    "exp_data_doc = 'Input_CSVs/Exp_Data/d='+str(exp_d)+'/n='+str(n)+cut_bounds+dense+'.csv'\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1:exp_d+1]\n",
    "Yexp = exp_data[:,-1]\n",
    "Xexp = clean_1D_arrays(Xexp)\n",
    "# print(Xexp)\n",
    "# print(Yexp)\n",
    "#Define GP Testing space\n",
    "\n",
    "LHS = False\n",
    "p_train = 20\n",
    "p=20 #int(np.sqrt(5**d)) #5 points per dimension in original theta set\n",
    "# Theta1 =  np.linspace(-2,2,p) #1x10\n",
    "# Theta2 =  np.linspace(-2,2,p) #1x10\n",
    "# theta_mesh = np.array(np.meshgrid(Theta1, Theta2)) #2 Uniform 5x5 arrays \n",
    "theta_mesh = gen_theta_set(LHS = LHS, n_points = p, dimensions = d, bounds = bounds_p, seed = 1)\n",
    "print(len(theta_mesh))\n",
    "\n",
    "print(\"Runs:\", runs)\n",
    "print(\"BO Iterations:\",BO_iters)\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "for emul in emulator: \n",
    "    sys.stdout.flush()\n",
    "    obj_use = obj\n",
    "    print(\"-------------------\")\n",
    "    print(\"Emulator?:\", emul)\n",
    "    if emul == True: #Change this based on number of TP for each test\n",
    "        t = p_train*n\n",
    "        sparse_grid_use = sparse_grid\n",
    "    else:\n",
    "        t = p_train\n",
    "        sparse_grid_use = np.array([sparse_grid[0]]) #Sparse Grid will always be False for 2-Input\n",
    "        \n",
    "    for sparse in sparse_grid_use:\n",
    "#         #Can set ep to 1 for sparse grid if wanted\n",
    "        if sparse == True:\n",
    "            obj_use =  np.array([\"obj\"])\n",
    "        else:\n",
    "            obj_use =  obj\n",
    "#             ep_use = torch.tensor([1]) \n",
    "#         else:\n",
    "#             ep_use = explore_bias\n",
    "        print(\"______________________________\")\n",
    "        print(\"Sparse Grid?:\", sparse)  \n",
    "\n",
    "        for obj_func in obj_use:\n",
    "            all_data_doc = find_train_doc_path(emul, obj_func, d, t, Bound_Cut, denseX)\n",
    "            all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\")) \n",
    "            print(\"Objective Function:\", obj_func)\n",
    "            print(\"-  -  -  -  -  -  -  -  -  -  -\")\n",
    "            for i in range(len(sep_fact)):\n",
    "#                 explore_bias = set_ep(emul, obj_func, sparse)\n",
    "                ep = torch.tensor([float(explore_bias)])\n",
    "                print(\"Separation Factor Train/Test:\", str(np.round(sep_fact[i],3)))\n",
    "                print(\"Lengthscale Set To:\", set_lengthscale)\n",
    "                print(\"Explore Bias Multiplier:\", str(np.round(float(ep),3)))\n",
    "                results = bo_iter_w_runs(BO_iters,all_data_doc,t,theta_mesh,true_p,train_iter,ep, Xexp, Yexp,\n",
    "                                                 noise_std, obj_func, runs, sparse, emul, package, kernel, set_lengthscale, outputscl, \n",
    "                                                 initialize, Constants, param_dict, bounds_p, bounds_x, verbose, save_fig, save_CSV,\n",
    "                                                 shuffle_seed, DateTime, sep_fact = sep_fact[i], LHS = LHS, skip_param_types = skip_param_types, \n",
    "                                                 eval_all_pairs = eval_all_pairs, normalize = norm, case_study = CS)\n",
    "#                 results = bo_iter_w_runs(BO_iters,all_data_doc,t,theta_mesh,true_p,train_iter,ep, Xexp, Yexp,\n",
    "#                                              noise_std, obj_func, runs, sparse, emul, set_lengthscale, Constants, \n",
    "#                                              param_dict, verbose, save_fig, shuffle_seed, DateTime, sep_fact = sep_fact[i], \n",
    "#                                              LHS = LHS, skip_param_types = skip_param_types, eval_all_pairs = eval_all_pairs)\n",
    "                print(\"The GP predicts the lowest SSE of\", \"{:.3e}\".format(np.exp(results[3])), \"occurs at \\u03B8 =\", results[2], \n",
    "                          \"during run\", results[1], \"at BO iteration\", results[0])\n",
    "                print(\"At this point, the highest EI occurs at \\u03B8 =\", results[4])\n",
    "                print(\"\\n\")\n",
    "print(true_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403ff5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
