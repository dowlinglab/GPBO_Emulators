{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.analyze_data import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pympler\n",
    "import pickle\n",
    "import signac\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from pympler import asizeof\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "from textwrap import fill\n",
    "\n",
    "#Ignore inconcistent version warning\n",
    "import warnings\n",
    "# from sklearn.exceptions import InconsistentVersionWarning\n",
    "# warnings.filterwarnings(action='ignore', category=InconsistentVersionWarning)\n",
    "import tensorflow_probability as tfp\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Simulator and Training Data\n",
    "cs_name_val = 3\n",
    "noise_mean = 0\n",
    "noise_std = None\n",
    "seed = 1\n",
    "#Define method, ep_enum classes, indecies to consider, and kernel\n",
    "meth_name = Method_name_enum(3)\n",
    "method = GPBO_Methods(meth_name)\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "gen_meth_x = Gen_meth_enum(2)\n",
    "num_x_data = 5\n",
    "\n",
    "#Define Simulator Class (Export your Simulator Object Here)\n",
    "simulator = simulator_helper_test_fxns(cs_name_val, noise_mean, noise_std, seed)\n",
    "num_theta_data = len(simulator.indeces_to_consider)*10\n",
    "#Generate Exp Data (OR Add your own experimental data as a Data class object)\n",
    "set_seed = 1 #Set set_seed to 1 for data generation\n",
    "gen_meth_x = Gen_meth_enum(gen_meth_x)\n",
    "exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x, set_seed)\n",
    "#Set simulator noise_std artifically as 5% of y_exp mean (So that noise will be set rather than trained)\n",
    "simulator.noise_std = np.abs(np.mean(exp_data.y_vals))*0.05\n",
    "print(simulator.noise_std)\n",
    "#Note at present, training data is always the same between jobs since we set the data generation seed to 1\n",
    "sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, 1.0, seed, False)\n",
    "val_data = simulator.gen_sim_data(10, 10, Gen_meth_enum(1), Gen_meth_enum(1), 1.0, seed + 1, False)\n",
    "# print(sim_data.theta_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method.emulator == True:\n",
    "    all_gp_data = sim_data\n",
    "    all_val_data = val_data\n",
    "else:\n",
    "    all_gp_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, 1.0, False)\n",
    "    print(len(all_gp_data.theta_vals), len(all_gp_data.x_vals), len(all_gp_data.y_vals))\n",
    "    all_val_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, 1.0, False)\n",
    "    print(len(all_val_data.theta_vals), len(all_val_data.x_vals), len(all_val_data.y_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale training data if necessary\n",
    "scalerY = RobustScaler(unit_variance = True)\n",
    "# scalerY = StandardScaler()\n",
    "y = scalerY.fit_transform(sim_data.y_vals.reshape(-1,1))\n",
    "y_test = scalerY.transform(val_data.y_vals.reshape(-1,1))\n",
    "# y = sim_data.y_vals.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=50, cumulative = True, density=True, stacked=True, edgecolor = 'k', label = \"Train\") \n",
    "plt.hist(y_test, bins=50, cumulative = True, stacked=True, density=True, label = \"Test\", edgecolor = 'k', alpha = 0.5) # Adjust the number of bins as needed\n",
    "xmin, xmax = plt.xlim() \n",
    "mu, std = norm.fit(y[~np.isnan(y)])\n",
    "x = np.linspace(xmin, xmax, 100) \n",
    "p = norm.cdf(x, mu, std) \n",
    "# plt.plot(x, p, 'g', linewidth=2, label = \"Normal CDF\") \n",
    "\n",
    "percentile_90_train = np.percentile(y[~np.isnan(y)], 95)\n",
    "percentile_90_test = np.percentile(y_test[~np.isnan(y_test)], 95)\n",
    "print(percentile_90_train, percentile_90_test)\n",
    "\n",
    "val1 = -2\n",
    "val2 = 2\n",
    "train_between = np.sum((y >= val1) & (y <= val2))\n",
    "train_proportion = train_between / len(y)\n",
    "\n",
    "# Calculate the proportion for the testing set\n",
    "test_between = np.sum((y_test >= val1) & (y_test <= val2))\n",
    "test_proportion = test_between / len(y_test)\n",
    "\n",
    "print(train_proportion, test_proportion)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(r'$y^{sim}$' +' Value')\n",
    "plt.ylabel('Cumulative Probability Density')\n",
    "plt.title('Histogram of MÃ¼ller ' + r'$y_0$' ' Data')\n",
    "plt.legend(loc = \"best\")\n",
    "\n",
    "plt.savefig(\"cs3_hist.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
