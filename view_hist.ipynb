{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.analyze_data import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pympler\n",
    "import pickle\n",
    "import signac\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from pympler import asizeof\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "#Ignore inconcistent version warning\n",
    "import warnings\n",
    "# from sklearn.exceptions import InconsistentVersionWarning\n",
    "# warnings.filterwarnings(action='ignore', category=InconsistentVersionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Simulator and Training Data\n",
    "cs_name_val = 17\n",
    "noise_mean = 0\n",
    "noise_std = None\n",
    "seed = 1\n",
    "#Define method, ep_enum classes, indecies to consider, and kernel\n",
    "meth_name = Method_name_enum(3)\n",
    "method = GPBO_Methods(meth_name)\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "gen_meth_x = Gen_meth_enum(2)\n",
    "num_x_data = 12\n",
    "\n",
    "#Define Simulator Class (Export your Simulator Object Here)\n",
    "simulator = simulator_helper_test_fxns(cs_name_val, noise_mean, noise_std, seed)\n",
    "num_theta_data = len(simulator.indeces_to_consider)*10\n",
    "#Generate Exp Data (OR Add your own experimental data as a Data class object)\n",
    "set_seed = 1 #Set set_seed to 1 for data generation\n",
    "gen_meth_x = Gen_meth_enum(gen_meth_x)\n",
    "exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x, set_seed)\n",
    "#Set simulator noise_std artifically as 5% of y_exp mean (So that noise will be set rather than trained)\n",
    "simulator.noise_std = np.abs(np.mean(exp_data.y_vals))*0.05\n",
    "print(simulator.noise_std)\n",
    "#Note at present, training data is always the same between jobs since we set the data generation seed to 1\n",
    "sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, 1.0, seed, False)\n",
    "val_data = simulator.gen_sim_data(15, 15, Gen_meth_enum(1), Gen_meth_enum(1), 1.0, seed + 1, False)\n",
    "# print(sim_data.theta_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method.emulator == True:\n",
    "    all_gp_data = sim_data\n",
    "    all_val_data = val_data\n",
    "else:\n",
    "    all_gp_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, 1.0, False)\n",
    "    print(len(all_gp_data.theta_vals), len(all_gp_data.x_vals), len(all_gp_data.y_vals))\n",
    "    all_val_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, 1.0, False)\n",
    "    print(len(all_val_data.theta_vals), len(all_val_data.x_vals), len(all_val_data.y_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale training data if necessary\n",
    "scalerY = RobustScaler(unit_variance = True)\n",
    "# scalerY = StandardScaler()\n",
    "y = scalerY.fit_transform(sim_data.y_vals.reshape(-1,1))\n",
    "y_test = scalerY.transform(val_data.y_vals.reshape(-1,1))\n",
    "# y = sim_data.y_vals.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=int(len(y)), density=True, edgecolor = 'k', label = \"Train\") \n",
    "plt.hist(y_test, bins=int(len(y_test)), density=True, label = \"Test\") # Adjust the number of bins as needed\n",
    "xmin, xmax = plt.xlim() \n",
    "mu, std = norm.fit(y[~np.isnan(y)])\n",
    "x = np.linspace(xmin, xmax, 100) \n",
    "p = norm.pdf(x, mu, std) \n",
    "# plt.plot(x, p, 'r', linewidth=2) \n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('y Value')\n",
    "plt.legend(loc = \"best\")\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Histogram of CS' + str(cs_name_val) + ' Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(y.flatten()**2)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test GPs\n",
    "#Make CS Params\n",
    "retrain_GP = 5\n",
    "normalize = True\n",
    "noise_std = simulator.noise_std #Yexp_std is exactly the noise_std of the GP Kernel\n",
    "print(noise_std)\n",
    "\n",
    "#Make Emulator\n",
    "#Evaluate GP Mean and Variance\n",
    "# gp_object = Type_1_GP_Emulator(all_gp_data, all_val_data, None, None, None, Kernel_enum(1), None, noise_std, None, \n",
    "#                                 retrain_GP, seed, normalize, None, None, None, None)\n",
    "gp_object = Type_2_GP_Emulator(all_gp_data, all_val_data, None, None, None, Kernel_enum(1), None, noise_std, None, \n",
    "                                retrain_GP, seed, normalize, None, None, None, None)\n",
    "#Choose training data\n",
    "train_data, test_data = gp_object.set_train_test_data(1.0, seed)\n",
    "#Train GP\n",
    "# gp_object.noise_std = None\n",
    "new_gp_model = gp_object.set_gp_model()\n",
    "gp_object.train_gp(new_gp_model)\n",
    "print(gp_object.scalerY.scale_)\n",
    "print(gp_object.fit_gp_model.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gp_object.trained_hyperparams)\n",
    "print(gp_object.trained_hyperparams[0].tolist() + gp_object.trained_hyperparams[1:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_object.fit_gp_model.kernel_.k1.k2.length_scale = np.array([4.45, 4.45, 0.684])\n",
    "# gp_object.fit_gp_model.kernel_.k1.k1.constant_value = 0.997**2\n",
    "# gp_object.fit_gp_model.kernel_.k2.noise_level = (0.0007680211296869702/1.1172376)**2\n",
    "# 2.41**2 * Matern(length_scale=[3.78, 2.38, 1.2, 0.261, 1.14, 1.5], nu=2.5) + WhiteKernel(noise_level=8.08e-05)\n",
    "print(gp_object.fit_gp_model.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate GP Mean and Variance\n",
    "all_val_data = simulator.gen_sim_data(15, 15, Gen_meth_enum(1), Gen_meth_enum(1), 1.0, simulator.seed, False)\n",
    "feat_val = gp_object.featurize_data(all_val_data)\n",
    "misc_gp_mean, misc_var_return = gp_object.eval_gp_mean_var_misc(all_val_data, feat_val, covar = False)\n",
    "# misc_gp_mean, misc_var_return = gp_object.eval_gp_mean_var_val(covar = False)\n",
    "# print(gp_object.scalerX.transform(np.concatenate((all_val_data.theta_vals, all_val_data.x_vals), axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_val_data.x_vals)\n",
    "print(misc_gp_mean)\n",
    "print(np.sqrt((misc_var_return)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse= np.sum((all_val_data.y_vals - misc_gp_mean)**2)/len(all_val_data.y_vals)\n",
    "print(\"MSE:\", mse)\n",
    "plt.figure()\n",
    "plt.plot(all_val_data.y_vals, all_val_data.y_vals, color='red', alpha=0.7)\n",
    "plt.scatter(all_val_data.y_vals, misc_gp_mean, color='blue', alpha=0.7)\n",
    "plt.errorbar(all_val_data.y_vals, misc_gp_mean, yerr = 1.96*np.sqrt(abs(misc_var_return)), alpha=0.3, fmt = 'o', color = \"blue\")\n",
    "plt.xlabel('True y Values')\n",
    "plt.ylabel('Predicted y Values')\n",
    "# plt.xlim([0.95,1.2])\n",
    "plt.title('Parity Plot of CS' + str(cs_name_val))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
