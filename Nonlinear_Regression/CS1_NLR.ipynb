{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2539354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import signac\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec834f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "criteria_dict = {\"cs_name_val\" : 1}\n",
    "project = signac.get_project()\n",
    "save_csv = False\n",
    "save_figs = False\n",
    "analyzer = General_Analysis(criteria_dict, project, save_csv)\n",
    "plotters = Plotters(analyzer, save_figs)\n",
    "\n",
    "param_name_str = \"t1t2\"\n",
    "indeces_to_consider = set_idcs_to_consider(1, param_name_str)\n",
    "\n",
    "bounds_x_l = np.array([[-2],[2]])\n",
    "bounds_theta_l = [-2, -2]\n",
    "bounds_theta_u = [ 2,  2]\n",
    "theta_ref = np.array([1.0, -1.0]) \n",
    "theta_names = ['theta_1', 'theta_2']\n",
    "theta_true = np.array([theta_ref[i] for i in indeces_to_consider] )\n",
    "theta_true_names = np.array([theta_names[i] for i in indeces_to_consider] )\n",
    "\n",
    "# Evaluate model and add noise based on assumed theta values\n",
    "# This generates experimental data points\n",
    "Xexp = np.linspace(-2,2,5).reshape(-1,1)\n",
    "theta_ref = np.array([1.0, -1.0]) \n",
    "Yexp = calc_cs1_polynomial(theta_ref, Xexp).flatten()\n",
    "print(Yexp)\n",
    "\n",
    "# Evaluate model based on the assumed experimental values\n",
    "X = np.linspace(np.min(Xexp),np.max(Xexp),100)\n",
    "Y = calc_cs1_polynomial(theta_ref, X.reshape(-1,1))\n",
    "\n",
    "# Compare the experiments to the true model\n",
    "plt.plot(X,Y,'b-',linewidth=2,label=r\"$y$\")\n",
    "plt.plot(Xexp,Yexp,'r.',markersize=10,label=r\"$y$\")\n",
    "plt.title(\"Plotting True Model and Synthetic Data\")\n",
    "plt.xlabel(r\"$x$\",fontsize=14)\n",
    "plt.ylabel(r'$y$',fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##New Cell\n",
    "\n",
    "## define function that includes nonlinear model\n",
    "def model(theta_guess, theta_ref, x, indeces_to_consider):\n",
    "    '''\n",
    "        \"\"\"\n",
    "    Creates Muller potential values given a guess for \"a\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        a_guess: ndarray, guess value for a\n",
    "        Constants: ndarray, The array containing the true values of Muller constants\n",
    "        x: ndarray, Independent variable data (exp or pred)\n",
    "    Returns\n",
    "    -------\n",
    "        y_model: ndarray, The simulated Muller potential given the guess\n",
    "    '''\n",
    "    #Define an array to store y values in\n",
    "    y_data = []\n",
    "    #Loop over all theta values\n",
    "    for i in range(len(x)):\n",
    "        #Create model coefficient from true space substituting in the values of param_space at the correct indeces\n",
    "        model_coefficients = theta_ref.copy()\n",
    "        #Replace coefficients a specified indeces with their theta_val counterparts\n",
    "        model_coefficients[indeces_to_consider] = theta_guess              \n",
    "        #Create y data coefficients\n",
    "        y_data.append(calc_cs1_polynomial(model_coefficients, x[i]))\n",
    "\n",
    "    #Convert list to array and flatten array\n",
    "    y_model = np.array(y_data).flatten()\n",
    "    \n",
    "    return y_model\n",
    "\n",
    "print(model(np.array([-1,1]), theta_ref, Xexp, indeces_to_consider))\n",
    "\n",
    "##New Cell\n",
    "\n",
    "# Create a function to optimize, in this case, least squares fitting\n",
    "def regression_func(theta_guess, theta_ref, x, indeces_to_consider, y):\n",
    "    '''\n",
    "    Function to define regression function for least-squares fitting\n",
    "    Arguments:\n",
    "        a_guess: ndarray, guess value for a\n",
    "        Constants: ndarray, The array containing the true values of Muller constants\n",
    "        x: ndarray, experimental X data (Inependent Variable)\n",
    "        y: ndarray, experimental Y data (Dependent Variable)\n",
    "    Returns:\n",
    "        e: residual vector\n",
    "    '''\n",
    "    \n",
    "    error = y - model(theta_guess, theta_ref, x, indeces_to_consider); #NOTE: Least squares will calculate sse based off this to minimize\n",
    "    \n",
    "    return error\n",
    "\n",
    "print(regression_func(np.array([-1,1]), theta_ref, Xexp, indeces_to_consider, Yexp))\n",
    "\n",
    "#Create a function to define the SSE for any Theta vector on a heat map.\n",
    "def sse_func(theta_guesses, theta_ref, indeces_to_consider, Xexp, Yexp):\n",
    "    '''\n",
    "    Function to define define sum of squared error function for heat map\n",
    "    Arguments:\n",
    "        xx: An N X D array of all a_1 values\n",
    "        yy: An D X N array of all a_2 values\n",
    "        x: independent variable vector (predicted x values including noise)\n",
    "        y: dependent variable vector (predicted y values on Heat Map)\n",
    "    Returns:\n",
    "        sse: N x N sum of squared error matrix of all generated combination of xx and yy\n",
    "    '''\n",
    "    #Initialize sse grid\n",
    "    sse = np.zeros(len(theta_guesses))\n",
    "    \n",
    "    #For each guess\n",
    "    for i in range(len(theta_guesses)):\n",
    "        #Evaluate the model\n",
    "        y_sim = model(theta_guesses[i], theta_ref, Xexp, indeces_to_consider)\n",
    "        #Calculate SSE\n",
    "        sse[i] = np.sum((y_sim - Yexp)**2)\n",
    "     \n",
    "    sse = sse.reshape(int(np.sqrt(len(theta_guesses))), -1).T\n",
    "    \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702dff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Set seed and repeats\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "repeats = 5\n",
    "\n",
    "## specify bounds\n",
    "lower = np.array([bounds_theta_l[i] for i in indeces_to_consider] )\n",
    "upper = np.array([bounds_theta_u[i] for i in indeces_to_consider] )\n",
    "bounds = (lower, upper) \n",
    "\n",
    "## specify initial guesses\n",
    "theta_guess = np.random.uniform(low=lower, high=upper, size=(repeats, len(lower)) )\n",
    "theta_vals = np.zeros((repeats, len(lower)))\n",
    "l2_norms = np.zeros(repeats)\n",
    "costs = np.zeros(repeats)\n",
    "fxn_evals = np.zeros(repeats)\n",
    "\n",
    "for i in range(repeats):\n",
    "    Solution = optimize.least_squares(regression_func, theta_guess[i] ,bounds=bounds, method='trf',\n",
    "                                      args=(theta_ref, Xexp, indeces_to_consider, Yexp),verbose=0)\n",
    "\n",
    "    theta_min_obj = Solution.x\n",
    "    costs[i] = Solution.cost\n",
    "    theta_vals[i] = theta_min_obj\n",
    "    #Note counting Jacobian and function evalauations as function evaluations\n",
    "    fxn_evals[i] = Solution.nfev + Solution.njev\n",
    "#     print(Solution.nfev, Solution.njev)\n",
    "    \n",
    "    del_theta = theta_min_obj - theta_true\n",
    "    theta_L2_norm = np.linalg.norm(del_theta, ord = 2)\n",
    "    l2_norms[i] = theta_L2_norm\n",
    "    \n",
    "nlr_theta = theta_vals[np.argmin(costs)]\n",
    "nlr_l2_norm = l2_norms[np.argmin(costs)]\n",
    "nlr_evals = fxn_evals[np.argmin(costs)]\n",
    "print(\"Best Theta = \", nlr_theta)\n",
    "print(\"Best Theta L2 norm = \", nlr_l2_norm)\n",
    "print(\"Evaluations = \", nlr_evals)\n",
    "print(\"theta_ref\", theta_true)\n",
    "Y_nlr_exp = model(nlr_theta, theta_ref, Xexp, indeces_to_consider)\n",
    "error = (Yexp - Y_nlr_exp)\n",
    "print(\"SSE = \", np.sum(error**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca92307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heat map data\n",
    "#Create list of heat map theta data\n",
    "heat_map_data_dict = {}\n",
    "\n",
    "#Create a linspace for the number of dimensions and define number of points\n",
    "dim_theta = len(theta_true_names)\n",
    "dim_list = np.linspace(0, dim_theta-1, dim_theta)\n",
    "\n",
    "#Create a list of all combinations (without repeats e.g no (1,1), (2,2)) of dimensions of theta\n",
    "mesh_combos = np.array(list(combinations(dim_list, 2)), dtype = int)\n",
    "n_points = 20\n",
    "\n",
    "#Meshgrid set always defined by n_points**2\n",
    "theta_set = np.tile(np.array(theta_true), (n_points**2, 1))\n",
    "\n",
    "#Set x_vals\n",
    "norm_x_vals = Xexp\n",
    "\n",
    "#Loop over all possible theta combinations of 2\n",
    "for i in range(len(mesh_combos)):\n",
    "    #Create a copy of the true values to change the mehsgrid valus on\n",
    "    theta_set_copy = np.copy(theta_set)\n",
    "    #Set the indeces of theta_set for evaluation as each row of mesh_combos\n",
    "    idcs = mesh_combos[i]\n",
    "    #define name of parameter set as tuple (\"param_1,param_2\")\n",
    "    data_set_name = (theta_true_names[idcs[0]], theta_true_names[idcs[1]])\n",
    "\n",
    "    #Create a meshgrid of values of the 2 selected values of theta and reshape to the correct shape\n",
    "    #Assume that theta1 and theta2 have equal number of points on the meshgrid\n",
    "    theta1 = np.linspace(lower[idcs[0]], upper[idcs[0]], n_points)\n",
    "    theta2 = np.linspace(lower[idcs[1]], upper[idcs[1]], n_points)\n",
    "    theta12_mesh = np.array(np.meshgrid(theta1, theta2))\n",
    "    theta12_vals = np.array(theta12_mesh).T.reshape(-1,2)\n",
    "\n",
    "    #Set initial values for evaluation (true values) to meshgrid values\n",
    "    theta_set_copy[:,idcs] = theta12_vals\n",
    "    \n",
    "    #Append data set to dictionary with name\n",
    "    heat_map_data_dict[data_set_name] = theta_set_copy\n",
    "    \n",
    "hm_data_keys = list(heat_map_data_dict.keys())\n",
    "# print(heat_map_data_dict[hm_data_keys[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Cell\n",
    "log_data = True\n",
    "# save_figure = True\n",
    "save_figure = False\n",
    "xbins = 5\n",
    "ybins = 5\n",
    "zbins = 900\n",
    "title= None\n",
    "\n",
    "\n",
    "#Get Number of pairs\n",
    "combos = list(combinations(dim_list, 2))\n",
    "pairs = len((list(combinations(dim_list, 2))))\n",
    "\n",
    "#For each pair\n",
    "for pair in range(pairs):\n",
    "    #Make a meshgrid for each parameter\n",
    "    idcs_to_plot = [int(combos[pair][i]) for i in range(len(combos[pair]))]\n",
    "    theta_data = heat_map_data_dict[hm_data_keys[pair]].reshape(n_points, n_points, -1).T\n",
    "    theta_mesh = np.take(theta_data, list(combos[pair]), axis=0)\n",
    "    \n",
    "    sse_sim = sse_func(heat_map_data_dict[hm_data_keys[pair]], theta_ref, indeces_to_consider, Xexp, Yexp)\n",
    "    param_names = theta_true_names[idcs_to_plot]\n",
    "    \n",
    "    title = \"Heat Map Pair \" + \"-\".join(map(str, param_names))\n",
    "    title = None\n",
    "\n",
    "    z = np.array([sse_sim])\n",
    "    if log_data == True:\n",
    "        z_titles = [\"ln(\"+ r\"$\\mathbf{e(\\theta)_{sim}}$\" + \")\"]\n",
    "        z = np.log(z)\n",
    "    else:\n",
    "        z_titles = [r\"$\\mathbf{e(\\theta)_{sim}}$\" + \")\"]\n",
    "    \n",
    "#     z_save_names = [\"sse_sim\", \"sse_nlr\"]\n",
    "#     path_end = '-'.join(z_save_names) \n",
    "    levels = [100]\n",
    "\n",
    "    param_info_dict = {\"true\":theta_true, \"min_sse\":nlr_theta, \"names\":param_names, \"idcs\":idcs_to_plot}\n",
    "    plotters.plot_nlr_heat_maps(theta_mesh, z, z_titles, levels, param_info_dict, log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot and compare predictions and experiments\n",
    "X_pred = np.linspace(-2,2,100).reshape(-1,1)\n",
    "Y_pred = model(nlr_theta, theta_ref, X_pred, indeces_to_consider).flatten()\n",
    "plt.figure(figsize = (9,6))\n",
    "plt.plot(Xexp,Yexp,'.g',markersize=20,label=r'$y$')\n",
    "plt.plot(X,Y,'r-',linewidth=3,label=r'$f(\\mathbf{\\theta_{true}})$')\n",
    "plt.plot(X_pred,Y_pred,'--b',linewidth=4,label=r'$f(\\mathbf{\\theta})$')\n",
    "# plt.title(\"Predictions with $\\\\theta = [0.994,-1.00]$ vs Synthetic Data\")\n",
    "# plt.title(\"Predictions with $\\\\theta = [0.802,-0.757]$ vs Synthetic Data\")\n",
    "plt.legend(loc = \"lower right\", fontsize=30) #(bbox_to_anchor=(1.04, 1), borderaxespad=0\n",
    "plt.xlabel(r'$x$',fontsize=30,fontweight='bold')\n",
    "plt.ylabel(r'$y$',fontsize=30,fontweight='bold')\n",
    "\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.minorticks_on() # turn on minor ticks\n",
    "plt.tick_params(which=\"minor\",direction=\"in\",top=True, right=True)\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.savefig(\"Figures/sim_true_comp_poster.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##New Cell\n",
    "\n",
    "#Plot error\n",
    "print(\"SSE = \", np.sum(error**2))\n",
    "plt.plot(Y_nlr_exp,error,\"b.\",markersize=20, label = \"Error\")\n",
    "plt.title(\"Residuals\")\n",
    "plt.xlabel('Predicted Y')\n",
    "plt.ylabel('Residuals vs. Predicted Value')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c44cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental Variance =  0.0001\n",
      "Parameter Prediction Standard Deviation: \n",
      " [0.00316228 0.00171499]\n",
      "Covariance matrix:\n",
      " [[1.00000000e-05 0.00000000e+00]\n",
      " [0.00000000e+00 2.94117647e-06]]\n",
      "Det(FIM) =  34000000000.00001\n",
      "Eigen Values (FIM):\n",
      " [100000. 340000.]\n",
      "Eigen Vectors (FIM)\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "Condition Number (FIM):  3.4\n",
      "Degree of precision loss (log10(k) of FIM):  0.5314789170422551\n"
     ]
    }
   ],
   "source": [
    "sigre = 0.01**2\n",
    "# sigre = (error.T @ error)/(len(error) - 2)\n",
    "Hess = Solution.jac.T @ Solution.jac\n",
    "Covar = sigre * np.linalg.inv(Hess)\n",
    "FIM = (1/sigre)*Hess\n",
    "print(\"Experimental Variance = \", sigre)\n",
    "#sqrt of diagonal is the error associated with each prediction\n",
    "print(\"Parameter Prediction Standard Deviation: \\n\", np.sqrt(np.diag(Covar)))\n",
    "print(\"Covariance matrix:\\n\",Covar)\n",
    "print(\"Det(FIM) = \", np.linalg.det(FIM))\n",
    "eigvals, eigvecs = np.linalg.eig(FIM)\n",
    "k = np.max(eigvals)/np.min(eigvals)\n",
    "print(\"Eigen Values (FIM):\\n\", eigvals)\n",
    "print(\"Eigen Vectors (FIM)\\n\", eigvecs)\n",
    "print(\"Condition Number (FIM): \", k)\n",
    "print(\"Degree of precision loss (log10(k) of FIM): \", math.log10(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a03e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
