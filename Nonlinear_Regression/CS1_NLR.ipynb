{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2539354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "log_plot = True\n",
    "\n",
    "def calc_cs1_polynomial(true_model_coefficients, x):\n",
    "    \"\"\"\n",
    "    Calculates the value of y for case study 1\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    true_model_coefficients: ndarray, The array containing the true values of Theta1 and Theta2\n",
    "    x: ndarray, The list of xs that will be used to generate y\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    y_poly: ndarray, The noiseless values of y given theta_true and x\n",
    "    \"\"\"\n",
    "    \n",
    "    y_poly =  true_model_coefficients[0]*x + true_model_coefficients[1]*x**2 +x**3\n",
    "       \n",
    "    return y_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec834f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create synthetic data assuming the following values for theta\n",
    "Theta_Guess = np.array([1,-1])\n",
    "\n",
    "##New Cell\n",
    "\n",
    "# Evaluate model and add noise based on assumed theta values\n",
    "# This generates experimental data points\n",
    "Xexp = np.linspace(-2,2,5)\n",
    "theta_ref = np.array([1.0, -1.0]) \n",
    "Yexp = calc_cs1_polynomial(theta_ref, Xexp)\n",
    "\n",
    "##New Cell\n",
    "\n",
    "# Evaluate model based on the assumed experimental values\n",
    "X = np.linspace(np.min(Xexp),np.max(Xexp),100)\n",
    "Y = Theta_Guess[0]*X + Theta_Guess[1]*X**2 + X**3\n",
    "\n",
    "# Compare the experiments to the true model\n",
    "plt.plot(X,Y,'b-',linewidth=2,label=r\"$y$\")\n",
    "plt.plot(Xexp,Yexp,'r.',markersize=10,label=r\"$y$\")\n",
    "plt.title(\"Plotting True Model and Synthetic Data\")\n",
    "plt.xlabel(r\"$x$\",fontsize=14)\n",
    "plt.ylabel(r'$y$',fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##New Cell\n",
    "\n",
    "## define function that includes nonlinear model\n",
    "def model(theta,x):\n",
    "    '''\n",
    "    Toy model\n",
    "    Arguments:\n",
    "        theta: parameter vector\n",
    "        x: independent variable vector\n",
    "    Returns:\n",
    "        y_model: dependent variable prediction\n",
    "    '''\n",
    "    y_model = theta[0]*x + theta[1]*x**2 + x**3\n",
    "    return y_model\n",
    "\n",
    "print(model(Theta_Guess,Xexp))\n",
    "\n",
    "##New Cell\n",
    "\n",
    "# Create a function to optimize, in this case, least squares fitting\n",
    "def regression_func(theta, x, y):\n",
    "    '''\n",
    "    Function to define regression function for least-squares fitting\n",
    "    Arguments:\n",
    "        theta: parameter vector\n",
    "        x: independent variable vector\n",
    "        y: dependent variable vector (measurements)\n",
    "    Returns:\n",
    "        e: residual vector\n",
    "    '''\n",
    "    \n",
    "    error = y - model(theta,x); #NOTE: Least squares will calculate sse based off this to minimize\n",
    "    \n",
    "    return error\n",
    "#New Cell\n",
    "\n",
    "#Create a function to define the SSE for any Theta vector on a heat map.\n",
    "def sse_func(xx, yy, x, y):\n",
    "    '''\n",
    "    Function to define define sum of squared error function for heat map\n",
    "    Arguments:\n",
    "        xx: An N X D array of all Theta1 values\n",
    "            \n",
    "        yy: An D X N array of all Theta2 values\n",
    "        theta: parameter vector\n",
    "        x: independent variable vector (predicted x values including noise)\n",
    "        y: dependent variable vector (predicted y values on Heat Map)\n",
    "    Returns:\n",
    "        sse: N x N sum of squared error matrix of all generated combination of xx and yy\n",
    "    '''\n",
    "    sse = np.zeros([len(xx),len(yy)])\n",
    "    \n",
    "    for i in range(len(xx)):\n",
    "        for j in range(len(yy)):\n",
    "            theta = np.array([xx[i][j],yy[i][j]])\n",
    "            sse[i][j] = sum((y - model(theta,x))**2) \n",
    "    \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702dff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#New Cell\n",
    "\n",
    "## specify initial guess\n",
    "# sse_list = []\n",
    "# for i in range(15):\n",
    "theta0 = np.random.rand(2) * (2+2) -2\n",
    "#     theta0 = Theta_Guess\n",
    "#     print(theta0)\n",
    "\n",
    "## specify bounds\n",
    "# first array: lower bounds\n",
    "# second array: upper bounds\n",
    "bounds = ([-np.inf, -np.inf], [np.inf, np.inf])\n",
    "\n",
    "## use least squares optimizer in scipy\n",
    "# argument 1: function that takes theta as input, returns residual\n",
    "# argument 2: initial guess for theta\n",
    "# optional arguments 'bounds': bounds for theta\n",
    "# optional arugment 'args': additional arguments to pass to residual function\n",
    "# optional argument 'method': select the numerical method\n",
    "#   if you want to consider bounds, choose 'trf'\n",
    "#   if you do not want to consider bounds, try either 'lm' or 'trf'\n",
    "Solution = optimize.least_squares(regression_func, theta0,bounds=bounds, method='trf',args=(Xexp, Yexp),verbose=2)\n",
    "\n",
    "theta = Solution.x\n",
    "print(Solution.fun)\n",
    "print(\"theta = \",theta)\n",
    "    \n",
    "Y_pred2 = model(theta,Xexp)\n",
    "error = regression_func(theta, Xexp, Yexp)\n",
    "print(error)\n",
    "SSE = np.sum(error**2)\n",
    "print(SSE)\n",
    "\n",
    "# sse_list = np.array(sse_list)\n",
    "# print(np.median(sse_list))\n",
    "# print(np.argmin(sse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca92307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Cell\n",
    "\n",
    "# generate predictions\n",
    "X_pred = np.linspace(np.min(Xexp),np.max(Xexp),20)\n",
    "Y_pred = model(theta, X_pred)\n",
    "\n",
    "Theta1_Map = np.linspace(-2,2,100)\n",
    "Theta2_Map = np.linspace(-2,2,100)\n",
    "\n",
    "x = Theta1_Map\n",
    "y = Theta2_Map\n",
    "\n",
    "# full coorindate arrays\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "zz = sse_func(xx,yy,X_pred,Y_pred)\n",
    "\n",
    "if log_plot == True:\n",
    "    zz = np.log(zz)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "cs = plt.contourf(xx, yy,zz, levels = 100, cmap = \"autumn\")\n",
    "\n",
    "# plot color bar\n",
    "# if np.amax(zz) < 1e-1:\n",
    "#     cbar = plt.colorbar(cs, format='%.2e')\n",
    "# else:\n",
    "#     cbar = plt.colorbar(cs, format = '%2.2f')\n",
    "\n",
    "# set font size in color bar\n",
    "# cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "# plot title in color bar\n",
    "# cbar.ax.set_ylabel(r'$\\mathbf{log(e(\\theta))}$', fontsize=16, fontweight='bold')\n",
    "#     print(p_GP_opt[0],p_GP_opt[1])\n",
    "\n",
    "\n",
    "\n",
    "# Plot equipotential line\n",
    "cs2 = plt.contour(cs, levels=cs.levels[::10], colors='k', alpha=0.7, linestyles='dashed', linewidths=3)\n",
    "\n",
    "if np.amax(zz) < 1e-1:\n",
    "    plt.clabel(cs2, fmt='%.2e', colors='k', fontsize=20)\n",
    "else:\n",
    "    plt.clabel(cs2, fmt='%2.2f', colors='k', fontsize=20)\n",
    "\n",
    "plt.scatter(Theta_Guess[0],Theta_Guess[1], color=\"blue\", s=100, label = \"True Optimal Value\", marker = (5,1))\n",
    "plt.scatter(theta[0],theta[1], color=\"white\",s=50, marker = \".\",label = \"NLR Optimal Value\", edgecolor = \"k\", linewidth=0.3)\n",
    "# plt.grid()\n",
    "\n",
    "# plt.legend(fontsize=10,bbox_to_anchor=(0, 1.05, 1, 0.2),borderaxespad=0, loc = \"lower left\")\n",
    "# plt.xlabel(r'$\\mathbf{\\theta_1}$',fontsize=20,fontweight='bold')\n",
    "# plt.ylabel(r'$\\mathbf{\\theta_2}$',fontsize=20,fontweight='bold')\n",
    "plt.xlim((np.amin(xx), np.amax(xx)))\n",
    "plt.ylim((np.amin(yy),np.amax(yy))) \n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.minorticks_on() # turn on minor ticks\n",
    "plt.tick_params(which=\"minor\",direction=\"in\",top=True, right=True)\n",
    "plt.axis('square')\n",
    "# plt.title(\"log(sse)\", fontweight = \"bold\", fontsize = 24)\n",
    "\n",
    "if log_plot == True:\n",
    "    plt.title(r'$\\mathbf{log(e(\\theta))}$', weight='bold',fontsize = 24)\n",
    "    plt.title(\"NLR\", weight='bold',fontsize = 20)\n",
    "#     plt.savefig(\"Figures/NLR_ln_SSE_poster.png\", dpi=300, bbox_inches='tight')\n",
    "else:\n",
    "    plt.title('Non-Linear Regression SSE', weight='bold',fontsize = 16)\n",
    "#     plt.savefig(\"Figures/NLR_SSE.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "\n",
    "plt.show()\n",
    "#New Cell\n",
    "\n",
    "# create plot and compare predictions and experiments\n",
    "plt.figure(figsize = (9,6))\n",
    "plt.plot(Xexp,Yexp,'.g',markersize=20,label=r'$y$')\n",
    "plt.plot(X,Y,'r-',linewidth=3,label=r'$f(\\mathbf{\\theta_{true}})$')\n",
    "plt.plot(X_pred,Y_pred,'--b',linewidth=4,label=r'$f(\\mathbf{\\theta})$')\n",
    "# plt.title(\"Predictions with $\\\\theta = [0.994,-1.00]$ vs Synthetic Data\")\n",
    "# plt.title(\"Predictions with $\\\\theta = [0.802,-0.757]$ vs Synthetic Data\")\n",
    "plt.legend(loc = \"lower right\", fontsize=30) #(bbox_to_anchor=(1.04, 1), borderaxespad=0\n",
    "plt.xlabel(r'$x$',fontsize=30,fontweight='bold')\n",
    "plt.ylabel(r'$y$',fontsize=30,fontweight='bold')\n",
    "\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.minorticks_on() # turn on minor ticks\n",
    "plt.tick_params(which=\"minor\",direction=\"in\",top=True, right=True)\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.savefig(\"Figures/sim_true_comp_poster.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##New Cell\n",
    "\n",
    "#Plot error\n",
    "Y_pred2 = model(theta,Xexp)\n",
    "error = (Yexp - Y_pred2)\n",
    "print(\"SSE = \", np.sum(error**2))\n",
    "plt.plot(Y_pred2,error,\"b.\",markersize=20, label = \"Error\")\n",
    "plt.title(\"Residuals\")\n",
    "plt.xlabel('Predicted Y')\n",
    "plt.ylabel('Residuals vs. Predicted Value')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jacobian and Uncertainty Analysis\n",
    "print(\"Jacobian =\\n\")\n",
    "print(Solution.jac)\n",
    "sigre = (error.T @ error)/(len(error) - 2)\n",
    "Sigma_theta2 = sigre * np.linalg.inv(Solution.jac.T @ Solution.jac)\n",
    "print(\"Covariance matrix:\\n\",Sigma_theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb0dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778b7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
