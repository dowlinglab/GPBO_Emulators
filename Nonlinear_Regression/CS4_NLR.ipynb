{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2539354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "log_plot = True\n",
    "\n",
    "def grid_sampling(num_points, bounds):\n",
    "        \"\"\"\n",
    "        Generates Grid sampled data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_points: int, number of points in LHS, should be greater than # of dimensions\n",
    "        bounds: ndarray, array containing upper and lower bounds of elements in LHS sample. Defaults of 0 and 1\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        grid_data: ndarray, (num_points)**bounds.shape[1] grid sample of data\n",
    "        \n",
    "        \"\"\"\n",
    "        #Generate mesh_grid data for theta_set in 2D\n",
    "        #Define linspace for theta\n",
    "        params = np.linspace(0,1, num_points)\n",
    "        #Define dimensions of parameter\n",
    "        dimensions = bounds.shape[1]\n",
    "        #Generate the equivalent of all meshgrid points\n",
    "        df = pd.DataFrame(list(itertools.product(params, repeat=dimensions)))\n",
    "        df2 = df.drop_duplicates()\n",
    "        scaled_data = df2.to_numpy()\n",
    "        #Normalize to bounds \n",
    "        lower_bound = bounds[0]\n",
    "        upper_bound = bounds[1]\n",
    "        grid_data = scaled_data*(upper_bound - lower_bound) + lower_bound \n",
    "        return grid_data\n",
    "\n",
    "def model(true_model_coefficients, X):\n",
    "    \"\"\"\n",
    "    Calculates the value of y for case study 1\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    true_model_coefficients: ndarray, The array containing the true values of Theta1 and Theta2\n",
    "    x: ndarray, The list of xs that will be used to generate y\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    y_poly: ndarray, The noiseless values of y given theta_true and x\n",
    "    \"\"\"\n",
    "    assert len(true_model_coefficients) == 4, \"4 Coefficients\"\n",
    "    t1, t2, t3, t4 = true_model_coefficients\n",
    "    \n",
    "    y_model = np.zeros(len(X))\n",
    "    #If array is not 2D, give it shape (len(array), 1)\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        #If array is not 2D, give it shape (len(array), 1)\n",
    "        if not len(x.shape) > 1:\n",
    "            x = x.reshape(-1,1)\n",
    "\n",
    "        assert x.shape[0] == 2, \"Polynomial x_data must be 2 dimensional\"\n",
    "        x1, x2 = x #Split x into 2 parts by splitting the rows\n",
    "\n",
    "        y_model[i] =  (t1*t2*x1)/(1+t2*x1) + (t3*t4*x2)/(1+t4*x2)\n",
    "        \n",
    "    y_model = np.array(y_model)\n",
    "       \n",
    "    return y_model\n",
    "\n",
    "# Create a function to optimize, in this case, least squares fitting\n",
    "def regression_func(theta, X, y):\n",
    "    '''\n",
    "    Function to define regression function for least-squares fitting\n",
    "    Arguments:\n",
    "        theta: parameter vector\n",
    "        x: independent variable vector\n",
    "        y: dependent variable vector (measurements)\n",
    "    Returns:\n",
    "        e: residual vector\n",
    "    '''\n",
    "    \n",
    "#     error = np.sum((y - model(theta,X))**2); #NOTE: Least squares will calculate sse based off this to minimize\n",
    "    error = (y - model(theta,X))\n",
    "    \n",
    "    return error\n",
    "#New Cell\n",
    "\n",
    "#Create a function to define the SSE for any Theta vector on a heat map.\n",
    "def sse_func(xx, yy, x, y):\n",
    "    '''\n",
    "    Function to define define sum of squared error function for heat map\n",
    "    Arguments:\n",
    "        xx: An N X D array of all Theta1 values\n",
    "            \n",
    "        yy: An D X N array of all Theta2 values\n",
    "        theta: parameter vector\n",
    "        x: independent variable vector (predicted x values including noise)\n",
    "        y: dependent variable vector (predicted y values on Heat Map)\n",
    "    Returns:\n",
    "        sse: N x N sum of squared error matrix of all generated combination of xx and yy\n",
    "    '''\n",
    "    sse = np.zeros([len(xx),len(yy)])\n",
    "    \n",
    "    for i in range(len(xx)):\n",
    "        for j in range(len(yy)):\n",
    "            theta = np.array([xx[i][j],yy[i][j]])\n",
    "            sse[i][j] = sum((y - model(theta,x))**2) \n",
    "    \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec834f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create synthetic data assuming the following values for theta\n",
    "theta_ref = np.array([20,0.2,200,0.02])\n",
    "##New Cell\n",
    "\n",
    "# Evaluate model and add noise based on assumed theta values\n",
    "# This generates experimental data points\n",
    "num_points = 5\n",
    "bounds_x = np.array([[1, 1], \n",
    "                     [11, 11]])\n",
    "Xexp = grid_sampling(num_points, bounds_x)\n",
    "Yexp = model(theta_ref, Xexp)\n",
    "\n",
    "# Evaluate model based on the assumed experimental values\n",
    "num_points_2 = 50\n",
    "X = grid_sampling(num_points_2, bounds_x)\n",
    "x1 = np.linspace(np.min(Xexp[:,0]),np.max(Xexp[:,0]),num_points_2)\n",
    "x2 = np.linspace(np.min(Xexp[:,1]),np.max(Xexp[:,1]),num_points_2)\n",
    "X1, X2 = np.meshgrid(x1,x2)\n",
    "X_mesh = np.meshgrid(x1,x2)\n",
    "# #Creates an array for Y that will be filled with the for loop\n",
    "# #Initialize y_sim\n",
    "Y = model(theta_ref, X)\n",
    "\n",
    "print(np.min(Y), np.max(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the experiments to the true model\n",
    "# Compare the experiments to the true model\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(X1, X2, Y.reshape(-1,num_points_2).T, 100, cmap='Reds')\n",
    "ax.plot(1,1,1, label = \"$y_{exp}$\", color = 'red')\n",
    "ax.scatter(1,1,1, label = \"Exp Data\", color = 'green', edgecolors = \"k\")\n",
    "ax.scatter3D(Xexp[:,0], Xexp[:,1], Yexp, c=Yexp, cmap='Greens', edgecolors = \"k\")\n",
    "plt.legend(fontsize=10,bbox_to_anchor=(0, 1.0, 1, 0.2),borderaxespad=0, loc = \"lower right\")\n",
    "\n",
    "ax.minorticks_on() # turn on minor ticks\n",
    "ax.tick_params(direction=\"in\",top=True, right=True) \n",
    "ax.tick_params(which=\"minor\",direction=\"in\",top=True, right=True)\n",
    "\n",
    "\n",
    "ax.zaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.grid(False)\n",
    "\n",
    "ax.set_xlim((np.amin(X1),np.amax(X1)))\n",
    "ax.set_ylim((np.amin(X2),np.amax(X2)))\n",
    "\n",
    "ax.set_xlabel('X1', fontsize=16,fontweight='bold')\n",
    "ax.set_ylabel('X2', fontsize=16,fontweight='bold')\n",
    "ax.set_zlabel('Muller Potential',fontsize=16,fontweight='bold');\n",
    "\n",
    "ax.locator_params(axis='y', nbins=5)\n",
    "ax.locator_params(axis='x', nbins=5)\n",
    "# ax.locator_params(axis='z', nbins=5)\n",
    "# plt.title(\"Plotting True Model and Synthetic Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700db82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zz = Y.reshape(num_points_2,-1).T\n",
    "xx = X1\n",
    "yy = X2\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "cs = plt.contourf(xx, yy,zz, levels = 100, cmap = \"autumn\")\n",
    "\n",
    "# plot color bar\n",
    "if np.amax(zz) < 1e-1:\n",
    "    cbar = plt.colorbar(cs, format='%.2e')\n",
    "else:\n",
    "    cbar = plt.colorbar(cs, format = '%2.2f')\n",
    "\n",
    "#set font size in color bar\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "# plot title in color bar\n",
    "# cbar.ax.set_ylabel(r'$\\mathbf{log(e(\\theta))}$', fontsize=16, fontweight='bold')\n",
    "#     print(p_GP_opt[0],p_GP_opt[1])\n",
    "\n",
    "\n",
    "\n",
    "# Plot equipotential line\n",
    "cs2 = plt.contour(cs, levels=cs.levels[::37], colors='k', alpha=0.7, linestyles='dashed', linewidths=3)\n",
    "\n",
    "if np.amax(zz) < 1e-1:\n",
    "    plt.clabel(cs2, fmt='%.2e', colors='k', fontsize=20)\n",
    "else:\n",
    "    plt.clabel(cs2, fmt='%2.2f', colors='k', fontsize=20)\n",
    "\n",
    "X_best = np.array(X_mesh).T.reshape(-1,2)[np.argmin(Y)]\n",
    "print(X_best)\n",
    "plt.scatter(X_best[0],X_best[1], color=\"blue\", s=100, label = \"True Optimal Value\", marker = (5,1))\n",
    "# plt.scatter(theta[0],theta[1], color=\"white\",s=50, marker = \".\",label = \"NLR Optimal Value\", edgecolor = \"k\", linewidth=0.3)\n",
    "# plt.grid()\n",
    "\n",
    "# plt.legend(fontsize=10,bbox_to_anchor=(0, 1.05, 1, 0.2),borderaxespad=0, loc = \"lower left\")\n",
    "plt.xlabel(r'$\\mathbf{x_1}$',fontsize=20,fontweight='bold')\n",
    "plt.ylabel(r'$\\mathbf{x_2}$',fontsize=20,fontweight='bold')\n",
    "plt.xlim((np.amin(xx), np.amax(xx)))\n",
    "plt.ylim((np.amin(yy),np.amax(yy))) \n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.minorticks_on() # turn on minor ticks\n",
    "plt.tick_params(which=\"minor\",direction=\"in\",top=True, right=True)\n",
    "plt.axis('square')\n",
    "# plt.title(\"log(sse)\", fontweight = \"bold\", fontsize = 24)\n",
    "\n",
    "if log_plot == True:\n",
    "    plt.title(r'$\\mathbf{log(e(\\theta))}$', weight='bold',fontsize = 24)\n",
    "    plt.title(\"NLR\", weight='bold',fontsize = 20)\n",
    "#     plt.savefig(\"Figures/NLR_ln_SSE_poster.png\", dpi=300, bbox_inches='tight')\n",
    "else:\n",
    "    plt.title('Non-Linear Regression SSE', weight='bold',fontsize = 16)\n",
    "#     plt.savefig(\"Figures/NLR_SSE.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702dff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#New Cell\n",
    "\n",
    "## specify initial guess\n",
    "# sse_list = []\n",
    "# for i in range(15):\n",
    "theta0 = np.array([20, 0.1, 250, 1e-2])\n",
    "#     theta0 = Theta_Guess\n",
    "#     print(theta0)\n",
    "\n",
    "## specify bounds\n",
    "# first array: lower bounds\n",
    "# second array: upper bounds\n",
    "bounds= np.array([[1, 1e-2, 1, 1e-3], [100, 1, 500,  1e-1]])\n",
    "\n",
    "## use least squares optimizer in scipy\n",
    "# argument 1: function that takes theta as input, returns residual\n",
    "# argument 2: initial guess for theta\n",
    "# optional arguments 'bounds': bounds for theta\n",
    "# optional arugment 'args': additional arguments to pass to residual function\n",
    "# optional argument 'method': select the numerical method\n",
    "#   if you want to consider bounds, choose 'trf'\n",
    "#   if you do not want to consider bounds, try either 'lm' or 'trf'\n",
    "Solution = optimize.least_squares(regression_func, theta0, bounds=bounds, method='trf',args=(Xexp, Yexp),verbose=2)\n",
    "\n",
    "theta = Solution.x\n",
    "print(\"theta = \",theta)\n",
    "    \n",
    "Y_pred2 = model(theta,Xexp)\n",
    "error = regression_func(theta, Xexp, Yexp)\n",
    "SSE = np.sum(error**2)\n",
    "print(SSE)\n",
    "\n",
    "# sse_list = np.array(sse_list)\n",
    "# print(np.median(sse_list))\n",
    "# print(np.argmin(sse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca92307",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = model(theta, X)\n",
    "zz = Y.reshape(num_points_2,-1).T\n",
    "xx = X1\n",
    "yy = X2\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "cs = plt.contourf(xx, yy,zz, levels = 100, cmap = \"autumn\")\n",
    "\n",
    "# plot color bar\n",
    "if np.amax(zz) < 1e-1:\n",
    "    cbar = plt.colorbar(cs, format='%.2e')\n",
    "else:\n",
    "    cbar = plt.colorbar(cs, format = '%2.2f')\n",
    "\n",
    "#set font size in color bar\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "# plot title in color bar\n",
    "# cbar.ax.set_ylabel(r'$\\mathbf{log(e(\\theta))}$', fontsize=16, fontweight='bold')\n",
    "#     print(p_GP_opt[0],p_GP_opt[1])\n",
    "\n",
    "\n",
    "\n",
    "# Plot equipotential line\n",
    "cs2 = plt.contour(cs, levels=cs.levels[::10], colors='k', alpha=0.7, linestyles='dashed', linewidths=3)\n",
    "\n",
    "if np.amax(zz) < 1e-1:\n",
    "    plt.clabel(cs2, fmt='%.2e', colors='k', fontsize=20)\n",
    "else:\n",
    "    plt.clabel(cs2, fmt='%2.2f', colors='k', fontsize=20)\n",
    "\n",
    "X_best = np.array(X_mesh).T.reshape(-1,2)[np.argmin(Y)]\n",
    "print(X_best)\n",
    "plt.scatter(X_best[0],X_best[1], color=\"blue\", s=100, label = \"True Optimal Value\", marker = (5,1))\n",
    "# plt.scatter(theta[0],theta[1], color=\"white\",s=50, marker = \".\",label = \"NLR Optimal Value\", edgecolor = \"k\", linewidth=0.3)\n",
    "# plt.grid()\n",
    "\n",
    "# plt.legend(fontsize=10,bbox_to_anchor=(0, 1.05, 1, 0.2),borderaxespad=0, loc = \"lower left\")\n",
    "# plt.xlabel(r'$\\mathbf{\\theta_1}$',fontsize=20,fontweight='bold')\n",
    "# plt.ylabel(r'$\\mathbf{\\theta_2}$',fontsize=20,fontweight='bold')\n",
    "plt.xlim((np.amin(xx), np.amax(xx)))\n",
    "plt.ylim((np.amin(yy),np.amax(yy))) \n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.minorticks_on() # turn on minor ticks\n",
    "plt.tick_params(which=\"minor\",direction=\"in\",top=True, right=True)\n",
    "plt.axis('square')\n",
    "# plt.title(\"log(sse)\", fontweight = \"bold\", fontsize = 24)\n",
    "\n",
    "if log_plot == True:\n",
    "    plt.title(r'$\\mathbf{log(e(\\theta))}$', weight='bold',fontsize = 24)\n",
    "    plt.title(\"NLR\", weight='bold',fontsize = 20)\n",
    "#     plt.savefig(\"Figures/NLR_ln_SSE_poster.png\", dpi=300, bbox_inches='tight')\n",
    "else:\n",
    "    plt.title('Non-Linear Regression SSE', weight='bold',fontsize = 16)\n",
    "#     plt.savefig(\"Figures/NLR_SSE.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot error\n",
    "Y_pred2 = model(theta,Xexp)\n",
    "error = (Yexp - Y_pred2)\n",
    "print(\"SSE = \", np.sum(error**2))\n",
    "\n",
    "#Jacobian and Uncertainty Analysis\n",
    "print(\"Jacobian =\\n\")\n",
    "print(Solution.jac)\n",
    "sigre = (error.T @ error)/(len(error) - 2)\n",
    "Sigma_theta2 = sigre * np.linalg.inv(Solution.jac.T @ Solution.jac)\n",
    "print(\"Covariance matrix:\\n\",Sigma_theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb0dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778b7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
