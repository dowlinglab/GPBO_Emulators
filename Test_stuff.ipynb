{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3b690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "from scipy.stats import qmc\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_functions_generic import gen_theta_set, find_train_doc_path, test_train_split, clean_1D_arrays, norm_unnorm\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "import random\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0a8ffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "Xexp = np.array([[1,2],\n",
    "        [2,3],\n",
    "        [4,5]])\n",
    "Y = np.tile(Xexp, (9,1))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2d81918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] [3 4 5 6 7 8 9]\n",
      "(1, 1)\n",
      "<class 'numpy.int64'>\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "X = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "X1,X2 = np.split(X, [3])\n",
    "print(X1,X2)\n",
    "\n",
    "X = np.array([[3]])\n",
    "print(X.shape)\n",
    "print(type(X.flatten()[0]))\n",
    "\n",
    "Y = 12\n",
    "for i in range(12):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c62faa9",
   "metadata": {},
   "source": [
    "#Set Parameters\n",
    "Theta_True = Constants = np.array([1,-1])\n",
    "print(Constants.shape)\n",
    "print(Theta_True.shape)\n",
    "\n",
    "d = len(Theta_True)\n",
    "runs = 2\n",
    "skip_param_types = 0\n",
    "\n",
    "obj = np.array([\"obj\"])\n",
    "emulator = np.array([True])\n",
    "\n",
    "#Pull Experimental data from CSV\n",
    "exp_data_doc = 'Input_CSVs/Exp_Data/d=2/n=5.csv'\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "n = len(Xexp)\n",
    "# print(len(Xexp) == len(Yexp))\n",
    "\n",
    "Xexp = clean_1D_arrays(Xexp)\n",
    "print(Xexp.shape)\n",
    "\n",
    "if emulator == True:\n",
    "    t = 20*n\n",
    "else:\n",
    "    t = 20\n",
    "\n",
    "#Define GP Testing space\n",
    "LHS = False\n",
    "p=20\n",
    "bounds = np.array([[-2,-2],[2,2]])\n",
    "# Theta1 =  np.linspace(-2,2,p) #1x10\n",
    "# Theta2 =  np.linspace(-2,2,p) #1x10\n",
    "# theta_mesh = np.array(np.meshgrid(Theta1, Theta2)) #2 Uniform 5x5 arrays \n",
    "theta_mesh = gen_theta_set(LHS = LHS, n_points = p, dimensions = d, bounds = bounds)\n",
    "print(theta_mesh.shape)\n",
    "\n",
    "all_data_doc = find_train_doc_path(emulator, obj, d, t)\n",
    "all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\")) \n",
    "print(all_data.shape)\n",
    "\n",
    "train_data, test_data = test_train_split(all_data, sep_fact = 0.2, shuffle_seed=9)\n",
    "train_p, test_p = train_data[:,1:-m], test_data[:,1:-m]\n",
    "print(train_p)\n",
    "\n",
    "print(train_p.shape)\n",
    "print(test_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad50c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n",
      "(8,)\n",
      "(15, 2)\n",
      "(400, 8)\n",
      "(20, 10)\n",
      "torch.Size([4, 8])\n",
      "torch.Size([16, 8])\n"
     ]
    }
   ],
   "source": [
    "CS = 2.2\n",
    "\n",
    "Constants = np.array([[-200,-100,-170,15],\n",
    "                      [-1,-1,-6.5,0.7],\n",
    "                      [0,0,11,0.6],\n",
    "                      [-10,-10,-6.5,0.7],\n",
    "                      [1,0,-0.5,-1],\n",
    "                      [0,0.5,1.5,1]])\n",
    "if CS == 2.2:\n",
    "    skip_param_types = 1 #This is what changes for subpoint\n",
    "    Theta_True = Constants[skip_param_types:skip_param_types+2].flatten()\n",
    "    param_dict = {0 : 'a_1', 1 : 'a_2', 2 : 'a_3', 3 : 'a_4',\n",
    "                  4 : 'b_1', 5 : 'b_2', 6 : 'b_3', 7 : 'b_4'}\n",
    "    exp_d = 2\n",
    "    n = 15 #Number of experimental data points to use\n",
    "    bounds = np.array([[-2, -2, -10, -2, -2, -2,  5, -2],\n",
    "                       [ 2,  2,   0,  2,  2,  2, 15,  2]])\n",
    "    LHS = True\n",
    "\n",
    "else:\n",
    "    Constants = Theta_True = np.array([1,-1])\n",
    "    skip_param_types = 0\n",
    "    param_dict = {0 : '\\\\theta_1', 1 : '\\\\theta_2'}\n",
    "    exp_d = 1\n",
    "    bounds = np.array([[-2,-2],[2,2]])\n",
    "    LHS = False\n",
    "    n = 5\n",
    "\n",
    "print(Constants.shape)\n",
    "print(Theta_True.shape)\n",
    "\n",
    "p = 20\n",
    "d = len(Theta_True)\n",
    "\n",
    "obj = np.array([\"obj\"])\n",
    "emulator = np.array([False])\n",
    "\n",
    "if emulator == True:\n",
    "    t = 20*n\n",
    "else:\n",
    "    t = 20\n",
    "\n",
    "# #Pull Experimental data from CSV\n",
    "exp_data_doc = 'Input_CSVs/Exp_Data/d='+str(exp_d)+'/n='+str(n)+'.csv'\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1:exp_d+1]\n",
    "Yexp = exp_data[:,-1]\n",
    "Xexp = clean_1D_arrays(Xexp)\n",
    "\n",
    "m = Xexp.shape[1]\n",
    "print(Xexp.shape)\n",
    "\n",
    "theta_mesh = gen_theta_set(LHS = LHS, n_points = p, dimensions = d, bounds = bounds)\n",
    "print(theta_mesh.shape)\n",
    "\n",
    "all_data_doc = find_train_doc_path(emulator, obj, d, t)\n",
    "all_data = np.array(pd.read_csv(all_data_doc, header=0,sep=\",\")) \n",
    "print(all_data.shape)\n",
    "\n",
    "train_data, test_data = test_train_split(all_data, sep_fact = 0.2, shuffle_seed=9)\n",
    "\n",
    "if CS == 1 and emulator == False:\n",
    "    train_p, test_p = train_data[:,1:-2], test_data[:,1:-2]\n",
    "else:\n",
    "    train_p, test_p = train_data[:,1:-1], test_data[:,1:-1]\n",
    "# print(train_p)\n",
    "print(train_p.shape)\n",
    "print(test_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cbbaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_x(x_vals, m, Xexp, emulator, norm = True, scaler = None):\n",
    "    \"\"\"\n",
    "    Normalizes or unnormalizes x data from training/testing data and experimental data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        x_vals: ndarray, x_values to normalize from training/testing data or Xexp when standard approaches are used\n",
    "        m: int, dimensionality of x data\n",
    "        Xexp: ndarraay, experimental x values\n",
    "        emulator: bool, whether GP is emulating fxn or error\n",
    "        norm: bool, whether the value will be normalized to 0 and 1 (True) or from 0 and 1 (False). Default True\n",
    "        scaler: None or MinMaxScaler(), used to un-normalize data or normalize data based on another sets normalization\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        x_scl: ndarray, rescaled values of x\n",
    "        scaler_x: MinMaxScaler(), scaler used to obtain these values\n",
    "    \"\"\"\n",
    "    x_vals = clean_1D_arrays(x_vals)\n",
    "    if emulator == True:\n",
    "        x_scl, scaler_x = norm_unnorm(x_vals, norm, scaler)\n",
    "#         x_scl, scaler_x = norm_unnorm(x_vals[:,-m:], norm, scaler)\n",
    "    else:\n",
    "        x_scl, scaler_x = norm_unnorm(Xexp, norm, scaler)\n",
    "    return x_scl, scaler_x\n",
    "\n",
    "def normalize_p_data(param_vals_data, m, emulator, norm = True, scaler = None):\n",
    "    \"\"\"\n",
    "    Normalizes or unnormalizes parameter data from training/testing data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        param_vals_data: ndarray, parameter values to normalize from training/testing data\n",
    "        m: int, dimensionality of x data\n",
    "        emulator: bool, whether GP is emulating fxn or error\n",
    "        norm: bool, whether the value will be normalized to 0 and 1 (True) or from 0 and 1 (False). Default True\n",
    "        scaler: None or MinMaxScaler(), used to un-normalize data or normalize data based on another sets normalization\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        param_data_scl: ndarray, rescaled values of x\n",
    "        scaler_theta: MinMaxScaler(), scaler used to obtain these values\n",
    "    \"\"\"\n",
    "    if emulator == True:\n",
    "        if norm == True:\n",
    "            param_data_scl, scaler_theta = norm_unnorm(param_vals_data[:,0:-m], norm, scaler)\n",
    "        else:\n",
    "            param_data_scl, scaler_theta = norm_unnorm(param_vals_data, norm, scaler)\n",
    "    else:\n",
    "        param_data_scl, scaler_theta = norm_unnorm(param_vals_data, norm, scaler)\n",
    "    return param_data_scl, scaler_theta\n",
    "\n",
    "def normalize_p_set(p_set, scaler_theta, norm = True):\n",
    "    \"\"\"\n",
    "    Normalizes or unnormalizes parameter data for theta_set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        param_vals_data: ndarray, parameter values to normalize from training/testing data\n",
    "        scaler_theta: None or MinMaxScaler(), used to (un)normalize data based on another sets normalization\n",
    "        norm: bool, whether the value will be normalized to 0 and 1 (True) or from 0 and 1 (False). Default True\n",
    "           \n",
    "    Returns\n",
    "    -------\n",
    "        p_set_scl: ndarray, rescaled values of x\n",
    "    \"\"\"\n",
    "    p_set_scl, scaler_theta = norm_unnorm(p_set, norm, scaler = scaler_theta)\n",
    "    return p_set_scl\n",
    "\n",
    "def normalize_p_true(p_true, scaler_theta, norm= True):\n",
    "    \"\"\"\n",
    "    Normalizes or unnormalizes parameter data for theta_true\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        p_true: ndarray, True parameter values\n",
    "        scaler_theta: None or MinMaxScaler(), used to (un)normalize data based on another sets normalization\n",
    "        norm: bool, whether the value will be normalized to 0 and 1 (True) or from 0 and 1 (False). Default True\n",
    "           \n",
    "    Returns\n",
    "    -------\n",
    "        theta_true_scl.flatten(): ndarray, rescaled values of theta_true flattened to correct dimensions\n",
    "    \"\"\"    \n",
    "    theta_true_scl, scaler_theta = norm_unnorm(clean_1D_arrays(p_true, param_clean = True), \n",
    "                                               norm, scaler_theta)\n",
    "    return theta_true_scl.flatten()\n",
    "\n",
    "def normalize_constants(Constants, p_true, scaler_theta, skip_params, CS, norm = True, scaler_C_before = None, \n",
    "                        scaler_C_after = None):\n",
    "    \"\"\"\n",
    "    Normalizes or unnormalizes data for constants\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        Constants: ndarray, ndarray, True values of Muller potential constants OR p_true (CS1 only)\n",
    "        p_true: ndarray, True parameter values\n",
    "        scaler_theta: None or MinMaxScaler(), used to (un)normalize data based on another sets normalization\n",
    "        skip_params: int, number of sets of parameters in Constants to skip before reaching the first iterable parameter row\n",
    "        CS: float, case study label \n",
    "        norm: bool, whether the value will be normalized to 0 and 1 (True) or from 0 and 1 (False). Default True\n",
    "        scaler_C_before: None or MinMaxScaler(), used to un-normalize normalized constansts before theta constants\n",
    "        scaler_C_after: None or MinMaxScaler(), used to un-normalize normalized constansts after theta constants\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        x_scl: ndarray, rescaled values of x\n",
    "        scaler_x: MinMaxScaler(), scaler used to obtain these values\n",
    "    \"\"\"    \n",
    "    num_param_types = clean_1D_arrays(Constants).shape[1]\n",
    "    len_param_type = int(len(p_true)/num_param_types)\n",
    "    if CS == 1:\n",
    "        Constants_scl = normalize_p_true(p_true, scaler_theta, norm)\n",
    "    else:\n",
    "        Constants_before, Constants_theta, Constants_after = np.split(Constants, [skip_params,len_param_type+1])\n",
    "        print(Constants_before.shape, Constants_theta.shape, Constants_after.shape)\n",
    "        Constants_before_scl, scaler_C_before = norm_unnorm(Constants_before.T, norm, scaler_C_before)\n",
    "        \n",
    "        Constants_theta_scl, scaler_theta =  norm_unnorm(clean_1D_arrays(Constants_theta.flatten(), param_clean = True),\n",
    "                                                 norm, scaler_theta)\n",
    "        Constants_theta_scl = Constants_theta_scl.reshape((2,4))\n",
    "        \n",
    "        Constants_after_scl, scaler_C_after = norm_unnorm(Constants_after.T, norm, scaler_C_after)\n",
    "        \n",
    "        Constants_scl = np.vstack((Constants_before_scl.T, Constants_theta_scl, Constants_after_scl.T))\n",
    "    return Constants_scl, scaler_C_before, scaler_C_after      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcc41a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4) (2, 4) (3, 4)\n",
      "[[ 0.          0.46511628  0.13953488  1.        ]\n",
      " [ 0.1068507   0.09384224  0.39060608 -0.05254495]\n",
      " [ 0.08827858  0.750685    0.80483466  0.68448759]\n",
      " [ 0.          0.          0.3271028   1.        ]\n",
      " [ 1.          0.5         0.25        0.        ]\n",
      " [ 0.          0.33333333  1.          0.66666667]]\n",
      "(1, 4) (2, 4) (3, 4)\n",
      "[[-200.  -100.  -170.    15. ]\n",
      " [  -1.    -1.    -6.5    0.7]\n",
      " [   0.     0.    11.     0.6]\n",
      " [ -10.   -10.    -6.5    0.7]\n",
      " [   1.     0.    -0.5   -1. ]\n",
      " [   0.     0.5    1.5    1. ]]\n",
      "[[-200.  -100.  -170.    15. ]\n",
      " [  -1.    -1.    -6.5    0.7]\n",
      " [   0.     0.    11.     0.6]\n",
      " [ -10.   -10.    -6.5    0.7]\n",
      " [   1.     0.    -0.5   -1. ]\n",
      " [   0.     0.5    1.5    1. ]]\n"
     ]
    }
   ],
   "source": [
    "norm = True\n",
    "X_data_scl, scaler_x = normalize_x(train_p[:,-m:], m, Xexp, emulator, norm)\n",
    "X_exp_scl = normalize_x(Xexp, m, Xexp, emulator, norm, scaler_x)[0]\n",
    "# print(X_exp_scl)\n",
    "train_p_scl, scaler_theta = normalize_p_data(train_p, m, emulator, norm)\n",
    "# p_set_scl = normalize_p_set(theta_mesh, scaler_theta, norm)\n",
    "p_true_scl = normalize_p_true(Theta_True, scaler_theta, norm)\n",
    "# print(p_true_scl)\n",
    "consatnts_scl, scaler_C_before, scaler_C_after  = normalize_constants(Constants, Theta_True, scaler_theta, skip_param_types, \n",
    "                                                                      CS, norm)\n",
    "print(consatnts_scl)\n",
    "norm = False\n",
    "# #Note these 3 lines are useless for emulator = False\n",
    "# X_data = normalize_x(X_data_scl, m, X_data_scl, emulator, norm, scaler_x)[0]\n",
    "# print(X_data[3])\n",
    "# print(train_p[3,-m:])\n",
    "\n",
    "# x_exp = normalize_x(X_exp_scl, m, X_exp_scl, emulator, norm, scaler_x)[0] #Wrong. Need to fix\n",
    "# print(x_exp[3])\n",
    "# print(Xexp[3])\n",
    "\n",
    "# train_p_rescl = normalize_p_data(train_p_scl, m, emulator, norm, scaler_theta)[0]\n",
    "# print(train_p_rescl[3])\n",
    "# # print(train_p[3])\n",
    "# print(train_p[3,0:-m])\n",
    "\n",
    "# p_set = normalize_p_set(p_set_scl, scaler_theta, norm)\n",
    "# print(p_set[3])\n",
    "# print(theta_mesh[3])\n",
    "\n",
    "# p_true = normalize_p_true(p_true_scl, scaler_theta, norm)\n",
    "# print(p_true)\n",
    "# print(Theta_True)\n",
    "\n",
    "Constants2 = normalize_constants(consatnts_scl, p_true_scl, scaler_theta, skip_param_types, CS, norm, scaler_C_before, \n",
    "                                 scaler_C_after)[0]\n",
    "print(Constants2)\n",
    "print(Constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(norm_unnorm(Constants_1_scl.T, norm = False, scaler = scaler_C1))\n",
    "# print(Constants_1)\n",
    "m = 2\n",
    "CS = 2.2\n",
    "\n",
    "p_vals_scl, scaler_theta = normalize_p_data(train_p, m, emulator, norm = True, scaler = None)\n",
    "# print(p_vals_scl)\n",
    "\n",
    "Constants_scl, scaler_C_before, scaler_C_after = normalize_constants(Constants, Theta_True, scaler_theta, skip_params, \n",
    "                                                                     CS, norm = True)\n",
    "\n",
    "constants_rscl, scaler_C_before, scaler_C_after = normalize_constants(Constants_scl, Theta_True, scaler_theta, skip_params, \n",
    "                                                                     CS, norm = False, scaler_C_before = scaler_C_before, \n",
    "                                                                     scaler_C_after = scaler_C_after)\n",
    "# constants = normalize_constants(Constants, Theta_True, scaler_theta, skip_params, CS, norm = False)\n",
    "print(Constants)\n",
    "print(constants_rscl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "random.seed(10)\n",
    "X = np.random.randint(-10,10, size = (3,3))\n",
    "Y = np.random.randint(-10,10, size = (3,3))\n",
    "print(X)\n",
    "# print(Y)\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# y_true  = []\n",
    "# y_pred = []\n",
    "\n",
    "# print(loo.get_n_splits(X))\n",
    "# for train_index, test_index in loo.split(X):\n",
    "#     df_test = X[test_index]\n",
    "#     df_train = X[train_index]\n",
    "#     print(df_train, df_test)\n",
    "    \n",
    "\n",
    "# scaler =  MinMaxScaler()\n",
    "# scaler.fit(X)\n",
    "# X = scaler.transform(X)\n",
    "# print(X)\n",
    "# X = scaler.inverse_transform(X)\n",
    "# print(X)\n",
    "\n",
    "from bo_functions_generic import norm_unnorm\n",
    "norm = True\n",
    "X_scl, scaler_X = norm_unnorm(X, norm = norm)\n",
    "Y_scl, scaler_Y = norm_unnorm(Y, norm = norm)\n",
    "\n",
    "print(X_scl, scaler_X)\n",
    "# print(Y, scaler_Y)\n",
    "\n",
    "X2 = np.array([[0, 1, 0.33],\n",
    "               [0.25 , 0.75, 0.66]])\n",
    "\n",
    "X3 = np.array([[2, 5, -2],\n",
    "               [-5 , 4, 0]])\n",
    "print(X3)\n",
    "X3, scaler_X = norm_unnorm(X3, norm = True, scaler = scaler_X)\n",
    "print(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474bc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xexp_bounds = np.array([[-1.5, -0.5],\n",
    "                        [1 , 2]])\n",
    "LHS = gen_theta_set(LHS = False, n_points = 20, dimensions = 2, bounds = Xexp_bounds)\n",
    "# print(LHS)\n",
    "# print(LHS.reshape((20,20,-1)).T)\n",
    "\n",
    "\n",
    "X1 = np.linspace(-1.5,1,20)\n",
    "X2 = np.linspace(-0.5,2,20)\n",
    "X_mesh = np.meshgrid(X1,X2)\n",
    "print(np.array(X_mesh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a211af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://realpython.com/python-timer/\n",
    "import time\n",
    "start = 3678393\n",
    "res = datetime.timedelta(seconds =start)\n",
    "print(res)\n",
    "\n",
    "time_tot = 0\n",
    "x = 0\n",
    "for i in range(89900):\n",
    "    start2 = time.time()\n",
    "    x += 1+2\n",
    "    end = time.time()\n",
    "\n",
    "    time_tot+= (end - start2)\n",
    "\n",
    "\n",
    "print(time_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4,3,0,0],\n",
    "              [4,0,0,3]])\n",
    "print(A[np.nonzero(A)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e064a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.zeros((3,3))\n",
    "B = pd.DataFrame(B)\n",
    "type(B)\n",
    "isinstance(B, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9)\n",
    "Array_1 = np.random.rand(3,2)\n",
    "Array_2 = np.random.rand(3,2)\n",
    "\n",
    "print(Array_1)\n",
    "print(Array_2)\n",
    "\n",
    "ds = gdal.Open('image.tif')\n",
    "# loop through each band\n",
    "\n",
    "path = \n",
    "\n",
    "with open(\"converted.raw\", \"wb\") as outfile:\n",
    "    for bi in range(ds.RasterCount):\n",
    "        band = ds.GetRasterBand(bi + 1)\n",
    "        # Read this band into a 2D NumPy array\n",
    "        ar = band.ReadAsArray()\n",
    "        print('Band %d has type %s'%(bi + 1, ar.dtype))   \n",
    "        np.save(outfile, ar.astype('uint16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847f32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba21891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
