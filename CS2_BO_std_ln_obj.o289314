Date and Time:  04-May-2023 (15:34:07)
Case Study:  2.2
Bounds On X Cut (T) or Normal (F)?  True
Dense Grid for Xexp? True
Number of Training Thetas:  200
Number of Experimental Data Points:  30
GP Training Package:  scikit_learn
GP Training Iterations (Gpytorch only):  300
GP Kernel Function:  Mat_52
GP Kernel lengthscale:  1
GP Kernel Has Trained outputscale?:  True
GP Training Restarts (when lengthscale not set):  5
Training Data Noise st.dev:  0.01
Runs: 3
BO Iterations: 30
%%%%%%%%%%%%%%%%%%%%%%%%%%
Norm: False
-------------------
GP Emulating Function Output (T) or SSE (F)? False
______________________________
Sparse Grid?: False
Scaling of Objective Function?  LN_obj
-  -  -  -  -  -  -  -  -  -  -
Separation Factor Train/Test: 1
Lengthscale Set To: 1
Explore Bias Multiplier: 1.0
The GP predicts the lowest SSE of 8.565e+04 occurs at θ = [-1.48654926  0.22815238 -5.8351264  -0.45665339  1.17468297 -0.63302511
 13.20573616 -0.10773604] during run 3 at BO iteration 1
At this point, the highest EI occurs at θ = [-1.03533494 -1.74325848 -0.47707725  1.95306718 -1.0572691  -0.07808274
 14.92232609  1.8301121 ]
True p:  [-1.  -1.  -6.5  0.7  0.   0.  11.   0.6]


