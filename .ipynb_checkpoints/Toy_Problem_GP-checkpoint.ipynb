{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#%matplotlib inline\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "220a0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "# Theta1 = np.linspace(-2,2,10)\n",
    "# Theta2 = np.linspace(-2,2,10)\n",
    "# mesh = np.array(np.meshgrid(Theta1, Theta2))\n",
    "# x = torch.tensor(np.linspace(-2,2,100))\n",
    "\n",
    "\n",
    "# train_T = torch.tensor(mesh.T.reshape(-1, 2))\n",
    "\n",
    "# noise_mean = 0\n",
    "# noise_std = 0.1**2\n",
    "# Theta_True = torch.tensor([1,-1])\n",
    "# noise = torch.tensor(np.random.normal(size=len(x),loc = noise_mean, scale = noise_std))\n",
    "\n",
    "# # True function is y=T1*x + T2*x^2 + x^3 with Gaussian noise\n",
    "# y_true =  Theta_True[0]*x + Theta_True[1]*x**2 +x**3 + noise\n",
    "\n",
    "# train_y = torch.tensor(np.zeros(len(train_T)))\n",
    "# #This will change to using pairs i and j in rows of a full theta with all combinations to get all the training data\n",
    "# for i in range(len(train_T)):\n",
    "#     for j in range(len(train_T)):\n",
    "#         y_exp = train_T[i,0]*x + train_T[j,1]*x**2 +x**3\n",
    "#         train_y[i] = (y_true[i] - y_exp[i])**2\n",
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 15^2 points in [-2,2] inclusive regularly spaced\n",
    "Theta1 = np.linspace(-2,2,3)\n",
    "Theta2 = np.linspace(-2,2,3)\n",
    "mesh = np.array(np.meshgrid(Theta1, Theta2))\n",
    "x = torch.tensor(np.linspace(-2,2,5))\n",
    "\n",
    "train_T = torch.tensor(mesh.T.reshape(-1, 2))\n",
    "\n",
    "\n",
    "noise_mean = 0\n",
    "noise_std = 0.1**2\n",
    "Theta_True = torch.tensor([1,-1])\n",
    "noise = torch.tensor(np.random.normal(size=len(x),loc = noise_mean, scale = noise_std))\n",
    "#Does Likelihood/defining the class add the noise for me?\n",
    "\n",
    "# True function is y=T1*x + T2*x^2 + x^3 with Gaussian noise\n",
    "y_true =  Theta_True[0]*x + Theta_True[1]*x**2 +x**3 + noise\n",
    "\n",
    "# train_y = torch.tensor(np.zeros([len(train_T),len(x)]))\n",
    "# #Need a for loop to allow all any x to be considered when GP is ran\n",
    "# for i in range(len(train_T)):\n",
    "#     for j in range(len(x)):\n",
    "#         y_true =  Theta_True[0]*x[j] + Theta_True[1]*x[j]**2 +x[j]**3 + torch.randn(x[j].size()) * noise_std\n",
    "#         y_exp = train_T[i,0]*x[j] + train_T[i,1]*x[j]**2 +x[j]**3\n",
    "#         print((y_true - y_exp)**2)\n",
    "#         train_y[i,j] = (y_true - y_exp)**2\n",
    "\n",
    "train_y = torch.tensor(np.zeros(len(train_T)))\n",
    "for i in range(len(train_T)):\n",
    "    y_exp = train_T[i,0]*x + train_T[i,1]*x**2 +x**3\n",
    "    train_y[i] = sum((y_true - y_exp)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8baeb09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh = np.array(np.meshgrid(Theta1, Theta2))\n",
    "# combinations = mesh.T.reshape(-1, 2)\n",
    "# print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d5ff1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_T, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_T, train_y, likelihood)\n",
    "        #What exactly is the mean and covariance of the GP model?\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_T, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal model hyperparameters\n",
    "training_iter = 300\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters \n",
    "#Should I change lr? How do I know what would be best?\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_T)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "#     print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "#         i + 1, training_iter, loss.item(),\n",
    "#         model.covar_module.base_kernel.lengthscale.item(),\n",
    "#          model.likelihood.noise.item()\n",
    "#     ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c599e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do I print the best hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2bbba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "test_Theta1 =  np.linspace(-2,2,3)\n",
    "test_Theta2 =  np.linspace(-2,2,3)\n",
    "mesh = np.array(np.meshgrid(test_Theta1, test_Theta2))\n",
    "\n",
    "# Test points are regularly spaced along [-2,2]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_T = torch.tensor(mesh.T.reshape(-1, 2))\n",
    "    observed_pred = likelihood(model(test_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6cad47ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 75.5822, 152.5827, 212.6790,  58.0681, 142.7911, 216.9297,  35.3126,\n",
      "        105.9201, 172.4094])\n"
     ]
    }
   ],
   "source": [
    "SSE = []\n",
    "for i in range(len(observed_pred.loc)):\n",
    "    SSE.append(observed_pred.loc[i].item())\n",
    "SSE = torch.tensor(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa39595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_func(xx, yy, x, y):\n",
    "    '''\n",
    "    Function to define define sum of squared error function for heat map\n",
    "    Arguments:\n",
    "        xx: An N X D array of all Theta1 values\n",
    "            \n",
    "        yy: An D X N array of all Theta2 values\n",
    "        theta: parameter vector\n",
    "        x: independent variable vector (predicted x values including noise)\n",
    "        y: dependent variable vector (predicted y values on Heat Map)\n",
    "    Returns:\n",
    "        sse: N x N sum of squared error matrix of all generated combination of xx and yy\n",
    "    '''\n",
    "    sse = np.zeros([len(xx),len(yy)])\n",
    "    \n",
    "    for i in range(len(xx)):\n",
    "        for j in range(len(yy)):\n",
    "            theta = np.array([xx[i][j],yy[i][j]])\n",
    "            sse[i][j] = sum((y - model(theta,x))**2) \n",
    "    \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a07719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "85fb47e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2., -2.],\n",
       "        [-2.,  0.],\n",
       "        [-2.,  2.],\n",
       "        [ 0., -2.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  2.],\n",
       "        [ 2., -2.],\n",
       "        [ 2.,  0.],\n",
       "        [ 2.,  2.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d6bf72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fheatmap\n",
    "# x = theta 1, y = theta 2, color = test\n",
    "xx , yy = torch.tensor(np.array(np.meshgrid(test_Theta1, test_Theta2)))\n",
    "zz = \n",
    "\n",
    "plt.contourf(xx, yy, zz) #What should xx, yy, and zz be for this to work?\n",
    "plt.colorbar()\n",
    "plt.scatter(theta[0],theta[1], color=\"red\", label = \"Optimal\")\n",
    "plt.axis('scaled')\n",
    "plt.grid()\n",
    "plt.legend(loc = 'best')\n",
    "plt.xlabel('Theta 1',weight='bold')\n",
    "plt.ylabel('Theta 2',weight='bold')\n",
    "plt.title('Heat Map of SSE', weight='bold',fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f98b98c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with torch.no_grad():\n",
    "# # Initialize plot\n",
    "\n",
    "# f, ax = plt.subplots()\n",
    "\n",
    "# # Get upper and lower confidence bounds\n",
    "# # Plot training data Heat Map (Theta 1,2 vs error)\n",
    "\n",
    "# ax.plot(train_T[0:].reshape(2,100)[0].numpy(), train_y.numpy(), 'k*') #Change\n",
    "\n",
    "# # Plot test data Heat Map (Theta 1,2 vs error)\n",
    "# ax.plot(test_T.reshape(2,50)[0:][1].numpy(), observed_pred.mean.numpy(), 'b') #Change\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd27f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
