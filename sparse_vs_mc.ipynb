{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cefe32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.17 s\n",
      "Wall time: 4.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "import copy\n",
    "import Tasmanian\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff728ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_name_val = 2\n",
    "meth_name_enum = 5\n",
    "CS_name  = CS_name_enum(cs_name_val)\n",
    "param_name_str = \"y0\" #set_param_str(cs_name_val)\n",
    "indecies_to_consider = set_idcs_to_consider(cs_name_val, param_name_str)\n",
    "meth_name = Method_name_enum(meth_name_enum)\n",
    "method = GPBO_Methods(meth_name)\n",
    "\n",
    "ep0 = 1\n",
    "ep_enum = Ep_enum(1)\n",
    "sep_fact = 1.0\n",
    "normalize = False\n",
    "noise_mean = 0\n",
    "noise_std = 0.01\n",
    "# noise_std = 0.0\n",
    "kernel = Kernel_enum(1)\n",
    "lenscl = None\n",
    "outputscl = 1 #outpulscl tuning is critical for log scaled obj fxns not to terminate early w/ regret (stdv affected)\n",
    "retrain_GP = 1\n",
    "reoptimize_obj = 1\n",
    "bo_iter_tot = 1\n",
    "bo_run_tot = 1\n",
    "save_data = False\n",
    "seed = 5\n",
    "ei_tol = 1e-6\n",
    "obj_tol = 1e-6\n",
    "DateTime = None\n",
    "\n",
    "num_x_data = 5\n",
    "gen_meth_x = Gen_meth_enum(2) #Note: Has to be the same for validation and sim data\n",
    "num_theta_data = 10*len(indecies_to_consider)\n",
    "num_theta_data_val = 200\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "gen_meth_theta_val = Gen_meth_enum(1)\n",
    "gen_heat_map_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f20c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get training data\n",
    "simulator = simulator_helper_test_fxns(CS_name, indecies_to_consider, noise_mean, noise_std, normalize, seed)\n",
    "\n",
    "#Calculate minimum Muller potential\n",
    "min_Mul = solve_pyomo_Muller_min(param_name_str, verbose = False)\n",
    "\n",
    "#Generate Exp Data\n",
    "exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x)\n",
    "\n",
    "#Generate Sim Data\n",
    "sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, False)\n",
    "\n",
    "#Generate sse_sim_data from new sim and exp_data\n",
    "sim_sse_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, sep_fact, False)\n",
    "\n",
    "#Generate validation data\n",
    "val_data = simulator.gen_sim_data(num_theta_data_val, num_x_data, gen_meth_theta_val, gen_meth_x, sep_fact, True)\n",
    "val_sse_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, sep_fact, True)\n",
    "\n",
    "#Set Cs_params and Simulator\n",
    "cs_name = CS_name.name + \"_BO_method_\" + meth_name.name + \"_sep_fact_\" + str(round(sep_fact,2))\n",
    "cs_params = CaseStudyParameters(cs_name, ep0, sep_fact, normalize, kernel, lenscl, outputscl, retrain_GP, \n",
    "                                reoptimize_obj, gen_heat_map_data, bo_iter_tot, bo_run_tot, save_data, DateTime, \n",
    "                                seed, ei_tol, obj_tol)\n",
    "\n",
    "#Initialize Driver\n",
    "ep_bias = Exploration_Bias(ep0, None, ep_enum, None, None, None, None, None, None, None)\n",
    "driver = GPBO_Driver(cs_params, method, simulator, exp_data, sim_data, sim_sse_data, val_data, val_sse_data, None, \n",
    "                     ep_bias, gen_meth_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b2ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make emulator\n",
    "if driver.method.emulator == False:\n",
    "    all_gp_data = driver.sim_sse_data\n",
    "    all_val_data = driver.val_sse_data\n",
    "    gp_emulator = Type_1_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                     driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                     driver.cs_params.retrain_GP, driver.cs_params.seed, None, None, None, None)\n",
    "else:\n",
    "    all_gp_data = driver.sim_data\n",
    "    all_val_data = driver.val_data\n",
    "    gp_emulator = Type_2_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                     driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                     driver.cs_params.retrain_GP, driver.cs_params.seed, None, None, None, None)\n",
    "    \n",
    "driver.gp_emulator = gp_emulator\n",
    "#Set train_test data\n",
    "train_data, test_data = driver.gp_emulator.set_train_test_data(driver.cs_params.sep_fact, driver.cs_params.seed)\n",
    "        \n",
    "#Initilize gp model\n",
    "gp_model = driver.gp_emulator.set_gp_model()\n",
    "driver.gp_emulator.train_gp(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb93375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ei_func(random_var, best_error, y_target, gp_mean, gp_var):\n",
    "    #Create a mask for values where pred_stdev >= 0 (Here approximation includes domain stdev >= 0) \n",
    "    pos_stdev_mask = (gp_var >= 0)\n",
    "\n",
    "    #Assuming all standard deviations are not zero\n",
    "    if np.any(pos_stdev_mask):\n",
    "        #Get indices and values where stdev > 0\n",
    "        valid_indices = np.where(pos_stdev_mask)[0]\n",
    "        gp_stdev_val = np.sqrt(gp_var[valid_indices])\n",
    "        gp_mean_val = gp_mean[valid_indices]\n",
    "        y_target_val = y_target[valid_indices]\n",
    "        mean_min_y = y_target_val - gp_mean_val\n",
    "    \n",
    "        # Calculate gp_var multiplied by points_p\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "\n",
    "        # Calculate the SSE for all data points simultaneously\n",
    "        sse_temp = np.sum((mean_min_y[:, np.newaxis].T - gp_stdev_rand_var)**2, axis=1)\n",
    "\n",
    "        # Apply max operator (equivalent to max[(best_error*ep) - SSE_Temp,0])\n",
    "        improvement = np.maximum(best_error - sse_temp, 0).reshape(-1,1)\n",
    "\n",
    "        # Calculate EI_temp using vectorized operations\n",
    "        ei_temp = improvement.flatten()\n",
    "        # mvn = np.array([multivariate_normal.pdf(random_var[i], mean = np.zeros(len(random_var[i])), cov = np.eye(len(random_var[i]))) \n",
    "                        # for i in range(len(random_var))])\n",
    "        \n",
    "        # Calculate the multivariate normal pdf for each row in 'epsilon'\n",
    "        mean_vector = np.zeros(random_var.shape[1])  # Assuming mean is zero for each dimension\n",
    "        cov_matrix = np.eye(random_var.shape[1])     # Assuming identity covariance matrix\n",
    "\n",
    "        mvn = multivariate_normal.pdf(random_var, mean=mean_vector, cov=cov_matrix)\n",
    "\n",
    "        ei_temp = ei_temp*mvn\n",
    "        print(ei_temp.shape)\n",
    "\n",
    "    else:\n",
    "        ei_temp = 0\n",
    "        \n",
    "    return ei_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(pilot_sample, statistic_function=None, ns=1000000, alpha=0.05, consolidator=lambda dummy: np.mean(dummy,axis=0), seed = seed):\n",
    "    # pilot_sample has one column per rv, one row per observation\n",
    "    # alpha is the level of significance; 0.05 for 95% confidence interval\n",
    "    pilot_sample = np.array(pilot_sample)\n",
    "    n_obs = pilot_sample.shape[0]\n",
    "    theta_shape = list(pilot_sample.shape)\n",
    "    quantiles = np.array([alpha*0.5, 1.0-alpha*0.5])\n",
    "    from numpy.random import default_rng\n",
    "    rng = default_rng(int(seed))\n",
    "    if consolidator is None:\n",
    "        f1 = statistic_function\n",
    "        f2 = None\n",
    "        theta_orig = f1(pilot_sample)\n",
    "        f1_shape = theta_orig.shape\n",
    "    elif statistic_function is None:\n",
    "        f1 = consolidator\n",
    "        f2 = None\n",
    "        theta_orig = f1(pilot_sample)\n",
    "        f1_shape = theta_orig.shape\n",
    "    else:\n",
    "        f1 = consolidator\n",
    "        f2 = statistic_function\n",
    "        consolidated_orig = f1(pilot_sample)\n",
    "        f1_shape = consolidated_orig.shape\n",
    "        theta_orig = f2(consolidated_orig)\n",
    "\n",
    "    theta_bs = np.zeros(tuple([ns]+list(f1_shape)))\n",
    "\n",
    "    for ibs in range(ns):\n",
    "        theta_bs[ibs,...] = f1(pilot_sample[rng.integers(0,n_obs,n_obs)])\n",
    "    if f2 is not None:\n",
    "        theta_bs = f2(theta_bs)\n",
    "    # percentile CI\n",
    "    CI_percentile = np.quantile(theta_bs, quantiles, 0)\n",
    "\n",
    "    return theta_orig, theta_bs, CI_percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98139058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\sparse_vs_mc.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m n\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# a = -3.668470846559581\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# b = 3.668470846559581\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# n = 115813\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m#Fill in f_args with data from a run\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m ei_mc, \u001b[39mvars\u001b[39m, ci \u001b[39m=\u001b[39m mc_integrate(ei_func, driver, a, b, \u001b[39mlen\u001b[39m(driver\u001b[39m.\u001b[39mexp_data\u001b[39m.\u001b[39my_vals), n \u001b[39m=\u001b[39m n)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(ei_mc[ei_mc \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# print(vars)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\sparse_vs_mc.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#Evaluate GP for validation data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m y_sim \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mexp_data\u001b[39m.\u001b[39my_vals\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m gp_mean_all, gp_var_all \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mgp_emulator\u001b[39m.\u001b[39meval_gp_mean_var_val()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m gp_mean \u001b[39m=\u001b[39m gp_mean_all[i\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(y_sim):i\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(y_sim)\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(y_sim)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m gp_var \u001b[39m=\u001b[39m gp_var_all[i\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(y_sim):i\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(y_sim)\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(y_sim)]\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\bo_methods_lib\\bo_methods_lib\\GPBO_Classes_New.py:1383\u001b[0m, in \u001b[0;36mGP_Emulator.eval_gp_mean_var_val\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_val_data, np\u001b[39m.\u001b[39mndarray), \u001b[39m\"\u001b[39m\u001b[39mself.feature_val_data must by np.ndarray\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m \u001b[39m#Evaluate test data for GP\u001b[39;00m\n\u001b[1;32m-> 1383\u001b[0m val_gp_mean, val_gp_var, val_gp_covar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__eval_gp_mean_var(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_val_data)\n\u001b[0;32m   1385\u001b[0m \u001b[39m#Set data parameters\u001b[39;00m\n\u001b[0;32m   1386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgp_val_data\u001b[39m.\u001b[39mgp_mean \u001b[39m=\u001b[39m val_gp_mean\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\bo_methods_lib\\bo_methods_lib\\GPBO_Classes_New.py:1312\u001b[0m, in \u001b[0;36mGP_Emulator.__eval_gp_mean_var\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1310\u001b[0m eval_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalerX\u001b[39m.\u001b[39mtransform(data)\n\u001b[0;32m   1311\u001b[0m \u001b[39m#Evaluate GP given parameter set theta and state point value\u001b[39;00m\n\u001b[1;32m-> 1312\u001b[0m gp_mean_scl, gp_covar_scl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_gp_model\u001b[39m.\u001b[39mpredict(eval_points, return_cov\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \n\u001b[0;32m   1314\u001b[0m \u001b[39m#Unscale gp_mean and gp_covariance\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m gp_mean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalerY\u001b[39m.\u001b[39minverse_transform(gp_mean_scl\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:456\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.predict\u001b[1;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[0;32m    450\u001b[0m V \u001b[39m=\u001b[39m solve_triangular(\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL_, K_trans\u001b[39m.\u001b[39mT, lower\u001b[39m=\u001b[39mGPR_CHOLESKY_LOWER, check_finite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    452\u001b[0m )\n\u001b[0;32m    454\u001b[0m \u001b[39mif\u001b[39;00m return_cov:\n\u001b[0;32m    455\u001b[0m     \u001b[39m# Alg 2.1, page 19, line 6 -> K(X_test, X_test) - v^T. v\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m     y_cov \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_(X) \u001b[39m-\u001b[39m V\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m V\n\u001b[0;32m    458\u001b[0m     \u001b[39m# undo normalisation\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     y_cov \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mouter(y_cov, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_train_std\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mreshape(\n\u001b[0;32m    460\u001b[0m         \u001b[39m*\u001b[39my_cov\u001b[39m.\u001b[39mshape, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:845\u001b[0m, in \u001b[0;36mSum.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    843\u001b[0m     \u001b[39mreturn\u001b[39;00m K1 \u001b[39m+\u001b[39m K2, np\u001b[39m.\u001b[39mdstack((K1_gradient, K2_gradient))\n\u001b[0;32m    844\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 845\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk1(X, Y) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk2(X, Y)\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:945\u001b[0m, in \u001b[0;36mProduct.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    941\u001b[0m     \u001b[39mreturn\u001b[39;00m K1 \u001b[39m*\u001b[39m K2, np\u001b[39m.\u001b[39mdstack(\n\u001b[0;32m    942\u001b[0m         (K1_gradient \u001b[39m*\u001b[39m K2[:, :, np\u001b[39m.\u001b[39mnewaxis], K2_gradient \u001b[39m*\u001b[39m K1[:, :, np\u001b[39m.\u001b[39mnewaxis])\n\u001b[0;32m    943\u001b[0m     )\n\u001b[0;32m    944\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 945\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk1(X, Y) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk2(X, Y)\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:1690\u001b[0m, in \u001b[0;36mMatern.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1688\u001b[0m length_scale \u001b[39m=\u001b[39m _check_length_scale(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_scale)\n\u001b[0;32m   1689\u001b[0m \u001b[39mif\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1690\u001b[0m     dists \u001b[39m=\u001b[39m pdist(X \u001b[39m/\u001b[39m length_scale, metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1692\u001b[0m     \u001b[39mif\u001b[39;00m eval_gradient:\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\spatial\\distance.py:2220\u001b[0m, in \u001b[0;36mpdist\u001b[1;34m(X, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   2218\u001b[0m     pdist_fn \u001b[39m=\u001b[39m metric_info\u001b[39m.\u001b[39mpdist_func\n\u001b[0;32m   2219\u001b[0m     _extra_windows_error_checks(X, out, (m \u001b[39m*\u001b[39m (m \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m,), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 2220\u001b[0m     \u001b[39mreturn\u001b[39;00m pdist_fn(X, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2221\u001b[0m \u001b[39melif\u001b[39;00m mstr\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mtest_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   2222\u001b[0m     metric_info \u001b[39m=\u001b[39m _TEST_METRICS\u001b[39m.\u001b[39mget(mstr, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Test MC integration\n",
    "def mc_integrate(func, driver, a, b, dim, n = 1000):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei\n",
    "    np.random.seed(seed)\n",
    "    integ_theta = np.zeros(len(driver.gp_emulator.gp_val_data.get_unique_theta()))\n",
    "    vars = np.zeros(len(driver.gp_emulator.gp_val_data.get_unique_theta()))\n",
    "    bs_vars = []\n",
    "    for i in range(len(driver.gp_emulator.gp_val_data.get_unique_theta())):\n",
    "        #Calcuate best error\n",
    "        if driver.method.emulator == False:\n",
    "            #Type 1 best error is inferred from training data \n",
    "            best_error, be_theta = driver.gp_emulator.calc_best_error()\n",
    "            best_errors_x = None\n",
    "        else:\n",
    "            #Type 2 best error must be calculated given the experimental data\n",
    "            best_error, be_theta, best_errors_x = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "        #Evaluate GP for validation data\n",
    "        y_sim = driver.exp_data.y_vals\n",
    "        gp_mean_all, gp_var_all = driver.gp_emulator.eval_gp_mean_var_val()\n",
    "        gp_mean = gp_mean_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "        gp_var = gp_var_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "        #Get random variable\n",
    "        random_var = np.random.multivariate_normal(np.zeros(dim), np.eye(dim), n)\n",
    "        #Calc EI\n",
    "        ei = func(random_var, best_error, y_sim, gp_mean, gp_var)\n",
    "        ei_mean = np.average(ei) #y.sum()/len(y)\n",
    "        vars[i] = 2*np.std(ei)\n",
    "        domain = np.power(b-a, dim)\n",
    "        \n",
    "        #Calc monte carlo integrand for each theta and add it to the total\n",
    "        integ = domain * ei_mean\n",
    "        integ_theta[i] = integ\n",
    "\n",
    "        # Perform bootstrapping\n",
    "        bootstrap_vars = bootstrap(ei, statistic_function=None, ns=100, alpha=0.05, seed=seed)\n",
    "        bs_vars.append(bootstrap_vars[-1])\n",
    "\n",
    "    return integ_theta, vars, np.array(bs_vars)\n",
    "\n",
    "a = 0\n",
    "b = 1\n",
    "n= 1000\n",
    "# a = -3.668470846559581\n",
    "# b = 3.668470846559581\n",
    "# n = 115813\n",
    "#Fill in f_args with data from a run\n",
    "ei_mc, vars, ci = mc_integrate(ei_func, driver, a, b, len(driver.exp_data.y_vals), n = n)\n",
    "print(ei_mc[ei_mc > 0])\n",
    "# print(vars)\n",
    "print(ci[(ci > 0).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caba991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Test Sparse Grid Integration\n",
    "#Calcuate best error\n",
    "if driver.method.emulator == False:\n",
    "    #Type 1 best error is inferred from training data \n",
    "    best_error_metrics = driver.gp_emulator.calc_best_error()\n",
    "    best_errors_x = None\n",
    "else:\n",
    "    #Type 2 best error must be calculated given the experimental data\n",
    "    best_error_metrics = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "#Set be in ep bias class\n",
    "driver.ep_bias.best_error = best_error_metrics[0]\n",
    "driver.ep_bias.set_ep()\n",
    "#Calculate EI for validation data\n",
    "if driver.method.emulator == False:\n",
    "    ei_output = driver.gp_emulator.eval_ei_val(driver.exp_data, driver.ep_bias, best_error_metrics)\n",
    "else:\n",
    "    ei_output = driver.gp_emulator.eval_ei_val(driver.exp_data, driver.ep_bias, best_error_metrics, driver.method)\n",
    "\n",
    "ei_sparse = ei_output[0]\n",
    "print(ei_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f0413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(ei_sparse[-1]/ei_mc[-1])\n",
    "print(ei_sparse[-4]/ei_mc[-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd366a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
