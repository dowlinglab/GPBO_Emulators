{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cefe32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.59 s, sys: 1.01 s, total: 3.61 s\n",
      "Wall time: 5.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import norm\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "import copy\n",
    "import Tasmanian\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff728ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_name_val = 1\n",
    "meth_name_enum = 5\n",
    "CS_name  = CS_name_enum(cs_name_val)\n",
    "param_name_str = set_param_str(cs_name_val)\n",
    "indecies_to_consider = set_idcs_to_consider(cs_name_val, param_name_str)\n",
    "meth_name = Method_name_enum(meth_name_enum)\n",
    "method = GPBO_Methods(meth_name)\n",
    "\n",
    "ep0 = 1\n",
    "ep_enum = Ep_enum(1)\n",
    "sep_fact = 1.0\n",
    "normalize = False\n",
    "noise_mean = 0\n",
    "noise_std = 0.01\n",
    "# noise_std = 0.0\n",
    "kernel = Kernel_enum(1)\n",
    "lenscl = None\n",
    "outputscl = 1 #outpulscl tuning is critical for log scaled obj fxns not to terminate early w/ regret (stdv affected)\n",
    "retrain_GP = 5\n",
    "reoptimize_obj = 5\n",
    "bo_iter_tot = 1\n",
    "bo_run_tot = 1\n",
    "save_data = False\n",
    "seed = 1\n",
    "ei_tol = 1e-6\n",
    "obj_tol = 1e-6\n",
    "DateTime = None\n",
    "\n",
    "num_x_data = 5\n",
    "gen_meth_x = Gen_meth_enum(2) #Note: Has to be the same for validation and sim data\n",
    "num_theta_data = 10*len(indecies_to_consider)\n",
    "num_theta_data_val = 20\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "gen_meth_theta_val = Gen_meth_enum(1)\n",
    "gen_heat_map_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f20c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get training data\n",
    "simulator = simulator_helper_test_fxns(CS_name, indecies_to_consider, noise_mean, noise_std, normalize, seed)\n",
    "\n",
    "#Calculate minimum Muller potential\n",
    "min_Mul = solve_pyomo_Muller_min(param_name_str, verbose = False)\n",
    "\n",
    "#Generate Exp Data\n",
    "exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x)\n",
    "\n",
    "#Generate Sim Data\n",
    "sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, False)\n",
    "\n",
    "#Generate sse_sim_data from new sim and exp_data\n",
    "sim_sse_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, sep_fact, False)\n",
    "\n",
    "#Generate validation data\n",
    "val_data = simulator.gen_sim_data(num_theta_data_val, num_x_data, gen_meth_theta_val, gen_meth_x, sep_fact, True)\n",
    "val_sse_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, sep_fact, True)\n",
    "\n",
    "#Set Cs_params and Simulator\n",
    "cs_name = CS_name.name + \"_BO_method_\" + meth_name.name + \"_sep_fact_\" + str(round(sep_fact,2))\n",
    "cs_params = CaseStudyParameters(cs_name, ep0, sep_fact, normalize, kernel, lenscl, outputscl, retrain_GP, \n",
    "                                reoptimize_obj, gen_heat_map_data, bo_iter_tot, bo_run_tot, save_data, DateTime, \n",
    "                                seed, ei_tol, obj_tol)\n",
    "\n",
    "#Initialize Driver\n",
    "ep_bias = Exploration_Bias(ep0, None, ep_enum, None, None, None, None, None, None, None)\n",
    "driver = GPBO_Driver(cs_params, method, simulator, exp_data, sim_data, sim_sse_data, val_data, val_sse_data, None, \n",
    "                     ep_bias, gen_meth_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b2ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make emulator\n",
    "if driver.method.emulator == False:\n",
    "    all_gp_data = driver.sim_sse_data\n",
    "    all_val_data = driver.val_sse_data\n",
    "    gp_emulator = Type_1_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                     driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                     driver.cs_params.retrain_GP, driver.cs_params.seed, None, None, None, None)\n",
    "else:\n",
    "    all_gp_data = driver.sim_data\n",
    "    all_val_data = driver.val_data\n",
    "    gp_emulator = Type_2_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                     driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                     driver.cs_params.retrain_GP, driver.cs_params.seed, None, None, None, None)\n",
    "    \n",
    "driver.gp_emulator = gp_emulator\n",
    "#Set train_test data\n",
    "train_data, test_data = driver.gp_emulator.set_train_test_data(driver.cs_params.sep_fact, driver.cs_params.seed)\n",
    "        \n",
    "#Initilize gp model\n",
    "gp_model = driver.gp_emulator.set_gp_model()\n",
    "driver.gp_emulator.train_gp(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb93375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ei_func(best_error, y_target, gp_mean, gp_var, random_var):\n",
    "    #Create a mask for values where pred_stdev >= 0 (Here approximation includes domain stdev >= 0) \n",
    "    pos_stdev_mask = (gp_var >= 0)\n",
    "\n",
    "    #Assuming all standard deviations are not zero\n",
    "    if np.any(pos_stdev_mask):\n",
    "        #Get indices and values where stdev > 0\n",
    "        valid_indices = np.where(pos_stdev_mask)[0]\n",
    "        gp_stdev_val = np.sqrt(gp_var[valid_indices])\n",
    "        gp_mean_val = gp_mean[valid_indices]\n",
    "        y_target_val = y_target[valid_indices]\n",
    "    \n",
    "        # Calculate gp_var multiplied by points_p\n",
    "        gp_stdev_rand_var = gp_stdev_val @ random_var.T\n",
    "\n",
    "        # Calculate the SSE for all data points simultaneously\n",
    "        sse_temp = np.sum((y_target_val[:, np.newaxis] - gp_mean_val[:, np.newaxis] - gp_stdev_rand_var.T)**2, axis=0)\n",
    "            \n",
    "        # Apply max operator (equivalent to max[(best_error*ep) - SSE_Temp,0])\n",
    "        improvement = np.maximum(best_error - sse_temp, 0).reshape(-1,1)\n",
    "\n",
    "        # Calculate EI_temp using vectorized operations\n",
    "        ei_temp = improvement*norm.pdf(random_var, loc=0, scale=1)\n",
    "\n",
    "    else:\n",
    "        ei_temp = 0\n",
    "        \n",
    "    return ei_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98139058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Test MC integration\n",
    "def mc_integrate(func, driver, a, b, dim, n = 1000):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei\n",
    "    integ_theta = np.zeros((driver.gp_emulator.gp_val_data.get_num_theta()))\n",
    "    for i in range(driver.gp_emulator.gp_val_data.get_num_theta()):\n",
    "        #Calcuate best error\n",
    "        if driver.method.emulator == False:\n",
    "            #Type 1 best error is inferred from training data \n",
    "            best_error, be_theta = driver.gp_emulator.calc_best_error()\n",
    "            best_errors_x = None\n",
    "        else:\n",
    "            #Type 2 best error must be calculated given the experimental data\n",
    "            best_error, be_theta, best_errors_x = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "        #Evaluate GP for validation data\n",
    "        y_sim = driver.exp_data.y_vals\n",
    "        gp_mean_all, gp_var_all = driver.gp_emulator.eval_gp_mean_var_val()\n",
    "        gp_mean = gp_mean_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "        gp_var = gp_var_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "        #Get random variable\n",
    "        random_var = np.random.uniform(a, b, (n, dim))\n",
    "        #Calc EI\n",
    "        ei = func(best_error, y_sim, gp_mean, gp_var, random_var)\n",
    "        ei_mean = np.average(ei) #y.sum()/len(y)\n",
    "        domain = np.power(b-a, dim)\n",
    "        \n",
    "        #Calc monte carlo integrand for each theta and add it to the total\n",
    "        integ = domain * ei_mean\n",
    "        integ_theta[i] = integ\n",
    "    \n",
    "    return integ_theta\n",
    "\n",
    "#Fill in f_args with data from a run\n",
    "print(mc_integrate(ei_func, driver, -1e20, 1e20, len(driver.exp_data.y_vals), n = 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caba991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Sparse Grid Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f0413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
