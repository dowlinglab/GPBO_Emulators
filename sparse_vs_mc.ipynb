{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cefe32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/mcarlozo/.conda/envs/Toy_Problem_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 s, sys: 360 ms, total: 2.93 s\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "import copy\n",
    "import Tasmanian\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff728ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_name_val = 2\n",
    "meth_name_enum = 5\n",
    "CS_name  = CS_name_enum(cs_name_val)\n",
    "param_name_str = \"y0\" #set_param_str(cs_name_val)\n",
    "indecies_to_consider = set_idcs_to_consider(cs_name_val, param_name_str)\n",
    "meth_name = Method_name_enum(meth_name_enum)\n",
    "method = GPBO_Methods(meth_name)\n",
    "\n",
    "ep0 = 1\n",
    "ep_enum = Ep_enum(1)\n",
    "sep_fact = 1.0\n",
    "normalize = False\n",
    "noise_mean = 0\n",
    "noise_std = 0.01\n",
    "# noise_std = 0.0\n",
    "kernel = Kernel_enum(1)\n",
    "lenscl = None\n",
    "outputscl = 1 #outpulscl tuning is critical for log scaled obj fxns not to terminate early w/ regret (stdv affected)\n",
    "retrain_GP = 1\n",
    "reoptimize_obj = 1\n",
    "bo_iter_tot = 1\n",
    "bo_run_tot = 1\n",
    "save_data = False\n",
    "seed = 5\n",
    "ei_tol = 1e-6\n",
    "obj_tol = 1e-6\n",
    "DateTime = None\n",
    "\n",
    "num_x_data = 5\n",
    "gen_meth_x = Gen_meth_enum(2) #Note: Has to be the same for validation and sim data\n",
    "num_theta_data = 10*len(indecies_to_consider)\n",
    "num_theta_data_val = 200\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "gen_meth_theta_val = Gen_meth_enum(1)\n",
    "gen_heat_map_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f20c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get training data\n",
    "simulator = simulator_helper_test_fxns(CS_name, indecies_to_consider, noise_mean, noise_std, normalize, seed)\n",
    "\n",
    "#Calculate minimum Muller potential\n",
    "min_Mul = solve_pyomo_Muller_min(param_name_str, verbose = False)\n",
    "\n",
    "#Generate Exp Data\n",
    "exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x)\n",
    "\n",
    "#Generate Sim Data\n",
    "sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, False)\n",
    "\n",
    "#Generate sse_sim_data from new sim and exp_data\n",
    "sim_sse_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, sep_fact, False)\n",
    "\n",
    "#Generate validation data\n",
    "val_data = simulator.gen_sim_data(num_theta_data_val, num_x_data, gen_meth_theta_val, gen_meth_x, sep_fact, True)\n",
    "val_sse_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, sep_fact, True)\n",
    "\n",
    "#Set Cs_params and Simulator\n",
    "cs_name = CS_name.name + \"_BO_method_\" + meth_name.name + \"_sep_fact_\" + str(round(sep_fact,2))\n",
    "cs_params = CaseStudyParameters(cs_name, ep0, sep_fact, normalize, kernel, lenscl, outputscl, retrain_GP, \n",
    "                                reoptimize_obj, gen_heat_map_data, bo_iter_tot, bo_run_tot, save_data, DateTime, \n",
    "                                seed, ei_tol, obj_tol)\n",
    "\n",
    "#Initialize Driver\n",
    "ep_bias = Exploration_Bias(ep0, None, ep_enum, None, None, None, None, None, None, None)\n",
    "driver = GPBO_Driver(cs_params, method, simulator, exp_data, sim_data, sim_sse_data, val_data, val_sse_data, None, \n",
    "                     ep_bias, gen_meth_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b2ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make emulator\n",
    "if driver.method.emulator == False:\n",
    "    all_gp_data = driver.sim_sse_data\n",
    "    all_val_data = driver.val_sse_data\n",
    "    gp_emulator = Type_1_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                     driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                     driver.cs_params.retrain_GP, driver.cs_params.seed, None, None, None, None)\n",
    "else:\n",
    "    all_gp_data = driver.sim_data\n",
    "    all_val_data = driver.val_data\n",
    "    gp_emulator = Type_2_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                     driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                     driver.cs_params.retrain_GP, driver.cs_params.seed, None, None, None, None)\n",
    "    \n",
    "driver.gp_emulator = gp_emulator\n",
    "#Set train_test data\n",
    "train_data, test_data = driver.gp_emulator.set_train_test_data(driver.cs_params.sep_fact, driver.cs_params.seed)\n",
    "        \n",
    "#Initilize gp model\n",
    "gp_model = driver.gp_emulator.set_gp_model()\n",
    "driver.gp_emulator.train_gp(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb93375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ei_func(random_var, best_error, y_target, gp_mean, gp_var):\n",
    "    #Create a mask for values where pred_stdev >= 0 (Here approximation includes domain stdev >= 0) \n",
    "    pos_stdev_mask = (gp_var >= 0)\n",
    "\n",
    "    #Assuming all standard deviations are not zero\n",
    "    if np.any(pos_stdev_mask):\n",
    "        #Get indices and values where stdev > 0\n",
    "        valid_indices = np.where(pos_stdev_mask)[0]\n",
    "        gp_stdev_val = np.sqrt(gp_var[valid_indices])\n",
    "        gp_mean_val = gp_mean[valid_indices]\n",
    "        y_target_val = y_target[valid_indices]\n",
    "        mean_min_y = y_target_val - gp_mean_val\n",
    "    \n",
    "        # Calculate gp_var multiplied by points_p\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "\n",
    "        # Calculate the SSE for all data points simultaneously\n",
    "        sse_temp = np.sum((mean_min_y[:, np.newaxis].T - gp_stdev_rand_var)**2, axis=1)\n",
    "\n",
    "        # Apply max operator (equivalent to max[(best_error*ep) - SSE_Temp,0])\n",
    "        improvement = np.maximum(best_error - sse_temp, 0).reshape(-1,1)\n",
    "\n",
    "        # Calculate EI_temp using vectorized operations\n",
    "        ei_temp = improvement.flatten()\n",
    "        \n",
    "        # Calculate the multivariate normal pdf for each row in 'epsilon'\n",
    "        mvn = multivariate_normal.pdf(random_var, mean=np.zeros(random_var.shape[1]), cov=np.eye(random_var.shape[1]))\n",
    "\n",
    "        ei_temp = ei_temp*mvn\n",
    "\n",
    "    else:\n",
    "        ei_temp = 0\n",
    "        \n",
    "    return ei_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db00c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Courtesy of Ryan Smith\n",
    "def bootstrap(pilot_sample, ns=100, alpha=0.05, seed = 1):\n",
    "    # pilot_sample has one column per rv, one row per observation\n",
    "    # alpha is the level of significance; 0.05 for 95% confidence interval\n",
    "    quantiles = np.array([alpha*0.5, 1.0-alpha*0.5])\n",
    "\n",
    "    #Set seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    #Determine mean of all original samples and its shape\n",
    "    theta_orig = np.mean(pilot_sample,axis=0)\n",
    "\n",
    "    #Initialize bootstrap samples as zeros\n",
    "    theta_bs = np.zeros(tuple([ns]+list(theta_orig.shape)))\n",
    "\n",
    "    #Create bootstrap samples\n",
    "    for ibs in range(ns):\n",
    "        samples = np.random.choice(pilot_sample, size= pilot_sample.shape[0], replace=True)\n",
    "        theta_bs[ibs,...] = np.mean(samples, axis = 0)\n",
    "\n",
    "    # percentile CI\n",
    "    CI_percentile = np.quantile(theta_bs, quantiles, 0)\n",
    "\n",
    "    # return theta_orig, theta_bs, CI_percentile\n",
    "    return CI_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98139058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Test MC integration\n",
    "def mc_integrate(func, driver, a, b, dim):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei\n",
    "    n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    integ_theta = np.zeros(len(driver.gp_emulator.gp_val_data.get_unique_theta()))\n",
    "    bs_vars = []\n",
    "    for i in range(len(driver.gp_emulator.gp_val_data.get_unique_theta())):\n",
    "        #Calcuate best error\n",
    "        if driver.method.emulator == False:\n",
    "            #Type 1 best error is inferred from training data \n",
    "            best_error, be_theta = driver.gp_emulator.calc_best_error()\n",
    "            best_errors_x = None\n",
    "        else:\n",
    "            #Type 2 best error must be calculated given the experimental data\n",
    "            best_error, be_theta, best_errors_x = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "        #Evaluate GP for validation data\n",
    "        y_sim = driver.exp_data.y_vals\n",
    "        gp_mean_all, gp_var_all = driver.gp_emulator.eval_gp_mean_var_val()\n",
    "        gp_mean = gp_mean_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "        gp_var = gp_var_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "        #Get random variable\n",
    "        random_var = np.random.multivariate_normal(np.zeros(dim), np.eye(dim), n)\n",
    "        #Calc EI\n",
    "        ei = func(random_var, best_error, y_sim, gp_mean, gp_var)\n",
    "        ei_mean = np.average(ei) #y.sum()/len(y)\n",
    "        domain = np.power(b-a, dim)\n",
    "        \n",
    "        #Calc monte carlo integrand for each theta and add it to the total\n",
    "        integ = domain * ei_mean\n",
    "        integ_theta[i] = integ\n",
    "\n",
    "        # Perform bootstrapping\n",
    "        bootstrap_vars = bootstrap(ei, ns=100, alpha=0.05, seed=seed)\n",
    "        bs_vars.append(bootstrap_vars)\n",
    "\n",
    "    return integ_theta, np.array(bs_vars)\n",
    "\n",
    "a = 0\n",
    "b = 1\n",
    "# a = -3.668470846559581\n",
    "# b = 3.668470846559581\n",
    "# n = 115813\n",
    "#Fill in f_args with data from a run\n",
    "ei_mc, ci = mc_integrate(ei_func, driver, a, b, len(driver.exp_data.y_vals))\n",
    "print(ei_mc[ei_mc > 0])\n",
    "print(ci[(ci > 0).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caba991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Sparse Grid Integration\n",
    "#Calcuate best error\n",
    "if driver.method.emulator == False:\n",
    "    #Type 1 best error is inferred from training data \n",
    "    best_error_metrics = driver.gp_emulator.calc_best_error()\n",
    "    best_errors_x = None\n",
    "else:\n",
    "    #Type 2 best error must be calculated given the experimental data\n",
    "    best_error_metrics = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "#Set be in ep bias class\n",
    "driver.ep_bias.best_error = best_error_metrics[0]\n",
    "driver.ep_bias.set_ep()\n",
    "#Calculate EI for validation data\n",
    "if driver.method.emulator == False:\n",
    "    ei_output = driver.gp_emulator.eval_ei_val(driver.exp_data, driver.ep_bias, best_error_metrics)\n",
    "else:\n",
    "    ei_output = driver.gp_emulator.eval_ei_val(driver.exp_data, driver.ep_bias, best_error_metrics, driver.method)\n",
    "\n",
    "ei_sparse = ei_output[0]\n",
    "print(ei_sparse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
