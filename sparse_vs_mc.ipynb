{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cefe32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.34 s\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "import copy\n",
    "import Tasmanian\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import integrate\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Test Functions\n",
    "def func1(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    return 1 - x1**2 - x2**2\n",
    "\n",
    "def func2(x1, x2):\n",
    "    return np.maximum(func1(x1,x2), 0)\n",
    "\n",
    "def func3(x1, x2):\n",
    "    return 0.5*(np.sqrt(func1(x1, x2)**2 + 1e-5) + func1(x1, x2))\n",
    "\n",
    "def func4(x1, x2):\n",
    "    return np.sin(x1)*x2\n",
    "\n",
    "def func5(x1, x2):\n",
    "    return np.maximum(func4(x1,x2), 0)\n",
    "\n",
    "def func6(x1, x2):\n",
    "    return 0.5*(np.sqrt(func4(x1, x2)**2 + 1e-5) + func4(x1, x2))\n",
    "\n",
    "def func7(x1, x2, x3, x4, x5):\n",
    "    return 1 - x1**2 - x2**2 - x3**2 - x4**2 - x5**2\n",
    "\n",
    "def func8(x1, x2, x3, x4, x5):\n",
    "    return np.maximum(func7(x1, x2, x3, x4, x5), 0)\n",
    "\n",
    "def func9(x1, x2, x3, x4, x5):\n",
    "    return 0.5*(np.sqrt(func7(x1, x2, x3, x4, x5)**2 + 1e-5) + func7(x1, x2, x3, x4, x5))\n",
    "\n",
    "#Create test functions*pdf(normal)\n",
    "def func1_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func1(x1,x2)*pdf\n",
    "\n",
    "def func2_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func2(x1,x2)*pdf\n",
    "\n",
    "def func3_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func3(x1,x2)*pdf\n",
    "\n",
    "def func4_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func4(x1,x2)*pdf\n",
    "\n",
    "def func5_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func5(x1,x2)*pdf\n",
    "\n",
    "def func6_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func6(x1,x2)*pdf\n",
    "\n",
    "def func7_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func7(x1,x2,x3,x4,x5)*pdf\n",
    "\n",
    "def func8_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func8(x1,x2,x3,x4,x5)*pdf\n",
    "\n",
    "def func9_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func9(x1,x2,x3,x4,x5)*pdf\n",
    "\n",
    "\n",
    "#Define simple Tasmanian SG integration fxn for \n",
    "def sg_integ_uniform(func, dim, depth = 20, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get grid points and weights\n",
    "    grid_p = Tasmanian.SparseGrid()\n",
    "    grid_p.makeGlobalGrid(dim, 0, depth, \"hyperbolic\", 'gauss-jacobi')\n",
    "    points_p = grid_p.getPoints()\n",
    "    weights_p = grid_p.getQuadratureWeights()\n",
    "\n",
    "    if dim == 2:\n",
    "        y = func(points_p[:,0], points_p[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(points_p[:,0], points_p[:,1], points_p[:,2],points_p[:,3],points_p[:,4])\n",
    "\n",
    "    integ = y@weights_p.T\n",
    "\n",
    "    return integ\n",
    "\n",
    "def mc_integ_uniform(func, a, b, dim, n, seed = 1):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei  \n",
    "    # n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)  \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get random variable\n",
    "    x_list = np.random.uniform(a, b, (n, dim))\n",
    "\n",
    "    if dim == 2:\n",
    "        y = func(x_list[:,0], x_list[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(x_list[:,0], x_list[:,1], x_list[:,2],x_list[:,3],x_list[:,4])\n",
    "\n",
    "    y_mean =  y.sum()/len(y)\n",
    "    domain = np.power(b-a, dim)\n",
    "\n",
    "    integ = domain * y_mean\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    bootstrap_vars = bootstrap(y, ns=1000, alpha=0.05, seed=seed)\n",
    "\n",
    "    return integ, np.array(bootstrap_vars)*domain\n",
    "\n",
    "#Bootstrap code for mc provided by Ryan Smith\n",
    "def bootstrap(pilot_sample, ns=100, alpha=0.05, seed = 1):\n",
    "    # pilot_sample has one column per rv, one row per observation\n",
    "    # alpha is the level of significance; 0.05 for 95% confidence interval\n",
    "    quantiles = np.array([alpha*0.5, 1.0-alpha*0.5])\n",
    "\n",
    "    #Set seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    #Determine mean of all original samples and its shape\n",
    "    theta_orig = np.mean(pilot_sample,axis=0)\n",
    "\n",
    "    #Initialize bootstrap samples as zeros\n",
    "    theta_bs = np.zeros(tuple([ns]+list(theta_orig.shape)))\n",
    "\n",
    "    #Create bootstrap samples\n",
    "    for ibs in range(ns):\n",
    "        samples = np.random.choice(pilot_sample, size= pilot_sample.shape[0], replace=True)\n",
    "        theta_bs[ibs,...] = np.mean(samples, axis = 0)\n",
    "\n",
    "    # percentile CI\n",
    "    CI_percentile = np.quantile(theta_bs, quantiles, 0)\n",
    "\n",
    "    # return theta_orig, theta_bs, CI_percentile\n",
    "    return CI_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:1233: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  quad_r = quad(f, low, high, args=args, full_output=self.full_output,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       scipy   mc n=100  mc n=1000  mc n=10000  sg depth=5  sg depth=10  \\\n",
      "0   1.333333   1.006297   1.288451    1.336877    1.333333     1.333333   \n",
      "1   1.570795   1.288276   1.533663    1.569565    1.333333     1.873080   \n",
      "2   1.570888   1.288369   1.533761    1.569660    1.333379     1.873007   \n",
      "3        0.0   0.137445  -0.002983    0.000148    0.000000     0.000000   \n",
      "4   0.459698   0.576202   0.466506    0.458559    0.630242     0.430468   \n",
      "5   0.459953   0.576323   0.466752    0.458818    0.630274     0.432838   \n",
      "6 -21.333333 -24.319122 -21.044289  -21.543264  -21.333333   -21.333333   \n",
      "7        n/a   1.231010   1.553981    1.512449  -21.333333    21.846363   \n",
      "8        n/a   1.231592   1.554520    1.512910  -21.331940    22.339082   \n",
      "\n",
      "   sg depth=20  \n",
      "0     1.333333  \n",
      "1     1.456093  \n",
      "2     1.456331  \n",
      "3     0.000000  \n",
      "4     0.450998  \n",
      "5     0.452638  \n",
      "6   -21.333333  \n",
      "7  -103.181580  \n",
      "8  -103.607586  \n"
     ]
    }
   ],
   "source": [
    "#Test MC vs Bootstrapping on a uniform distribution random variable\n",
    "column_names = [\"scipy\", \"mc n=100\", \"mc n=1000\", \"mc n=10000\", \"sg depth=5\", \"sg depth=10\", \"sg depth=20\"]\n",
    "results_df = pd.DataFrame(columns=column_names)\n",
    "# func_list = [func1, func2, func3, func4, func5, func6]\n",
    "func_list = [func1, func2, func3, func4, func5, func6, func7, func8, func9]\n",
    "\n",
    "l_bound = -1\n",
    "u_bound = 1\n",
    "seed = 1\n",
    "depth1 = 5\n",
    "depth2 = 10\n",
    "depth3 = 20\n",
    "n1 = 100\n",
    "n2 = 1000\n",
    "n3 = 10000\n",
    "\n",
    "#Loop over test functions\n",
    "for i in range(len(func_list)):\n",
    "    func = func_list[i]\n",
    "\n",
    "    if i > 5:\n",
    "        #Only evaluate w/ scipy up to example 7\n",
    "        bounds = np.full((5, 2), [l_bound, u_bound])\n",
    "        if i > 6:\n",
    "            z_scipy = \"n/a\"\n",
    "        else:\n",
    "            z_scipy = integrate.nquad(func, bounds)[0]\n",
    "        dim =5\n",
    "    else:\n",
    "        z_scipy = integrate.dblquad(func, l_bound, u_bound, l_bound, u_bound)[0]\n",
    "        dim =2\n",
    "\n",
    "    #Evaluate integral w/ MC for 3 n values\n",
    "    z_mc1, z_mc_ci1= mc_integ_uniform(func, l_bound, u_bound, dim, n1, seed = seed)\n",
    "    z_mc2, z_mc_ci2= mc_integ_uniform(func, l_bound, u_bound, dim, n2, seed = seed)\n",
    "    z_mc3, z_mc_ci3= mc_integ_uniform(func, l_bound, u_bound, dim, n3, seed = seed)\n",
    "    #Evaluate integral with sparse grid for 3 depths\n",
    "    z_sg1 = sg_integ_uniform(func, l_bound, u_bound, dim, depth1, seed = seed)\n",
    "    z_sg2 = sg_integ_uniform(func, l_bound, u_bound, dim, depth2, seed = seed)\n",
    "    z_sg3 = sg_integ_uniform(func, l_bound, u_bound, dim, depth3, seed = seed)\n",
    "\n",
    "    #Add results to dataframe\n",
    "    iter_df = pd.DataFrame(columns=column_names)\n",
    "    integ_results = [z_scipy, z_mc1, z_mc2, z_mc3, z_sg1, z_sg2, z_sg3]\n",
    "    # Add the new row to the DataFrame\n",
    "    iter_df.loc[0] = integ_results\n",
    "    results_df = pd.concat([results_df.astype(iter_df.dtypes), iter_df], ignore_index=True)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(\"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_test_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test MC vs Sparse Grid on a fxn*norm.pdf w/ gaussian random variable\n",
    "def sg_integ_gauss(func, dim, depth = 20, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get grid points and weights\n",
    "    grid_p = Tasmanian.SparseGrid()\n",
    "    grid_p.makeGlobalGrid(dim, 0, depth, \"hyperbolic\", 'gauss-hermite')\n",
    "    points_p = grid_p.getPoints()\n",
    "    points_p = np.sqrt(2)*points_p\n",
    "    weights_p = grid_p.getQuadratureWeights()\n",
    "\n",
    "    #Evaluate function\n",
    "    if dim == 2:\n",
    "        y = func(points_p[:,0], points_p[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(points_p[:,0], points_p[:,1], points_p[:,2],points_p[:,3],points_p[:,4])\n",
    "\n",
    "    integ = (1/np.pi)*y@weights_p.T\n",
    "\n",
    "    return integ\n",
    "\n",
    "def mc_integ_gauss(func, dim, n, seed = 1):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei  \n",
    "    # n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)  \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get random variable from normal distribution\n",
    "    x_list = np.random.multivariate_normal(np.zeros(dim), np.eye(dim), n)\n",
    "\n",
    "    #Evaluate function\n",
    "    if dim == 2:\n",
    "        y = func(x_list[:,0], x_list[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(x_list[:,0], x_list[:,1], x_list[:,2],x_list[:,3],x_list[:,4])\n",
    "\n",
    "    y_mean =  np.mean(y)\n",
    "\n",
    "    integ = y_mean\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    bootstrap_vars = bootstrap(y, ns=1000, alpha=0.05, seed=seed)\n",
    "\n",
    "    return integ, np.array(bootstrap_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\sparse_vs_mc.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     dim \u001b[39m=\u001b[39m\u001b[39m5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     z_scipy \u001b[39m=\u001b[39m integrate\u001b[39m.\u001b[39mdblquad(func_pdf, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     dim \u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m z_mc1, z_mc_ci1\u001b[39m=\u001b[39m mc_integrate_gauss(func, dim, n1, seed \u001b[39m=\u001b[39m seed)\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:775\u001b[0m, in \u001b[0;36mdblquad\u001b[1;34m(func, a, b, gfun, hfun, args, epsabs, epsrel)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtemp_ranges\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m [gfun(args[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(gfun) \u001b[39melse\u001b[39;00m gfun,\n\u001b[0;32m    773\u001b[0m             hfun(args[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(hfun) \u001b[39melse\u001b[39;00m hfun]\n\u001b[1;32m--> 775\u001b[0m \u001b[39mreturn\u001b[39;00m nquad(func, [temp_ranges, [a, b]], args\u001b[39m=\u001b[39margs,\n\u001b[0;32m    776\u001b[0m         opts\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mepsabs\u001b[39m\u001b[39m\"\u001b[39m: epsabs, \u001b[39m\"\u001b[39m\u001b[39mepsrel\u001b[39m\u001b[39m\"\u001b[39m: epsrel})\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:1179\u001b[0m, in \u001b[0;36mnquad\u001b[1;34m(func, ranges, args, opts, full_output)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1178\u001b[0m     opts \u001b[39m=\u001b[39m [opt \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(opt) \u001b[39melse\u001b[39;00m _OptFunc(opt) \u001b[39mfor\u001b[39;00m opt \u001b[39min\u001b[39;00m opts]\n\u001b[1;32m-> 1179\u001b[0m \u001b[39mreturn\u001b[39;00m _NQuad(func, ranges, opts, full_output)\u001b[39m.\u001b[39mintegrate(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:1233\u001b[0m, in \u001b[0;36m_NQuad.integrate\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1232\u001b[0m     f \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintegrate, depth\u001b[39m=\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m-> 1233\u001b[0m quad_r \u001b[39m=\u001b[39m quad(f, low, high, args\u001b[39m=\u001b[39margs, full_output\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_output,\n\u001b[0;32m   1234\u001b[0m               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopt)\n\u001b[0;32m   1235\u001b[0m value \u001b[39m=\u001b[39m quad_r[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1236\u001b[0m abserr \u001b[39m=\u001b[39m quad_r[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:465\u001b[0m, in \u001b[0;36mquad\u001b[1;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst, complex_func)\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m     retval \u001b[39m=\u001b[39m _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[0;32m    466\u001b[0m                    points)\n\u001b[0;32m    467\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m     \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:579\u001b[0m, in \u001b[0;36m_quad\u001b[1;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[0;32m    578\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n\u001b[0;32m    580\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    581\u001b[0m     \u001b[39mif\u001b[39;00m infbounds \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:1233\u001b[0m, in \u001b[0;36m_NQuad.integrate\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1232\u001b[0m     f \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintegrate, depth\u001b[39m=\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m-> 1233\u001b[0m quad_r \u001b[39m=\u001b[39m quad(f, low, high, args\u001b[39m=\u001b[39margs, full_output\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_output,\n\u001b[0;32m   1234\u001b[0m               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopt)\n\u001b[0;32m   1235\u001b[0m value \u001b[39m=\u001b[39m quad_r[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1236\u001b[0m abserr \u001b[39m=\u001b[39m quad_r[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:465\u001b[0m, in \u001b[0;36mquad\u001b[1;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst, complex_func)\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m     retval \u001b[39m=\u001b[39m _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[0;32m    466\u001b[0m                    points)\n\u001b[0;32m    467\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m     \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:579\u001b[0m, in \u001b[0;36m_quad\u001b[1;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[0;32m    578\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n\u001b[0;32m    580\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    581\u001b[0m     \u001b[39mif\u001b[39;00m infbounds \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\sparse_vs_mc.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mvars\u001b[39m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x1,x2])\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m pdf \u001b[39m=\u001b[39m multivariate_normal\u001b[39m.\u001b[39mpdf(\u001b[39mvars\u001b[39m, mean\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros(\u001b[39mvars\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), cov\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39meye(\u001b[39mvars\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#X22sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func2(x1,x2)\u001b[39m*\u001b[39mpdf\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:588\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.pdf\u001b[1;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    586\u001b[0m dim, mean, cov_object \u001b[39m=\u001b[39m params\n\u001b[0;32m    587\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_quantiles(x, dim)\n\u001b[1;32m--> 588\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logpdf(x, mean, cov_object))\n\u001b[0;32m    589\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(cov_object\u001b[39m.\u001b[39mrank \u001b[39m<\u001b[39m dim):\n\u001b[0;32m    590\u001b[0m     out_of_bounds \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mcov_object\u001b[39m.\u001b[39m_support_mask(x\u001b[39m-\u001b[39mmean)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Test MC vs Sparse Grid on a fxn*norm.pdf w/ gaussian random variable\n",
    "column_names = [\"scipy\", \"mc n=100\", \"mc n=1000\", \"mc n=10000\", \"sg depth=5\", \"sg depth=10\", \"sg depth=20\"]\n",
    "results_df = pd.DataFrame(columns=column_names)\n",
    "func_list = [func1, func2, func3, func4, func5, func6]\n",
    "func_list2 = [func1_pdf, func2_pdf, func3_pdf, func4_pdf, func5_pdf, func6_pdf] # func7_pdf, func8_pdf, func9_pdf\n",
    "# func_list = [func1, func2, func3, func4, func5, func6, func7, func8, func9]\n",
    "\n",
    "l_bound = -1\n",
    "u_bound = 1\n",
    "seed = 1\n",
    "depth1 = 5\n",
    "depth2 = 10\n",
    "depth3 = 20\n",
    "n1 = 100\n",
    "n2 = 1000\n",
    "n3 = 10000\n",
    "\n",
    "for i in range(len(func_list)):\n",
    "    func = func_list[i]\n",
    "    func_pdf = func_list2[i]\n",
    "\n",
    "    if i > 5:\n",
    "        #Scipy intractable for 5D problems\n",
    "        z_scipy = \"n/a\"\n",
    "\n",
    "        dim =5\n",
    "    else:\n",
    "        z_scipy = integrate.dblquad(func_pdf, -np.inf, np.inf, -np.inf, np.inf)[0]\n",
    "        dim =2\n",
    "\n",
    "    #Evaluate \"improvement (the normal function)\" integral using MC\n",
    "    z_mc1, z_mc_ci1= mc_integ_gauss(func, dim, n1, seed = seed)\n",
    "    z_mc2, z_mc_ci2= mc_integ_gauss(func, dim, n2, seed = seed)\n",
    "    z_mc3, z_mc_ci3= mc_integ_gauss(func, dim, n3, seed = seed)\n",
    "    #Evaluate \"improvement (the normal function)\" integral using sparse grid\n",
    "    z_sg1 = mc_integ_gauss(func, dim, depth1, seed = seed)\n",
    "    z_sg2 = mc_integ_gauss(func, dim, depth2, seed = seed)\n",
    "    z_sg3 = mc_integ_gauss(func, dim, depth3, seed = seed)\n",
    "\n",
    "    #Add to dataframe results\n",
    "    iter_df = pd.DataFrame(columns=column_names)\n",
    "    integ_results = [z_scipy, z_mc1, z_mc2, z_mc3, z_sg1, z_sg2, z_sg3]\n",
    "    # Add the new row to the DataFrame\n",
    "    iter_df.loc[0] = integ_results\n",
    "    results_df = pd.concat([results_df.astype(iter_df.dtypes), iter_df], ignore_index=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(\"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_test_gauss_all2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb93375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Expected Improvement\n",
    "def ei_func(random_var, best_error, y_target, gp_mean, gp_var):\n",
    "    #Create a mask for values where pred_stdev >= 0 (Here approximation includes domain stdev >= 0) \n",
    "    pos_stdev_mask = (gp_var >= 0)\n",
    "\n",
    "    #Assuming all standard deviations are not zero\n",
    "    if np.any(pos_stdev_mask):\n",
    "        #Get indices and values where stdev > 0\n",
    "        valid_indices = np.where(pos_stdev_mask)[0]\n",
    "        gp_stdev_val = np.sqrt(gp_var[valid_indices])\n",
    "        gp_mean_val = gp_mean[valid_indices]\n",
    "        y_target_val = y_target[valid_indices]\n",
    "        mean_min_y = y_target_val - gp_mean_val\n",
    "    \n",
    "        # Calculate gp_var multiplied by points_p\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "\n",
    "        # Calculate the SSE for all data points simultaneously\n",
    "        sse_temp = np.sum((mean_min_y[:, np.newaxis].T - gp_stdev_rand_var)**2, axis=1)\n",
    "\n",
    "        # Apply max operator (equivalent to max[(best_error*ep) - SSE_Temp,0])\n",
    "        improvement = np.maximum(best_error - sse_temp, 0).reshape(-1,1)\n",
    "\n",
    "        # Calculate EI_temp using vectorized operations\n",
    "        ei_temp = improvement.flatten()\n",
    "        \n",
    "        # Calculate the multivariate normal pdf for each row in 'epsilon'\n",
    "        # mvn = multivariate_normal.pdf(random_var, mean=np.zeros(random_var.shape[1]), cov=np.eye(random_var.shape[1]))\n",
    "        # ei_temp = ei_temp*mvn\n",
    "        #Note, we do not multiply by the mvn to get ei because for MC, we also divide by the mvn to get the final ei. Therefore, both steps are unnecessary\n",
    "\n",
    "    else:\n",
    "        ei_temp = 0\n",
    "        \n",
    "    return ei_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define MC integration code in the context of an EI test w/ a heat map\n",
    "def mc_integrate_simp(func, driver, heat_map_data, n):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei\n",
    "    # n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)\n",
    "    \n",
    "    np.random.seed(driver.cs_params.seed)\n",
    "\n",
    "    #Calcuate best error\n",
    "    if driver.method.emulator == False:\n",
    "        #Type 1 best error is inferred from training data \n",
    "        best_error, be_theta = driver.gp_emulator.calc_best_error()\n",
    "        best_errors_x = None\n",
    "    else:\n",
    "        #Type 2 best error must be calculated given the experimental data\n",
    "        best_error, be_theta, best_errors_x = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "        \n",
    "    #Evaluate GP for heat map data\n",
    "    y_sim = driver.exp_data.y_vals\n",
    "    gp_mean_all = heat_map_data.gp_mean\n",
    "    gp_var_all = heat_map_data.gp_var\n",
    "    gp_mean = gp_mean_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "    gp_var = gp_var_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "\n",
    "    #Get random variable\n",
    "    random_var = np.random.multivariate_normal(np.zeros(dim), np.eye(dim), n)\n",
    "\n",
    "    #Calc EI\n",
    "    ei = func(random_var, best_error, y_sim, gp_mean, gp_var)\n",
    "    ei_mean = np.average(ei) #y.sum()/len(y)\n",
    "\n",
    "    return ei_mean\n",
    "\n",
    "def sg_integ_simp(driver, heat_map_data, depth):\n",
    "    #Test Sparse Grid Integration\n",
    "    driver.sg_depth = depth\n",
    "    #Calcuate best error\n",
    "    if driver.method.emulator == False:\n",
    "        #Type 1 best error is inferred from training data \n",
    "        best_error_metrics = driver.gp_emulator.calc_best_error()\n",
    "        best_errors_x = None\n",
    "    else:\n",
    "        #Type 2 best error must be calculated given the experimental data\n",
    "        best_error_metrics = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "    #Set be in ep bias class\n",
    "    driver.ep_bias.best_error = best_error_metrics[0]\n",
    "    driver.ep_bias.set_ep()\n",
    "    #Calculate EI for heat map data\n",
    "    if driver.method.emulator == False:\n",
    "        ei_output = driver.gp_emulator.eval_ei_misc(heat_map_data, driver.exp_data, driver.ep_bias, best_error_metrics)\n",
    "    else:\n",
    "        ei_output = driver.gp_emulator.eval_ei_misc(heat_map_data, driver.exp_data, driver.ep_bias, best_error_metrics, driver.method, driver.sg_depth)\n",
    "\n",
    "    ei_sparse = ei_output[0]\n",
    "    return ei_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points_set = 30\n",
    "n_list = [100,1000,10000]\n",
    "sg_list = [5,10,20]\n",
    "\n",
    "cs_name_val = 1\n",
    "meth_name_enum = 5\n",
    "CS_name  = CS_name_enum(cs_name_val)\n",
    "param_name_str = \"t1t2\" #set_param_str(cs_name_val)\n",
    "indecies_to_consider = set_idcs_to_consider(cs_name_val, param_name_str)\n",
    "meth_name = Method_name_enum(meth_name_enum)\n",
    "method = GPBO_Methods(meth_name)\n",
    "\n",
    "ep0 = 1\n",
    "ep_enum = Ep_enum(1)\n",
    "sep_fact = 1.0\n",
    "normalize = True\n",
    "noise_mean = 0\n",
    "noise_std = 0.01\n",
    "kernel = Kernel_enum(1)\n",
    "lenscl = None\n",
    "outputscl = None #outpulscl tuning is critical for log scaled obj fxns not to terminate early w/ regret (stdv affected)\n",
    "retrain_GP = 1\n",
    "reoptimize_obj = 1\n",
    "bo_iter_tot = 1\n",
    "bo_run_tot = 1\n",
    "save_data = False\n",
    "ei_tol = 1e-6\n",
    "obj_tol = 1e-6\n",
    "DateTime = None\n",
    "seed = 13\n",
    "num_x_data = 5\n",
    "gen_meth_x = Gen_meth_enum(2) #Note: Has to be the same for validation and sim data\n",
    "num_theta_data = 10*len(indecies_to_consider)\n",
    "num_theta_data_val = 20\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "gen_meth_theta_val = Gen_meth_enum(1)\n",
    "gen_heat_map_data = False\n",
    "\n",
    "#Loop over seeds\n",
    "for ntd in range(5,31,5):\n",
    "    num_theta_data = ntd*len(indecies_to_consider)\n",
    "    #Get training data\n",
    "    simulator = simulator_helper_test_fxns(CS_name, indecies_to_consider, noise_mean, noise_std, seed)\n",
    "\n",
    "    #Calculate minimum Muller potential\n",
    "    min_Mul = solve_pyomo_Muller_min(param_name_str, verbose = False)\n",
    "\n",
    "    #Generate Exp Data\n",
    "    exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x)\n",
    "\n",
    "    #Generate Sim Data\n",
    "    sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, False)\n",
    "\n",
    "    #Generate sse_sim_data from new sim and exp_data\n",
    "    sim_sse_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, sep_fact, False)\n",
    "\n",
    "    #Generate validation data\n",
    "    val_data = simulator.gen_sim_data(num_theta_data_val, num_x_data, gen_meth_theta_val, gen_meth_x, sep_fact, True)\n",
    "    val_sse_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, sep_fact, True)\n",
    "\n",
    "    #Set Cs_params and Simulator\n",
    "    cs_name = CS_name.name + \"_BO_method_\" + meth_name.name + \"_sep_fact_\" + str(round(sep_fact,2))\n",
    "    cs_params = CaseStudyParameters(cs_name, ep0, sep_fact, normalize, kernel, lenscl, outputscl, retrain_GP, \n",
    "                                    reoptimize_obj, gen_heat_map_data, bo_iter_tot, bo_run_tot, save_data, DateTime, \n",
    "                                    seed, ei_tol, obj_tol)\n",
    "\n",
    "    #Initialize Driver\n",
    "    ep_bias = Exploration_Bias(ep0, None, ep_enum, None, None, None, None, None, None, None)\n",
    "    driver = GPBO_Driver(cs_params, method, simulator, exp_data, sim_data, sim_sse_data, val_data, val_sse_data, None, \n",
    "                        ep_bias, gen_meth_theta)\n",
    "\n",
    "    #Make emulator\n",
    "    if driver.method.emulator == False:\n",
    "        all_gp_data = driver.sim_sse_data\n",
    "        all_val_data = driver.val_sse_data\n",
    "        gp_emulator = Type_1_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                        driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                        driver.cs_params.retrain_GP, driver.cs_params.seed, driver.cs_params.normalize, None, None, None, None)\n",
    "    else:\n",
    "        all_gp_data = driver.sim_data\n",
    "        all_val_data = driver.val_data\n",
    "        gp_emulator = Type_2_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                        driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                        driver.cs_params.retrain_GP, driver.cs_params.seed, driver.cs_params.normalize, None, None, None, None)\n",
    "        \n",
    "    driver.gp_emulator = gp_emulator\n",
    "    #Set train_test data\n",
    "    train_data, test_data = driver.gp_emulator.set_train_test_data(driver.cs_params.sep_fact, driver.cs_params.seed)\n",
    "            \n",
    "    #Initilize and train gp model\n",
    "    gp_model = driver.gp_emulator.set_gp_model()\n",
    "    driver.gp_emulator.train_gp(gp_model)\n",
    "\n",
    "    #Get heat map data\n",
    "    heat_map_dict = driver.create_heat_map_param_data(n_points_set)\n",
    "    heat_map_data = heat_map_dict[list(heat_map_dict.keys())[0]]\n",
    "    unique_theta = heat_map_data.get_unique_theta()\n",
    "    featurized_hm_data = driver.gp_emulator.featurize_data(heat_map_data)\n",
    "    heat_map_data.gp_mean, heat_map_data.gp_var = gp_emulator.eval_gp_mean_var_misc(heat_map_data, featurized_hm_data)\n",
    "\n",
    "    ei_list = []\n",
    "    #Loop over n (100, 1000, and 10000) and sg depth (5, 10, 20)\n",
    "    for i in range(len(n_list)):\n",
    "        #Init EI array\n",
    "        ei_mc = np.zeros(len(unique_theta))\n",
    "        #Loop over each theta in heat map data\n",
    "        for theta in range(len(unique_theta)):\n",
    "            #Get EI From mc and save to ei array\n",
    "            ei_mc[theta] = mc_integrate_simp(ei_func, driver, len(driver.exp_data.y_vals), n_list[i], seed)\n",
    "        #Use sg method to get all eis at once\n",
    "        ei_sg = sg_integ_simp(driver, heat_map_data, sg_list[i])\n",
    "        #Save EI array to EI array list\n",
    "        ei_list.append(ei_mc.reshape(n_points_set,n_points_set))\n",
    "        ei_list.append(ei_sg.reshape(n_points_set,n_points_set))\n",
    "\n",
    "    ei_list = np.array(ei_list)\n",
    "\n",
    "    #Plot heat maps with plot_heat_maps()\n",
    "    #Make heat maps\n",
    "    title_fontsize = 24\n",
    "    other_fontsize = 20\n",
    "    xbins = 4\n",
    "    ybins = 5\n",
    "    zbins = 900\n",
    "    save_fig = False\n",
    "    cmap = \"autumn\"\n",
    "    log_data = True\n",
    "    test_mesh = unique_theta.T.reshape(2,n_points_set,n_points_set)\n",
    "    levels = [100,100,100,100,100,100]\n",
    "    param_names = list(heat_map_dict.keys())[0]\n",
    "    plot_axis_names = param_names\n",
    "    idcs_to_plot = [driver.simulator.theta_true_names.index(name) for name in param_names]\n",
    "    z_titles = [\"mc 100\", \"mc 1000\", \"mc 10000\", \"sg 5\", \"sg 10\", \"sg 20\"]\n",
    "    title = \"seed = \"+str(seed)\n",
    "    save_path = \"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_sg_test/ntd_\"+ str(int(num_theta_data)) +\"/\"\n",
    "\n",
    "    plot_heat_maps(test_mesh, None, None, None, None, plot_axis_names, levels, idcs_to_plot, ei_list, z_titles, xbins, ybins, zbins, title, title_fontsize, other_fontsize, cmap, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
