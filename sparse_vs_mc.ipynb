{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefe32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "import copy\n",
    "import Tasmanian\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import integrate\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Test Functions\n",
    "def func1(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    return 1 - x1**2 - x2**2\n",
    "\n",
    "def func2(x1, x2):\n",
    "    return np.maximum(func1(x1,x2), 0)\n",
    "\n",
    "def func3(x1, x2):\n",
    "    return 0.5*(np.sqrt(func1(x1, x2)**2 + 1e-5) + func1(x1, x2))\n",
    "\n",
    "def func4(x1, x2):\n",
    "    return np.sin(x1)*x2\n",
    "\n",
    "def func5(x1, x2):\n",
    "    return np.maximum(func4(x1,x2), 0)\n",
    "\n",
    "def func6(x1, x2):\n",
    "    return 0.5*(np.sqrt(func4(x1, x2)**2 + 1e-5) + func4(x1, x2))\n",
    "\n",
    "def func7(x1, x2, x3, x4, x5):\n",
    "    return 1 - x1**2 - x2**2 - x3**2 - x4**2 - x5**2\n",
    "\n",
    "def func8(x1, x2, x3, x4, x5):\n",
    "    return np.maximum(func7(x1, x2, x3, x4, x5), 0)\n",
    "\n",
    "def func9(x1, x2, x3, x4, x5):\n",
    "    return 0.5*(np.sqrt(func7(x1, x2, x3, x4, x5)**2 + 1e-5) + func7(x1, x2, x3, x4, x5))\n",
    "\n",
    "#Create test functions*pdf(normal)\n",
    "def func1_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func1(x1,x2)*pdf\n",
    "\n",
    "def func2_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func2(x1,x2)*pdf\n",
    "\n",
    "def func3_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func3(x1,x2)*pdf\n",
    "\n",
    "def func4_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func4(x1,x2)*pdf\n",
    "\n",
    "def func5_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func5(x1,x2)*pdf\n",
    "\n",
    "def func6_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func6(x1,x2)*pdf\n",
    "\n",
    "def func7_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func7(x1,x2,x3,x4,x5)*pdf\n",
    "\n",
    "def func8_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func8(x1,x2,x3,x4,x5)*pdf\n",
    "\n",
    "def func9_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func9(x1,x2,x3,x4,x5)*pdf\n",
    "\n",
    "\n",
    "#Define simple Tasmanian SG integration fxn for \n",
    "def sg_integ_uniform(func, dim, depth = 20, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get grid points and weights\n",
    "    grid_p = Tasmanian.SparseGrid()\n",
    "    grid_p.makeGlobalGrid(dim, 0, depth, \"hyperbolic\", 'gauss-jacobi')\n",
    "    points_p = grid_p.getPoints()\n",
    "    weights_p = grid_p.getQuadratureWeights()\n",
    "\n",
    "    if dim == 2:\n",
    "        y = func(points_p[:,0], points_p[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(points_p[:,0], points_p[:,1], points_p[:,2],points_p[:,3],points_p[:,4])\n",
    "\n",
    "    integ = y@weights_p.T\n",
    "\n",
    "    return integ\n",
    "\n",
    "def mc_integ_uniform(func, a, b, dim, n, seed = 1):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei  \n",
    "    # n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)  \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get random variable\n",
    "    x_list = np.random.uniform(a, b, (n, dim))\n",
    "\n",
    "    if dim == 2:\n",
    "        y = func(x_list[:,0], x_list[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(x_list[:,0], x_list[:,1], x_list[:,2],x_list[:,3],x_list[:,4])\n",
    "\n",
    "    y_mean =  y.sum()/len(y)\n",
    "    domain = np.power(b-a, dim)\n",
    "\n",
    "    integ = domain * y_mean\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    bootstrap_vars = bootstrap(y, ns=1000, alpha=0.05, seed=seed)\n",
    "\n",
    "    return integ, np.array(bootstrap_vars)*domain\n",
    "\n",
    "#Bootstrap code for mc provided by Ryan Smith\n",
    "def bootstrap(pilot_sample, ns=100, alpha=0.05, seed = 1):\n",
    "    # pilot_sample has one column per rv, one row per observation\n",
    "    # alpha is the level of significance; 0.05 for 95% confidence interval\n",
    "    quantiles = np.array([alpha*0.5, 1.0-alpha*0.5])\n",
    "\n",
    "    #Set seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    #Determine mean of all original samples and its shape\n",
    "    theta_orig = np.mean(pilot_sample,axis=0)\n",
    "\n",
    "    #Initialize bootstrap samples as zeros\n",
    "    theta_bs = np.zeros(tuple([ns]+list(theta_orig.shape)))\n",
    "\n",
    "    #Create bootstrap samples\n",
    "    for ibs in range(ns):\n",
    "        samples = np.random.choice(pilot_sample, size= pilot_sample.shape[0], replace=True)\n",
    "        theta_bs[ibs,...] = np.mean(samples, axis = 0)\n",
    "\n",
    "    # percentile CI\n",
    "    CI_percentile = np.quantile(theta_bs, quantiles, 0)\n",
    "\n",
    "    # return theta_orig, theta_bs, CI_percentile\n",
    "    return CI_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test MC vs Bootstrapping on a uniform distribution random variable\n",
    "column_names = [\"scipy\", \"mc n=100\", \"mc n=1000\", \"mc n=10000\", \"sg depth=5\", \"sg depth=10\", \"sg depth=20\"]\n",
    "results_df = pd.DataFrame(columns=column_names)\n",
    "# func_list = [func1, func2, func3, func4, func5, func6]\n",
    "func_list = [func1, func2, func3, func4, func5, func6, func7, func8, func9]\n",
    "\n",
    "#Note -1 to 1 chosen to allow use of Gauss-Jacobi rule\n",
    "l_bound = -1\n",
    "u_bound = 1\n",
    "seed = 1\n",
    "depth1 = 5\n",
    "depth2 = 10\n",
    "depth3 = 20\n",
    "n1 = 100\n",
    "n2 = 1000\n",
    "n3 = 10000\n",
    "\n",
    "#Loop over test functions\n",
    "for i in range(len(func_list)):\n",
    "    func = func_list[i]\n",
    "\n",
    "    if i > 5:\n",
    "        #Only evaluate w/ scipy up to example 7\n",
    "        bounds = np.full((5, 2), [l_bound, u_bound])\n",
    "        if i > 6:\n",
    "            z_scipy = \"n/a\"\n",
    "        else:\n",
    "            z_scipy = integrate.nquad(func, bounds)[0]\n",
    "        dim =5\n",
    "    else:\n",
    "        z_scipy = integrate.dblquad(func, l_bound, u_bound, l_bound, u_bound)[0]\n",
    "        dim =2\n",
    "\n",
    "    #Evaluate integral w/ MC for 3 n values\n",
    "    z_mc1, z_mc_ci1= mc_integ_uniform(func, l_bound, u_bound, dim, n1, seed = seed)\n",
    "    z_mc2, z_mc_ci2= mc_integ_uniform(func, l_bound, u_bound, dim, n2, seed = seed)\n",
    "    z_mc3, z_mc_ci3= mc_integ_uniform(func, l_bound, u_bound, dim, n3, seed = seed)\n",
    "    #Evaluate integral with sparse grid for 3 depths\n",
    "    z_sg1 = sg_integ_uniform(func, dim, depth1, seed = seed)\n",
    "    z_sg2 = sg_integ_uniform(func, dim, depth2, seed = seed)\n",
    "    z_sg3 = sg_integ_uniform(func, dim, depth3, seed = seed)\n",
    "\n",
    "    #Add results to dataframe\n",
    "    iter_df = pd.DataFrame(columns=column_names)\n",
    "    integ_results = [z_scipy, z_mc1, z_mc2, z_mc3, z_sg1, z_sg2, z_sg3]\n",
    "    # Add the new row to the DataFrame\n",
    "    iter_df.loc[0] = integ_results\n",
    "    results_df = pd.concat([results_df.astype(iter_df.dtypes), iter_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(\"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_test_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test MC vs Sparse Grid on a fxn*norm.pdf w/ gaussian random variable\n",
    "def sg_integ_gauss(func, dim, depth = 20, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get grid points and weights\n",
    "    grid_p = Tasmanian.SparseGrid()\n",
    "    grid_p.makeGlobalGrid(dim, 0, depth, \"hyperbolic\", 'gauss-hermite')\n",
    "    points_p = grid_p.getPoints()\n",
    "    points_p = np.sqrt(2)*points_p\n",
    "    weights_p = grid_p.getQuadratureWeights()\n",
    "\n",
    "    #Evaluate function\n",
    "    if dim == 2:\n",
    "        y = func(points_p[:,0], points_p[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(points_p[:,0], points_p[:,1], points_p[:,2],points_p[:,3],points_p[:,4])\n",
    "\n",
    "    integ = (1/np.pi)*y@weights_p.T\n",
    "\n",
    "    return integ\n",
    "\n",
    "def mc_integ_gauss(func, dim, n, seed = 1):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei  \n",
    "    # n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)  \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get random variable from normal distribution\n",
    "    x_list = np.random.multivariate_normal(np.zeros(dim), np.eye(dim), n)\n",
    "\n",
    "    #Evaluate function\n",
    "    if dim == 2:\n",
    "        y = func(x_list[:,0], x_list[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(x_list[:,0], x_list[:,1], x_list[:,2],x_list[:,3],x_list[:,4])\n",
    "\n",
    "    y_mean =  np.mean(y)\n",
    "\n",
    "    integ = y_mean\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    bootstrap_vars = bootstrap(y, ns=1000, alpha=0.05, seed=seed)\n",
    "\n",
    "    return integ, np.array(bootstrap_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test MC vs Sparse Grid on a fxn*norm.pdf w/ gaussian random variable\n",
    "column_names = [\"scipy\", \"mc n=100\", \"mc n=1000\", \"mc n=10000\", \"sg depth=5\", \"sg depth=10\", \"sg depth=20\"]\n",
    "results_df = pd.DataFrame(columns=column_names)\n",
    "func_list = [func1, func2, func3, func4, func5, func6]\n",
    "func_list2 = [func1_pdf, func2_pdf, func3_pdf, func4_pdf, func5_pdf, func6_pdf] # func7_pdf, func8_pdf, func9_pdf\n",
    "# func_list = [func1, func2, func3, func4, func5, func6, func7, func8, func9]\n",
    "\n",
    "l_bound = -1\n",
    "u_bound = 1\n",
    "seed = 1\n",
    "depth1 = 5\n",
    "depth2 = 10\n",
    "depth3 = 20\n",
    "n1 = 100\n",
    "n2 = 1000\n",
    "n3 = 10000\n",
    "\n",
    "for i in range(len(func_list)):\n",
    "    func = func_list[i]\n",
    "    func_pdf = func_list2[i]\n",
    "\n",
    "    if i > 5:\n",
    "        #Scipy intractable for 5D problems\n",
    "        z_scipy = \"n/a\"\n",
    "\n",
    "        dim =5\n",
    "    else:\n",
    "        z_scipy = integrate.dblquad(func_pdf, -np.inf, np.inf, -np.inf, np.inf)[0]\n",
    "        dim =2\n",
    "\n",
    "    #Evaluate \"improvement (the normal function)\" integral using MC\n",
    "    z_mc1, z_mc_ci1= mc_integ_gauss(func, dim, n1, seed = seed)\n",
    "    z_mc2, z_mc_ci2= mc_integ_gauss(func, dim, n2, seed = seed)\n",
    "    z_mc3, z_mc_ci3= mc_integ_gauss(func, dim, n3, seed = seed)\n",
    "    #Evaluate \"improvement (the normal function)\" integral using sparse grid\n",
    "    z_sg1 = mc_integ_gauss(func, dim, depth1, seed = seed)\n",
    "    z_sg2 = mc_integ_gauss(func, dim, depth2, seed = seed)\n",
    "    z_sg3 = mc_integ_gauss(func, dim, depth3, seed = seed)\n",
    "\n",
    "    #Add to dataframe results\n",
    "    iter_df = pd.DataFrame(columns=column_names)\n",
    "    integ_results = [z_scipy, z_mc1, z_mc2, z_mc3, z_sg1, z_sg2, z_sg3]\n",
    "    # Add the new row to the DataFrame\n",
    "    iter_df.loc[0] = integ_results\n",
    "    results_df = pd.concat([results_df.astype(iter_df.dtypes), iter_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(\"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_test_gauss_all2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb93375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Expected Improvement\n",
    "def ei_func(random_var, best_error, y_target, gp_mean, gp_var):\n",
    "    #Create a mask for values where pred_stdev >= 0 (Here approximation includes domain stdev >= 0) \n",
    "    pos_stdev_mask = (gp_var >= 0)\n",
    "\n",
    "    #Assuming all standard deviations are not zero\n",
    "    if np.any(pos_stdev_mask):\n",
    "        #Get indices and values where stdev > 0\n",
    "        valid_indices = np.where(pos_stdev_mask)[0]\n",
    "        gp_stdev_val = np.sqrt(gp_var[valid_indices])\n",
    "        gp_mean_val = gp_mean[valid_indices]\n",
    "        y_target_val = y_target[valid_indices]\n",
    "        mean_min_y = y_target_val - gp_mean_val\n",
    "    \n",
    "        # Calculate gp_var multiplied by points_p\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "\n",
    "        # Calculate the SSE for all data points simultaneously\n",
    "        sse_temp = np.sum((mean_min_y[:, np.newaxis].T - gp_stdev_rand_var)**2, axis=1)\n",
    "\n",
    "        # Apply max operator (equivalent to max[(best_error*ep) - SSE_Temp,0])\n",
    "        improvement = np.maximum(best_error - sse_temp, 0).reshape(-1,1)\n",
    "\n",
    "        # Calculate EI_temp using vectorized operations\n",
    "        ei_temp = improvement.flatten()\n",
    "        \n",
    "        # Calculate the multivariate normal pdf for each row in 'epsilon'\n",
    "        # mvn = multivariate_normal.pdf(random_var, mean=np.zeros(random_var.shape[1]), cov=np.eye(random_var.shape[1]))\n",
    "        # ei_temp = ei_temp*mvn\n",
    "        #Note, we do not multiply by the mvn to get ei because for MC, we also divide by the mvn to get the final ei. Therefore, both steps are unnecessary\n",
    "\n",
    "    else:\n",
    "        ei_temp = 0\n",
    "        \n",
    "    return ei_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define MC integration code in the context of an EI test w/ a heat map\n",
    "def mc_integ_ei(func, driver, heat_map_data, n, theta_i):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei\n",
    "    # n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)\n",
    "    dim = len(driver.exp_data.y_vals)\n",
    "    np.random.seed(driver.cs_params.seed)\n",
    "\n",
    "    #Calcuate best error\n",
    "    if driver.method.emulator == False:\n",
    "        #Type 1 best error is inferred from training data \n",
    "        best_error, be_theta = driver.gp_emulator.calc_best_error()\n",
    "        best_errors_x = None\n",
    "    else:\n",
    "        #Type 2 best error must be calculated given the experimental data\n",
    "        best_error, be_theta, best_errors_x = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "        \n",
    "    #Evaluate GP for heat map data\n",
    "    y_sim = driver.exp_data.y_vals\n",
    "    gp_mean_all = heat_map_data.gp_mean\n",
    "    gp_var_all = heat_map_data.gp_var\n",
    "    gp_mean = gp_mean_all[theta_i*len(y_sim):theta_i*len(y_sim)+len(y_sim)]\n",
    "    gp_var = gp_var_all[theta_i*len(y_sim):theta_i*len(y_sim)+len(y_sim)]\n",
    "\n",
    "    #Get random variable\n",
    "    random_var = np.random.multivariate_normal(np.zeros(dim), np.eye(dim), n)\n",
    "\n",
    "    #Calc EI\n",
    "    ei = func(random_var, best_error, y_sim, gp_mean, gp_var)\n",
    "    ei_mean = np.mean(ei) #y.sum()/len(y)\n",
    "\n",
    "    return ei_mean\n",
    "\n",
    "def sg_integ_ei(driver, heat_map_data, depth):\n",
    "    #Test Sparse Grid Integration\n",
    "    driver.sg_depth = depth\n",
    "    #Calcuate best error\n",
    "    if driver.method.emulator == False:\n",
    "        #Type 1 best error is inferred from training data \n",
    "        best_error_metrics = driver.gp_emulator.calc_best_error()\n",
    "        best_errors_x = None\n",
    "    else:\n",
    "        #Type 2 best error must be calculated given the experimental data\n",
    "        best_error_metrics = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "    #Set be in ep bias class\n",
    "    driver.ep_bias.best_error = best_error_metrics[0]\n",
    "    driver.ep_bias.set_ep()\n",
    "    #Calculate EI for heat map data\n",
    "    if driver.method.emulator == False:\n",
    "        ei_output = driver.gp_emulator.eval_ei_misc(heat_map_data, driver.exp_data, driver.ep_bias, best_error_metrics)\n",
    "    else:\n",
    "        ei_output = driver.gp_emulator.eval_ei_misc(heat_map_data, driver.exp_data, driver.ep_bias, best_error_metrics, driver.method, driver.sg_depth)\n",
    "\n",
    "    ei_sparse = ei_output[0]\n",
    "    return ei_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points_set = 30\n",
    "n_list = [100, 1000, 1000]\n",
    "sg_list = [5, 10, 20]\n",
    "\n",
    "cs_name_val = 1\n",
    "meth_name_enum = 5\n",
    "CS_name  = CS_name_enum(cs_name_val)\n",
    "param_name_str = \"t1t2\" #set_param_str(cs_name_val)\n",
    "indecies_to_consider = set_idcs_to_consider(cs_name_val, param_name_str)\n",
    "meth_name = Method_name_enum(meth_name_enum)\n",
    "method = GPBO_Methods(meth_name)\n",
    "\n",
    "ep0 = 1\n",
    "ep_enum = Ep_enum(1)\n",
    "sep_fact = 1.0\n",
    "normalize = True\n",
    "noise_mean = 0\n",
    "noise_std = 0.01\n",
    "kernel = Kernel_enum(1)\n",
    "lenscl = None\n",
    "outputscl = None #outpulscl tuning is critical for log scaled obj fxns not to terminate early w/ regret (stdv affected)\n",
    "retrain_GP = 1\n",
    "reoptimize_obj = 1\n",
    "bo_iter_tot = 1\n",
    "bo_run_tot = 1\n",
    "save_data = False\n",
    "ei_tol = 1e-6\n",
    "obj_tol = 1e-6\n",
    "DateTime = None\n",
    "seed = 13\n",
    "num_x_data = 5\n",
    "gen_meth_x = Gen_meth_enum(2) #Note: Has to be the same for validation and sim data\n",
    "num_theta_data = 10*len(indecies_to_consider)\n",
    "num_theta_data_val = 20\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "gen_meth_theta_val = Gen_meth_enum(1)\n",
    "gen_heat_map_data = False\n",
    "\n",
    "#Loop over seeds\n",
    "for seed in range(1,2):\n",
    "    #Get training data\n",
    "    simulator = simulator_helper_test_fxns(CS_name, indecies_to_consider, noise_mean, noise_std, seed)\n",
    "\n",
    "    #Calculate minimum Muller potential\n",
    "    min_Mul = solve_pyomo_Muller_min(param_name_str, verbose = False)\n",
    "\n",
    "    #Generate Exp Data\n",
    "    exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x)\n",
    "\n",
    "    #Generate Sim Data\n",
    "    sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, False)\n",
    "\n",
    "    #Generate sse_sim_data from new sim and exp_data\n",
    "    sim_sse_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, sep_fact, False)\n",
    "\n",
    "    #Generate validation data\n",
    "    val_data = simulator.gen_sim_data(num_theta_data_val, num_x_data, gen_meth_theta_val, gen_meth_x, sep_fact, True)\n",
    "    val_sse_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, sep_fact, True)\n",
    "\n",
    "    #Set Cs_params and Simulator\n",
    "    cs_name = CS_name.name + \"_BO_method_\" + meth_name.name + \"_sep_fact_\" + str(round(sep_fact,2))\n",
    "    cs_params = CaseStudyParameters(cs_name, ep0, sep_fact, normalize, kernel, lenscl, outputscl, retrain_GP, \n",
    "                                    reoptimize_obj, gen_heat_map_data, bo_iter_tot, bo_run_tot, save_data, DateTime, \n",
    "                                    seed, ei_tol, obj_tol)\n",
    "\n",
    "    #Initialize Driver\n",
    "    ep_bias = Exploration_Bias(ep0, None, ep_enum, None, None, None, None, None, None, None)\n",
    "    driver = GPBO_Driver(cs_params, method, simulator, exp_data, sim_data, sim_sse_data, val_data, val_sse_data, None, \n",
    "                        ep_bias, gen_meth_theta)\n",
    "\n",
    "    #Make emulator\n",
    "    if driver.method.emulator == False:\n",
    "        all_gp_data = driver.sim_sse_data\n",
    "        all_val_data = driver.val_sse_data\n",
    "        gp_emulator = Type_1_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                        driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                        driver.cs_params.retrain_GP, driver.cs_params.seed, driver.cs_params.normalize, None, None, None, None)\n",
    "    else:\n",
    "        all_gp_data = driver.sim_data\n",
    "        all_val_data = driver.val_data\n",
    "        gp_emulator = Type_2_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                        driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                        driver.cs_params.retrain_GP, driver.cs_params.seed, driver.cs_params.normalize, None, None, None, None)\n",
    "        \n",
    "    driver.gp_emulator = gp_emulator\n",
    "    #Set train_test data\n",
    "    train_data, test_data = driver.gp_emulator.set_train_test_data(driver.cs_params.sep_fact, driver.cs_params.seed)\n",
    "            \n",
    "    #Initilize and train gp model\n",
    "    gp_model = driver.gp_emulator.set_gp_model()\n",
    "    driver.gp_emulator.train_gp(gp_model)\n",
    "\n",
    "    #Get heat map data\n",
    "    heat_map_dict = driver.create_heat_map_param_data(n_points_set)\n",
    "    heat_map_data = heat_map_dict[list(heat_map_dict.keys())[0]]\n",
    "    unique_theta = heat_map_data.get_unique_theta()\n",
    "    featurized_hm_data = driver.gp_emulator.featurize_data(heat_map_data)\n",
    "    heat_map_data.gp_mean, heat_map_data.gp_var = gp_emulator.eval_gp_mean_var_misc(heat_map_data, featurized_hm_data)\n",
    "\n",
    "    ei_list = []\n",
    "    #Loop over n (100, 1000, and 10000) and sg depth (5, 10, 20)\n",
    "    for i in range(len(n_list)):\n",
    "        #Init EI array\n",
    "        ei_mc = np.zeros(len(unique_theta))\n",
    "        #Loop over each theta in heat map data\n",
    "        for theta in range(len(unique_theta)):\n",
    "            #Get EI From mc and save to ei array\n",
    "            ei_mc[theta] = mc_integ_ei(ei_func, driver, heat_map_data, n_list[i], theta)\n",
    "        #Use sg method to get all eis at once\n",
    "        ei_sg = sg_integ_ei(driver, heat_map_data, sg_list[i])\n",
    "        # #Save EI array to EI array list\n",
    "        ei_list.append(ei_mc.reshape(n_points_set,n_points_set))\n",
    "        ei_list.append(ei_sg.reshape(n_points_set,n_points_set))\n",
    "\n",
    "    ei_list = np.array(ei_list)\n",
    "\n",
    "    #Plot heat maps with plot_heat_maps()\n",
    "    #Make heat maps\n",
    "    title_fontsize = 24\n",
    "    other_fontsize = 20\n",
    "    xbins = 4\n",
    "    ybins = 5\n",
    "    zbins = 900\n",
    "    save_fig = False\n",
    "    cmap = \"autumn\"\n",
    "    log_data = True\n",
    "    test_mesh = unique_theta.T.reshape(2,n_points_set,n_points_set)\n",
    "    levels = [100,100,100,100,100,100]\n",
    "    param_names = list(heat_map_dict.keys())[0]\n",
    "    plot_axis_names = param_names\n",
    "    idcs_to_plot = [driver.simulator.theta_true_names.index(name) for name in param_names]\n",
    "    z_titles = [\"mc 100\", \"sg 5\", \"mc 1000\", \"sg 10\", \"mc 10000\", \"sg 20\"]\n",
    "    title = \"seed = \"+ str(seed)\n",
    "    save_path = None\n",
    "    # save_path = \"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_sg_test/seed{:02d}/\".format(int(seed))\n",
    "\n",
    "    plot_heat_maps(test_mesh, None, None, None, None, plot_axis_names, levels, idcs_to_plot, ei_list, z_titles, xbins, ybins, zbins, title, title_fontsize, other_fontsize, cmap, save_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Create .mp4 file\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "\n",
    "def list_png_files_in_seed_subdirectories(directory):\n",
    "    search_pattern = os.path.join(directory, 'seed**',\"*\",\"*\", '*.png')\n",
    "    png_files = glob.glob(search_pattern, recursive=True)\n",
    "    return png_files\n",
    "\n",
    "# Example usage:\n",
    "directory_path = \"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_sg_test/\"\n",
    "filenames = list_png_files_in_seed_subdirectories(directory_path)\n",
    "# print(filenames)\n",
    "\n",
    "gif_path = \"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_sg_test/seed_mov.mp4\"\n",
    "with imageio.get_writer(gif_path, mode='I', fps=0.3) as writer: #Note. For gif use duration instead of fps\n",
    "    #For each file\n",
    "    for filename in filenames: \n",
    "        #Get image\n",
    "        image = imageio.imread(filename, pilmode = \"RGBA\")\n",
    "        #Get the correct shape for the pngs based on the 1st file\n",
    "        if filename == filenames[0]: \n",
    "            shape = image.shape\n",
    "            #Force image to have XY dims divisible by 16\n",
    "            new_shape = (np.ceil(shape[0] / 16) * 16, np.ceil(shape[1] / 16) * 16, shape[2])\n",
    "        #If item shapes not the same force them to be the same. Fixes issues where pixels are off\n",
    "        if image.shape is not shape: \n",
    "            image = resize(image, (new_shape))\n",
    "        #Add file to movie as a uint8 type and multiply array by 255 to get correct coloring\n",
    "        writer.append_data((image*255).astype(np.uint8)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
