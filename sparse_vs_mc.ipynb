{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cefe32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.38 s\n",
      "Wall time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement, combinations, permutations\n",
    "import copy\n",
    "import Tasmanian\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bo_methods_lib\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_New import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Class_fxns import * #Fix this later\n",
    "from bo_methods_lib.bo_methods_lib.GPBO_Classes_plotters import * #Fix this later\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import integrate\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sg_integrate(func, a, b, dim, depth = 20, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get grid points and weights\n",
    "    grid_p = Tasmanian.SparseGrid()\n",
    "    grid_p.makeGlobalGrid(dim, 0, depth, \"hyperbolic\", 'gauss-jacobi')\n",
    "    points_p = grid_p.getPoints()\n",
    "    # print(len(points_p))\n",
    "    weights_p = grid_p.getQuadratureWeights()\n",
    "\n",
    "    if dim == 2:\n",
    "        y = func(points_p[:,0], points_p[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(points_p[:,0], points_p[:,1], points_p[:,2],points_p[:,3],points_p[:,4])\n",
    "\n",
    "    integ = y@weights_p.T\n",
    "\n",
    "    return integ\n",
    "\n",
    "def mc_integrate(func, a, b, dim, n, seed = 1):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei  \n",
    "    # n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)  \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get random variable\n",
    "    x_list = np.random.uniform(a, b, (n, dim))\n",
    "\n",
    "    if dim == 2:\n",
    "        y = func(x_list[:,0], x_list[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(x_list[:,0], x_list[:,1], x_list[:,2],x_list[:,3],x_list[:,4])\n",
    "\n",
    "    y_mean =  y.sum()/len(y)\n",
    "    domain = np.power(b-a, dim)\n",
    "\n",
    "    integ = domain * y_mean\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    bootstrap_vars = bootstrap(y, ns=1000, alpha=0.05, seed=seed)\n",
    "\n",
    "    return integ, np.array(bootstrap_vars)*domain\n",
    "\n",
    "def bootstrap(pilot_sample, ns=100, alpha=0.05, seed = 1):\n",
    "    # pilot_sample has one column per rv, one row per observation\n",
    "    # alpha is the level of significance; 0.05 for 95% confidence interval\n",
    "    quantiles = np.array([alpha*0.5, 1.0-alpha*0.5])\n",
    "\n",
    "    #Set seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    #Determine mean of all original samples and its shape\n",
    "    theta_orig = np.mean(pilot_sample,axis=0)\n",
    "\n",
    "    #Initialize bootstrap samples as zeros\n",
    "    theta_bs = np.zeros(tuple([ns]+list(theta_orig.shape)))\n",
    "\n",
    "    #Create bootstrap samples\n",
    "    for ibs in range(ns):\n",
    "        samples = np.random.choice(pilot_sample, size= pilot_sample.shape[0], replace=True)\n",
    "        theta_bs[ibs,...] = np.mean(samples, axis = 0)\n",
    "\n",
    "    # percentile CI\n",
    "    CI_percentile = np.quantile(theta_bs, quantiles, 0)\n",
    "\n",
    "    # return theta_orig, theta_bs, CI_percentile\n",
    "    return CI_percentile\n",
    "\n",
    "\n",
    "#Create Test 2D Functions\n",
    "def func1(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    return 1 - x1**2 - x2**2\n",
    "\n",
    "def func2(x1, x2):\n",
    "    return np.maximum(func1(x1,x2), 0)\n",
    "\n",
    "def func3(x1, x2):\n",
    "    return 0.5*(np.sqrt(func1(x1, x2)**2 + 1e-5) + func1(x1, x2))\n",
    "\n",
    "def func4(x1, x2):\n",
    "    return np.sin(x1)*x2\n",
    "\n",
    "def func5(x1, x2):\n",
    "    return np.maximum(func4(x1,x2), 0)\n",
    "\n",
    "def func6(x1, x2):\n",
    "    return 0.5*(np.sqrt(func4(x1, x2)**2 + 1e-5) + func4(x1, x2))\n",
    "\n",
    "def func7(x1, x2, x3, x4, x5):\n",
    "    return 1 - x1**2 - x2**2 - x3**2 - x4**2 - x5**2\n",
    "\n",
    "def func8(x1, x2, x3, x4, x5):\n",
    "    return np.maximum(func7(x1, x2, x3, x4, x5), 0)\n",
    "\n",
    "def func9(x1, x2, x3, x4, x5):\n",
    "    return 0.5*(np.sqrt(func7(x1, x2, x3, x4, x5)**2 + 1e-5) + func7(x1, x2, x3, x4, x5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:1233: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  quad_r = quad(f, low, high, args=args, full_output=self.full_output,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       scipy   mc n=100  mc n=1000  mc n=10000  sg depth=5  sg depth=10  \\\n",
      "0   1.333333   1.006297   1.288451    1.336877    1.333333     1.333333   \n",
      "1   1.570795   1.288276   1.533663    1.569565    1.333333     1.873080   \n",
      "2   1.570888   1.288369   1.533761    1.569660    1.333379     1.873007   \n",
      "3        0.0   0.137445  -0.002983    0.000148    0.000000     0.000000   \n",
      "4   0.459698   0.576202   0.466506    0.458559    0.630242     0.430468   \n",
      "5   0.459953   0.576323   0.466752    0.458818    0.630274     0.432838   \n",
      "6 -21.333333 -24.319122 -21.044289  -21.543264  -21.333333   -21.333333   \n",
      "7        n/a   1.231010   1.553981    1.512449  -21.333333    21.846363   \n",
      "8        n/a   1.231592   1.554520    1.512910  -21.331940    22.339082   \n",
      "\n",
      "   sg depth=20  \n",
      "0     1.333333  \n",
      "1     1.456093  \n",
      "2     1.456331  \n",
      "3     0.000000  \n",
      "4     0.450998  \n",
      "5     0.452638  \n",
      "6   -21.333333  \n",
      "7  -103.181580  \n",
      "8  -103.607586  \n"
     ]
    }
   ],
   "source": [
    "column_names = [\"scipy\", \"mc n=100\", \"mc n=1000\", \"mc n=10000\", \"sg depth=5\", \"sg depth=10\", \"sg depth=20\"]\n",
    "results_df = pd.DataFrame(columns=column_names)\n",
    "# func_list = [func1, func2, func3, func4, func5, func6]\n",
    "func_list = [func1, func2, func3, func4, func5, func6, func7, func8, func9]\n",
    "\n",
    "l_bound = -1\n",
    "u_bound = 1\n",
    "seed = 1\n",
    "depth1 = 5\n",
    "depth2 = 10\n",
    "depth3 = 20\n",
    "n1 = 100\n",
    "n2 = 1000\n",
    "n3 = 10000\n",
    "\n",
    "for i in range(len(func_list)):\n",
    "    func = func_list[i]\n",
    "\n",
    "    if i > 5:\n",
    "        bounds = np.full((5, 2), [l_bound, u_bound])\n",
    "        if i > 6:\n",
    "            z_scipy = \"n/a\"\n",
    "        else:\n",
    "            z_scipy = integrate.nquad(func, bounds)[0]\n",
    "        dim =5\n",
    "    else:\n",
    "        z_scipy = integrate.dblquad(func, l_bound, u_bound, l_bound, u_bound)[0]\n",
    "        dim =2\n",
    "\n",
    "    z_mc1, z_mc_ci1= mc_integrate(func, l_bound, u_bound, dim, n1, seed = seed)\n",
    "    z_mc2, z_mc_ci2= mc_integrate(func, l_bound, u_bound, dim, n2, seed = seed)\n",
    "    z_mc3, z_mc_ci3= mc_integrate(func, l_bound, u_bound, dim, n3, seed = seed)\n",
    "    z_sg1 = sg_integrate(func, l_bound, u_bound, dim, depth1, seed = seed)\n",
    "    z_sg2 = sg_integrate(func, l_bound, u_bound, dim, depth2, seed = seed)\n",
    "    z_sg3 = sg_integrate(func, l_bound, u_bound, dim, depth3, seed = seed)\n",
    "\n",
    "    iter_df = pd.DataFrame(columns=column_names)\n",
    "    integ_results = [z_scipy, z_mc1, z_mc2, z_mc3, z_sg1, z_sg2, z_sg3]\n",
    "    # Add the new row to the DataFrame\n",
    "    iter_df.loc[0] = integ_results\n",
    "    results_df = pd.concat([results_df.astype(iter_df.dtypes), iter_df], ignore_index=True)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(\"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_test_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sg_integrate_gauss(func, dim, depth = 20, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get grid points and weights\n",
    "    grid_p = Tasmanian.SparseGrid()\n",
    "    grid_p.makeGlobalGrid(dim, 0, depth, \"hyperbolic\", 'gauss-hermite')\n",
    "    points_p = grid_p.getPoints()\n",
    "    points_p = np.sqrt(2)*points_p\n",
    "    weights_p = grid_p.getQuadratureWeights()\n",
    "\n",
    "    if dim == 2:\n",
    "        y = func(points_p[:,0], points_p[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(points_p[:,0], points_p[:,1], points_p[:,2],points_p[:,3],points_p[:,4])\n",
    "\n",
    "    integ = (1/np.pi)*y@weights_p.T\n",
    "\n",
    "    return integ\n",
    "\n",
    "def mc_integrate_gauss(func, dim, n, seed = 1):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei  \n",
    "    # n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)  \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #Get random variable\n",
    "    x_list = np.random.multivariate_normal(np.zeros(dim), np.eye(dim), n)\n",
    "\n",
    "    if dim == 2:\n",
    "        y = func(x_list[:,0], x_list[:,1])\n",
    "    elif dim ==5:\n",
    "        y = func(x_list[:,0], x_list[:,1], x_list[:,2],x_list[:,3],x_list[:,4])\n",
    "\n",
    "    y_mean =  np.mean(y)\n",
    "\n",
    "    integ = y_mean\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    bootstrap_vars = bootstrap(y, ns=1000, alpha=0.05, seed=seed)\n",
    "\n",
    "    return integ, np.array(bootstrap_vars)\n",
    "\n",
    "def func1_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func1(x1,x2)*pdf\n",
    "\n",
    "def func2_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func2(x1,x2)*pdf\n",
    "\n",
    "def func3_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func3(x1,x2)*pdf\n",
    "\n",
    "def func4_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func4(x1,x2)*pdf\n",
    "\n",
    "def func5_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func5(x1,x2)*pdf\n",
    "\n",
    "def func6_pdf(x1, x2):\n",
    "    # for 2D: f(x)= 1 - x1^2 - x2^2\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func6(x1,x2)*pdf\n",
    "\n",
    "def func7_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func7(x1,x2,x3,x4,x5)*pdf\n",
    "\n",
    "def func8_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func8(x1,x2,x3,x4,x5)*pdf\n",
    "\n",
    "def func9_pdf(x1, x2, x3, x4, x5):\n",
    "    try:\n",
    "        vars = np.concatenate((x1,x2),axis =1)\n",
    "    except:\n",
    "        vars = np.array([x1,x2]).reshape(1,-1)\n",
    "    pdf = multivariate_normal.pdf(vars, mean=np.zeros(vars.shape[1]), cov=np.eye(vars.shape[1]))\n",
    "    return func9(x1,x2,x3,x4,x5)*pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\scipy\\integrate\\_quadpack_py.py:1233: IntegrationWarning: The integral is probably divergent, or slowly convergent.\n",
      "  quad_r = quad(f, low, high, args=args, full_output=self.full_output,\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"scipy\", \"mc n=100\", \"mc n=1000\", \"mc n=10000\", \"sg depth=5\", \"sg depth=10\", \"sg depth=20\"]\n",
    "results_df = pd.DataFrame(columns=column_names)\n",
    "func_list = [func1, func2, func3, func4, func5, func6, func7, func8, func9]\n",
    "func_list2 = [func1_pdf, func2_pdf, func3_pdf, func4_pdf, func5_pdf, func6_pdf, func7_pdf, func8_pdf, func9_pdf] # func7_pdf, func8_pdf, func9_pdf\n",
    "# func_list = [func1, func2, func3, func4, func5, func6, func7, func8, func9]\n",
    "\n",
    "l_bound = -1\n",
    "u_bound = 1\n",
    "seed = 1\n",
    "depth1 = 5\n",
    "depth2 = 10\n",
    "depth3 = 20\n",
    "n1 = 100\n",
    "n2 = 1000\n",
    "n3 = 10000\n",
    "\n",
    "for i in range(len(func_list)):\n",
    "    func = func_list[i]\n",
    "    func_pdf = func_list2[i]\n",
    "\n",
    "    if i > 5:\n",
    "        bounds = np.full((5, 2), [-np.inf, np.inf])\n",
    "        if i > 6:\n",
    "            z_scipy = \"n/a\"\n",
    "        else:\n",
    "            z_scipy = integrate.nquad(func_pdf, bounds)[0]\n",
    "        dim =5\n",
    "    else:\n",
    "        z_scipy = integrate.dblquad(func_pdf, -np.inf, np.inf, -np.inf, np.inf)[0]\n",
    "        dim =2\n",
    "\n",
    "    z_mc1, z_mc_ci1= mc_integrate_gauss(func, dim, n1, seed = seed)\n",
    "    z_mc2, z_mc_ci2= mc_integrate_gauss(func, dim, n2, seed = seed)\n",
    "    z_mc3, z_mc_ci3= mc_integrate_gauss(func, dim, n3, seed = seed)\n",
    "    z_sg1 = sg_integrate_gauss(func, dim, depth1, seed = seed)\n",
    "    z_sg2 = sg_integrate_gauss(func, dim, depth2, seed = seed)\n",
    "    z_sg3 = sg_integrate_gauss(func, dim, depth3, seed = seed)\n",
    "\n",
    "    iter_df = pd.DataFrame(columns=column_names)\n",
    "    integ_results = [z_scipy, z_mc1, z_mc2, z_mc3, z_sg1, z_sg2, z_sg3]\n",
    "    # Add the new row to the DataFrame\n",
    "    iter_df.loc[0] = integ_results\n",
    "    results_df = pd.concat([results_df.astype(iter_df.dtypes), iter_df], ignore_index=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"/Users/mcarlozo/Documents/Graduate_Research/Toy_Problem/mc_test_gauss_all2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff728ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_name_val = 1\n",
    "meth_name_enum = 5\n",
    "CS_name  = CS_name_enum(cs_name_val)\n",
    "param_name_str = \"t1t2\" #set_param_str(cs_name_val)\n",
    "indecies_to_consider = set_idcs_to_consider(cs_name_val, param_name_str)\n",
    "meth_name = Method_name_enum(meth_name_enum)\n",
    "method = GPBO_Methods(meth_name)\n",
    "\n",
    "ep0 = 1\n",
    "ep_enum = Ep_enum(1)\n",
    "sep_fact = 1.0\n",
    "normalize = False\n",
    "noise_mean = 0\n",
    "noise_std = 0.01\n",
    "# noise_std = 0.0\n",
    "kernel = Kernel_enum(1)\n",
    "lenscl = None\n",
    "outputscl = 1 #outpulscl tuning is critical for log scaled obj fxns not to terminate early w/ regret (stdv affected)\n",
    "retrain_GP = 1\n",
    "reoptimize_obj = 1\n",
    "bo_iter_tot = 1\n",
    "bo_run_tot = 1\n",
    "save_data = False\n",
    "seed = 5\n",
    "ei_tol = 1e-6\n",
    "obj_tol = 1e-6\n",
    "DateTime = None\n",
    "\n",
    "num_x_data = 5\n",
    "gen_meth_x = Gen_meth_enum(2) #Note: Has to be the same for validation and sim data\n",
    "num_theta_data = 10*len(indecies_to_consider)\n",
    "num_theta_data_val = 200\n",
    "gen_meth_theta = Gen_meth_enum(1)\n",
    "gen_meth_theta_val = Gen_meth_enum(1)\n",
    "gen_heat_map_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f20c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get training data\n",
    "simulator = simulator_helper_test_fxns(CS_name, indecies_to_consider, noise_mean, noise_std, seed)\n",
    "\n",
    "#Calculate minimum Muller potential\n",
    "min_Mul = solve_pyomo_Muller_min(param_name_str, verbose = False)\n",
    "\n",
    "#Generate Exp Data\n",
    "exp_data = simulator.gen_exp_data(num_x_data, gen_meth_x)\n",
    "\n",
    "#Generate Sim Data\n",
    "sim_data = simulator.gen_sim_data(num_theta_data, num_x_data, gen_meth_theta, gen_meth_x, sep_fact, False)\n",
    "\n",
    "#Generate sse_sim_data from new sim and exp_data\n",
    "sim_sse_data = simulator.sim_data_to_sse_sim_data(method, sim_data, exp_data, sep_fact, False)\n",
    "\n",
    "#Generate validation data\n",
    "val_data = simulator.gen_sim_data(num_theta_data_val, num_x_data, gen_meth_theta_val, gen_meth_x, sep_fact, True)\n",
    "val_sse_data = simulator.sim_data_to_sse_sim_data(method, val_data, exp_data, sep_fact, True)\n",
    "\n",
    "#Set Cs_params and Simulator\n",
    "cs_name = CS_name.name + \"_BO_method_\" + meth_name.name + \"_sep_fact_\" + str(round(sep_fact,2))\n",
    "cs_params = CaseStudyParameters(cs_name, ep0, sep_fact, normalize, kernel, lenscl, outputscl, retrain_GP, \n",
    "                                reoptimize_obj, gen_heat_map_data, bo_iter_tot, bo_run_tot, save_data, DateTime, \n",
    "                                seed, ei_tol, obj_tol)\n",
    "\n",
    "#Initialize Driver\n",
    "ep_bias = Exploration_Bias(ep0, None, ep_enum, None, None, None, None, None, None, None)\n",
    "driver = GPBO_Driver(cs_params, method, simulator, exp_data, sim_data, sim_sse_data, val_data, val_sse_data, None, \n",
    "                     ep_bias, gen_meth_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82b2ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make emulator\n",
    "if driver.method.emulator == False:\n",
    "    all_gp_data = driver.sim_sse_data\n",
    "    all_val_data = driver.val_sse_data\n",
    "    gp_emulator = Type_1_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                     driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                     driver.cs_params.retrain_GP, driver.cs_params.seed, None, None, None, None)\n",
    "else:\n",
    "    all_gp_data = driver.sim_data\n",
    "    all_val_data = driver.val_data\n",
    "    gp_emulator = Type_2_GP_Emulator(all_gp_data, all_val_data, None, None, None, driver.cs_params.kernel, \n",
    "                                     driver.cs_params.lenscl, driver.simulator.noise_std, driver.cs_params.outputscl, \n",
    "                                     driver.cs_params.retrain_GP, driver.cs_params.seed, None, None, None, None)\n",
    "    \n",
    "driver.gp_emulator = gp_emulator\n",
    "#Set train_test data\n",
    "train_data, test_data = driver.gp_emulator.set_train_test_data(driver.cs_params.sep_fact, driver.cs_params.seed)\n",
    "        \n",
    "#Initilize gp model\n",
    "gp_model = driver.gp_emulator.set_gp_model()\n",
    "driver.gp_emulator.train_gp(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb93375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ei_func(random_var, best_error, y_target, gp_mean, gp_var):\n",
    "    #Create a mask for values where pred_stdev >= 0 (Here approximation includes domain stdev >= 0) \n",
    "    pos_stdev_mask = (gp_var >= 0)\n",
    "\n",
    "    #Assuming all standard deviations are not zero\n",
    "    if np.any(pos_stdev_mask):\n",
    "        #Get indices and values where stdev > 0\n",
    "        valid_indices = np.where(pos_stdev_mask)[0]\n",
    "        gp_stdev_val = np.sqrt(gp_var[valid_indices])\n",
    "        gp_mean_val = gp_mean[valid_indices]\n",
    "        y_target_val = y_target[valid_indices]\n",
    "        mean_min_y = y_target_val - gp_mean_val\n",
    "    \n",
    "        # Calculate gp_var multiplied by points_p\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "        gp_stdev_rand_var = gp_stdev_val * random_var\n",
    "\n",
    "        # Calculate the SSE for all data points simultaneously\n",
    "        sse_temp = np.sum((mean_min_y[:, np.newaxis].T - gp_stdev_rand_var)**2, axis=1)\n",
    "\n",
    "        # Apply max operator (equivalent to max[(best_error*ep) - SSE_Temp,0])\n",
    "        improvement = np.maximum(best_error - sse_temp, 0).reshape(-1,1)\n",
    "\n",
    "        # Calculate EI_temp using vectorized operations\n",
    "        ei_temp = improvement.flatten()\n",
    "        \n",
    "        # Calculate the multivariate normal pdf for each row in 'epsilon'\n",
    "        # mvn = multivariate_normal.pdf(random_var, mean=np.zeros(random_var.shape[1]), cov=np.eye(random_var.shape[1]))\n",
    "\n",
    "        # ei_temp = ei_temp*mvn\n",
    "\n",
    "    else:\n",
    "        ei_temp = 0\n",
    "        \n",
    "    return ei_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db00c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Courtesy of Ryan Smith\n",
    "def bootstrap(pilot_sample, ns=100, alpha=0.05, seed = 1):\n",
    "    # pilot_sample has one column per rv, one row per observation\n",
    "    # alpha is the level of significance; 0.05 for 95% confidence interval\n",
    "    quantiles = np.array([alpha*0.5, 1.0-alpha*0.5])\n",
    "\n",
    "    #Set seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    #Determine mean of all original samples and its shape\n",
    "    theta_orig = np.mean(pilot_sample,axis=0)\n",
    "\n",
    "    #Initialize bootstrap samples as zeros\n",
    "    theta_bs = np.zeros(tuple([ns]+list(theta_orig.shape)))\n",
    "\n",
    "    #Create bootstrap samples\n",
    "    for ibs in range(ns):\n",
    "        samples = np.random.choice(pilot_sample, size= pilot_sample.shape[0], replace=True)\n",
    "        theta_bs[ibs,...] = np.mean(samples, axis = 0)\n",
    "\n",
    "    # percentile CI\n",
    "    CI_percentile = np.quantile(theta_bs, quantiles, 0)\n",
    "\n",
    "    # return theta_orig, theta_bs, CI_percentile\n",
    "    return CI_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98139058",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\sparse_vs_mc.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m b \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# a = -3.668470846559581\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# b = 3.668470846559581\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# n = 115813\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m#Fill in f_args with data from a run\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m ei_mc, ci \u001b[39m=\u001b[39m mc_integrate(ei_func, driver, a, b, \u001b[39mlen\u001b[39m(driver\u001b[39m.\u001b[39mexp_data\u001b[39m.\u001b[39my_vals))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(ei_mc[ei_mc \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(ci[(ci \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mall(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)])\n",
      "\u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\sparse_vs_mc.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#Evaluate GP for validation data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m y_sim \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mexp_data\u001b[39m.\u001b[39my_vals\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m gp_mean_all, gp_var_all \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mgp_emulator\u001b[39m.\u001b[39meval_gp_mean_var_val()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m gp_mean \u001b[39m=\u001b[39m gp_mean_all[i\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(y_sim):i\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(y_sim)\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(y_sim)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mcarlozo/Documents/Repos/Toy_Problem/sparse_vs_mc.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m gp_var \u001b[39m=\u001b[39m gp_var_all[i\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(y_sim):i\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(y_sim)\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(y_sim)]\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\bo_methods_lib\\bo_methods_lib\\GPBO_Classes_New.py:1387\u001b[0m, in \u001b[0;36mGP_Emulator.eval_gp_mean_var_val\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_val_data) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMust have validation data. Run set_train_test_data() to generate\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1386\u001b[0m \u001b[39m#Evaluate test data for GP\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m val_gp_mean, val_gp_var, val_gp_covar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__eval_gp_mean_var(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_val_data)\n\u001b[0;32m   1389\u001b[0m \u001b[39m#Set data parameters\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgp_val_data\u001b[39m.\u001b[39mgp_mean \u001b[39m=\u001b[39m val_gp_mean\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\Documents\\Repos\\Toy_Problem\\bo_methods_lib\\bo_methods_lib\\GPBO_Classes_New.py:1312\u001b[0m, in \u001b[0;36mGP_Emulator.__eval_gp_mean_var\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1310\u001b[0m eval_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalerX\u001b[39m.\u001b[39mtransform(data)\n\u001b[0;32m   1311\u001b[0m \u001b[39m#Evaluate GP given parameter set theta and state point value\u001b[39;00m\n\u001b[1;32m-> 1312\u001b[0m gp_mean_scl, gp_covar_scl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_gp_model\u001b[39m.\u001b[39mpredict(eval_points, return_cov\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \n\u001b[0;32m   1314\u001b[0m \u001b[39m#Unscale gp_mean and gp_covariance\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m gp_mean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalerY\u001b[39m.\u001b[39minverse_transform(gp_mean_scl\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:459\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.predict\u001b[1;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[0;32m    456\u001b[0m y_cov \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_(X) \u001b[39m-\u001b[39m V\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m V\n\u001b[0;32m    458\u001b[0m \u001b[39m# undo normalisation\u001b[39;00m\n\u001b[1;32m--> 459\u001b[0m y_cov \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mouter(y_cov, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_train_std\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mreshape(\n\u001b[0;32m    460\u001b[0m     \u001b[39m*\u001b[39my_cov\u001b[39m.\u001b[39mshape, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    461\u001b[0m )\n\u001b[0;32m    462\u001b[0m \u001b[39m# if y_cov has shape (n_samples, n_samples, 1), reshape to\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m# (n_samples, n_samples)\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m y_cov\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mcarlozo\\AppData\\Local\\anaconda3\\envs\\Toy_Problem_env\\Lib\\site-packages\\numpy\\core\\numeric.py:837\u001b[0m, in \u001b[0;36m_outer_dispatcher\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mv cannot be empty\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    834\u001b[0m     \u001b[39mreturn\u001b[39;00m multiarray\u001b[39m.\u001b[39mcorrelate(a, v[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], mode)\n\u001b[1;32m--> 837\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_outer_dispatcher\u001b[39m(a, b, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    838\u001b[0m     \u001b[39mreturn\u001b[39;00m (a, b, out)\n\u001b[0;32m    841\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_outer_dispatcher)\n\u001b[0;32m    842\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mouter\u001b[39m(a, b, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Test MC integration\n",
    "def mc_integrate(func, driver, dim):\n",
    "    # Monte Carlo integration of given function over domain from a to b (for each parameter)\n",
    "    # dim: dimensions of function\n",
    "    #Initialize total ei\n",
    "    n = math.ceil((norm.ppf(1-0.05/2)/0.05)**2)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    integ_theta = np.zeros(len(driver.gp_emulator.gp_val_data.get_unique_theta()))\n",
    "    bs_vars = []\n",
    "    for i in range(len(driver.gp_emulator.gp_val_data.get_unique_theta())):\n",
    "        #Calcuate best error\n",
    "        if driver.method.emulator == False:\n",
    "            #Type 1 best error is inferred from training data \n",
    "            best_error, be_theta = driver.gp_emulator.calc_best_error()\n",
    "            best_errors_x = None\n",
    "        else:\n",
    "            #Type 2 best error must be calculated given the experimental data\n",
    "            best_error, be_theta, best_errors_x = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "        #Evaluate GP for validation data\n",
    "        y_sim = driver.exp_data.y_vals\n",
    "        gp_mean_all, gp_var_all = driver.gp_emulator.eval_gp_mean_var_val()\n",
    "        gp_mean = gp_mean_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "        gp_var = gp_var_all[i*len(y_sim):i*len(y_sim)+len(y_sim)]\n",
    "        #Get random variable\n",
    "        random_var = np.random.multivariate_normal(np.zeros(dim), np.eye(dim), n)\n",
    "        #Calc EI\n",
    "        ei = func(random_var, best_error, y_sim, gp_mean, gp_var)\n",
    "        ei_mean = np.average(ei) #y.sum()/len(y)\n",
    "        domain = 1\n",
    "        \n",
    "        #Calc monte carlo integrand for each theta and add it to the total\n",
    "        integ = domain * ei_mean\n",
    "        integ_theta[i] = integ\n",
    "\n",
    "        # Perform bootstrapping\n",
    "        bootstrap_vars = bootstrap(ei, ns=100, alpha=0.05, seed=seed)\n",
    "        bs_vars.append(bootstrap_vars)\n",
    "\n",
    "    return integ_theta, np.array(bs_vars)\n",
    "\n",
    "\n",
    "# n = 115813\n",
    "#Fill in f_args with data from a run\n",
    "ei_mc, ci = mc_integrate(ei_func, driver, len(driver.exp_data.y_vals))\n",
    "print(ei_mc[ei_mc > 0])\n",
    "print(ci[(ci > 0).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caba991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Sparse Grid Integration\n",
    "#Calcuate best error\n",
    "if driver.method.emulator == False:\n",
    "    #Type 1 best error is inferred from training data \n",
    "    best_error_metrics = driver.gp_emulator.calc_best_error()\n",
    "    best_errors_x = None\n",
    "else:\n",
    "    #Type 2 best error must be calculated given the experimental data\n",
    "    best_error_metrics = driver.gp_emulator.calc_best_error(driver.method, driver.exp_data)\n",
    "#Set be in ep bias class\n",
    "driver.ep_bias.best_error = best_error_metrics[0]\n",
    "driver.ep_bias.set_ep()\n",
    "#Calculate EI for validation data\n",
    "if driver.method.emulator == False:\n",
    "    ei_output = driver.gp_emulator.eval_ei_val(driver.exp_data, driver.ep_bias, best_error_metrics)\n",
    "else:\n",
    "    ei_output = driver.gp_emulator.eval_ei_val(driver.exp_data, driver.ep_bias, best_error_metrics, driver.method)\n",
    "\n",
    "ei_sparse = ei_output[0]\n",
    "print(ei_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map_dict = driver.create_heat_map_param_data(n_points_set = 20)\n",
    "heat_map = heat_map_dict[list(heat_map_dict.keys())[0]]\n",
    "\n",
    "#Init EI array list\n",
    "#Loop over n (100, 1000, and 10000)\n",
    "    #Init EI array\n",
    "    #Loop over each theta in heat map data\n",
    "        #Get EI From mc and save to ei array \n",
    "    #Save EI array to EI array list\n",
    "#Loop over depth for sparse grid (5, 10, 20)\n",
    "    #Init EI array\n",
    "    #Loop over each theta in heat map data\n",
    "        #Get EI from Sparse Grid (Depth = 5, 10, 20)\n",
    "    #Save EI array to EI array list\n",
    "#Return ei of each theta for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
