{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "from bo_functions import eval_GP_components\n",
    "from bo_functions import calc_ei_total_test\n",
    "from bo_functions import create_y_data\n",
    "\n",
    "from bo_plotters import plot_hyperparams\n",
    "from bo_plotters import sse_plotter\n",
    "from bo_plotters import stdev_plotter\n",
    "from bo_plotters import ei_plotter_adv_test\n",
    "from bo_plotters import ei_plotter\n",
    "from bo_plotters import plot_xy\n",
    "from bo_plotters import error_plotter_4D\n",
    "from bo_plotters import y_plotter_4D\n",
    "from bo_plotters import stdev_plotter_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2934c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull x and Y data from CSV\n",
    "#Pull x data from CSV\n",
    "exp_data_doc = \"exp_data.csv\"\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "\n",
    "n = len(Xexp)\n",
    "q = 3\n",
    "# print(n)\n",
    "Theta_True = np.array([1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test data\n",
    "train_data_doc = \"train_3_in_data.csv\"\n",
    "train_data = np.array(pd.read_csv(train_data_doc, header=0,sep=\",\"))\n",
    "# print(train_data)\n",
    "train_theta = train_data[:,1:3]\n",
    "train_p = torch.tensor(train_data[:,1:4])\n",
    "train_y = torch.tensor(train_data[:,4])\n",
    "# print(train_p)\n",
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71daa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Meshgrid\n",
    "p = 10\n",
    "Theta1 = np.linspace(-2,2,p)\n",
    "Theta2 = np.linspace(-2,2,p)\n",
    "\n",
    "theta_mesh = np.array(np.meshgrid(Theta1,Theta2))\n",
    "theta1_mesh = theta_mesh[0]\n",
    "theta2_mesh = theta_mesh[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Point EI: 0.000578173284595751\n",
      "The GP estimates the highest EI is at Theta =  [ 2. -2.]  at iteration  1 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-8.70652646] and the GP variance is [0.54981077]\n",
      "At Xexp =  -1.0 the GP mean is  [-5.49836897] and the GP variance is [0.49664058]\n",
      "At Xexp =  0.0 the GP mean is  [-1.85863819] and the GP variance is [0.51923688]\n",
      "At Xexp =  1.0 the GP mean is  [0.92234868] and the GP variance is [0.19520237]\n",
      "At Xexp =  2.0 the GP mean is  [3.26915367] and the GP variance is [0.46910825]\n",
      "Training Point EI: 6.281735848885639e-07\n",
      "The GP estimates the highest EI is at Theta =  [ 0.66666667 -1.55555556]  at iteration  2 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-13.88883797] and the GP variance is [0.5157408]\n",
      "At Xexp =  -1.0 the GP mean is  [-5.46337523] and the GP variance is [0.60211349]\n",
      "At Xexp =  0.0 the GP mean is  [-0.52095046] and the GP variance is [0.64000883]\n",
      "At Xexp =  1.0 the GP mean is  [0.97111074] and the GP variance is [0.58632597]\n",
      "At Xexp =  2.0 the GP mean is  [2.87785871] and the GP variance is [0.63754017]\n",
      "Training Point EI: 1.846660480979423e-05\n",
      "The GP estimates the highest EI is at Theta =  [-2. -2.]  at iteration  3 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-12.91501018] and the GP variance is [0.21223162]\n",
      "At Xexp =  -1.0 the GP mean is  [-3.40118489] and the GP variance is [0.33768356]\n",
      "At Xexp =  0.0 the GP mean is  [-0.12076597] and the GP variance is [0.38140535]\n",
      "At Xexp =  1.0 the GP mean is  [0.70686304] and the GP variance is [0.27001935]\n",
      "At Xexp =  2.0 the GP mean is  [3.77779082] and the GP variance is [0.36521078]\n",
      "Training Point EI: 0.0017371000069285603\n",
      "The GP estimates the highest EI is at Theta =  [1.11111111 0.22222222]  at iteration  4 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-12.97869635] and the GP variance is [0.21222279]\n",
      "At Xexp =  -1.0 the GP mean is  [-3.45494512] and the GP variance is [0.33743812]\n",
      "At Xexp =  0.0 the GP mean is  [-0.20464063] and the GP variance is [0.38088779]\n",
      "At Xexp =  1.0 the GP mean is  [0.70008753] and the GP variance is [0.26985306]\n",
      "At Xexp =  2.0 the GP mean is  [3.71216626] and the GP variance is [0.36510114]\n",
      "Training Point EI: 0.015060787507909734\n",
      "The GP estimates the highest EI is at Theta =  [2. 2.]  at iteration  5 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-13.72502766] and the GP variance is [0.19695364]\n",
      "At Xexp =  -1.0 the GP mean is  [-3.12143358] and the GP variance is [0.29549197]\n",
      "At Xexp =  0.0 the GP mean is  [0.13396488] and the GP variance is [0.34350693]\n",
      "At Xexp =  1.0 the GP mean is  [0.75400666] and the GP variance is [0.26588345]\n",
      "At Xexp =  2.0 the GP mean is  [5.13866267] and the GP variance is [0.33825254]\n",
      "Training Point EI: 0.0007053843234204327\n",
      "The GP estimates the highest EI is at Theta =  [2.         0.22222222]  at iteration  6 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-13.67118418] and the GP variance is [0.19685589]\n",
      "At Xexp =  -1.0 the GP mean is  [-3.1410402] and the GP variance is [0.29539002]\n",
      "At Xexp =  0.0 the GP mean is  [0.30110648] and the GP variance is [0.34340859]\n",
      "At Xexp =  1.0 the GP mean is  [0.74312003] and the GP variance is [0.26587963]\n",
      "At Xexp =  2.0 the GP mean is  [4.80863614] and the GP variance is [0.33794994]\n",
      "Training Point EI: 0.0006374556393718978\n",
      "The GP estimates the highest EI is at Theta =  [-1.55555556  0.22222222]  at iteration  7 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-13.72224925] and the GP variance is [0.19671103]\n",
      "At Xexp =  -1.0 the GP mean is  [-3.0196453] and the GP variance is [0.29424537]\n",
      "At Xexp =  0.0 the GP mean is  [0.46504069] and the GP variance is [0.34079251]\n",
      "At Xexp =  1.0 the GP mean is  [1.04618331] and the GP variance is [0.25914444]\n",
      "At Xexp =  2.0 the GP mean is  [5.36229409] and the GP variance is [0.33146494]\n",
      "Training Point EI: 0.0006426861332429201\n",
      "The GP estimates the highest EI is at Theta =  [2.         1.11111111]  at iteration  8 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-13.73092449] and the GP variance is [0.19670345]\n",
      "At Xexp =  -1.0 the GP mean is  [-3.03744653] and the GP variance is [0.29419235]\n",
      "At Xexp =  0.0 the GP mean is  [0.49201694] and the GP variance is [0.34062709]\n",
      "At Xexp =  1.0 the GP mean is  [1.08990087] and the GP variance is [0.25821126]\n",
      "At Xexp =  2.0 the GP mean is  [5.35800739] and the GP variance is [0.33087087]\n",
      "Training Point EI: 0.00022267796128441764\n",
      "The GP estimates the highest EI is at Theta =  [-2.  2.]  at iteration  9 \n",
      "\n",
      "At Xexp =  -2.0 the GP mean is  [-13.69959753] and the GP variance is [0.19495371]\n",
      "At Xexp =  -1.0 the GP mean is  [-3.09767724] and the GP variance is [0.28895372]\n",
      "At Xexp =  0.0 the GP mean is  [0.41788901] and the GP variance is [0.33394039]\n",
      "At Xexp =  1.0 the GP mean is  [1.04248585] and the GP variance is [0.25739825]\n",
      "At Xexp =  2.0 the GP mean is  [5.26218712] and the GP variance is [0.32627198]\n"
     ]
    }
   ],
   "source": [
    "#Set number of training iterations and train GP\n",
    "iterations = 500\n",
    "BO_iters = 10\n",
    "for i in range(BO_iters):\n",
    "    if torch.is_tensor(train_p) != True:\n",
    "        train_p = torch.from_numpy(train_p)\n",
    "    if torch.is_tensor(train_y) != True:\n",
    "        train_y = torch.from_numpy(train_y)\n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    # We will use the simplest form of GP model, exact inference\n",
    "    #Defines our model in terms of the class parameters in bo_functions\n",
    "    model = ExactGPModel(train_p, train_y, likelihood)\n",
    "    \n",
    "    train_GP = train_GP_model(model,likelihood, train_p, train_y, iterations, verbose=False)\n",
    "    noise_list = train_GP[0]\n",
    "    lengthscale_list = train_GP[1]\n",
    "    outputscale_list = train_GP[2]\n",
    "    \n",
    "#     #Plot hyperparameters vs iteration\n",
    "#     noise_title = \"Noise Hyperparameter\"\n",
    "#     lengthscale_title = \"Lengthscale Hyperparameter\"\n",
    "#     outputscale_title = \"Outputscale Hyperparameter\"\n",
    "#     plot_hyperparams(iterations, noise_list,noise_title)\n",
    "#     plot_hyperparams(iterations, lengthscale_list,lengthscale_title)\n",
    "#     plot_hyperparams(iterations, outputscale_list,outputscale_title)\n",
    "    \n",
    "    outputscale = torch.tensor([1])\n",
    "    lengthscale = torch.tensor([1])\n",
    "    noise = torch.tensor([0.1])\n",
    "\n",
    "    model.likelihood.noise = noise\n",
    "    model.covar_module.base_kernel.lengthscale =lengthscale\n",
    "    model.covar_module.outputscale = outputscale\n",
    "    \n",
    "#     print(\"Noise Hyperparameter: \", float(model.likelihood.noise))\n",
    "#     print(\"Lengthscale Hyperparameter: \", float(model.covar_module.base_kernel.lengthscale))\n",
    "#     print(\"Outputscale Hyperparameter: \", float(model.covar_module.outputscale))\n",
    "    \n",
    "    # Get into evaluation (predictive posterior) mode\n",
    "    model.eval()\n",
    "    likelihood.eval();\n",
    "    \n",
    "    #Will compare the rigorous solution and approximation later (multidimensional integral over each experiment using a sparse grid)\n",
    "    #Calculate EI\n",
    "    EI_Components = eval_GP_components(p,n,Xexp,Yexp, theta_mesh, model, likelihood)\n",
    "    EI = EI_Components[0]\n",
    "    SSE =EI_Components[1]\n",
    "    y_GP = EI_Components[2]\n",
    "    stdev_GP = EI_Components[3]\n",
    "    error_GP = EI_Components[4]\n",
    "    SSE_var_GP = EI_Components[5]\n",
    "    ei_TP = EI_Components[6]\n",
    "    print(\"Training Point EI:\",ei_TP)\n",
    "#     print(Error)\n",
    "\n",
    "    #Finds the index where sse is the smallest and finds which Theta combination corresponds to that value\n",
    "    argmin = np.array(np.where(np.isclose(SSE, np.amin(SSE),atol=1e-10)==True))\n",
    "    Theta_1_Opt = float(theta1_mesh[argmin[0],argmin[1]])\n",
    "    Theta_2_Opt = float(theta2_mesh[argmin[0],argmin[1]])\n",
    "    Theta_Opt_GP = np.array((Theta_1_Opt,Theta_2_Opt))\n",
    "\n",
    "\n",
    "    #calculates best theta value\n",
    "    argmax = np.array(np.where(np.isclose(EI, np.amax(EI),atol=1e-10)==True))\n",
    "    #     print(argmax)\n",
    "    Theta1_Best = float(theta1_mesh[argmax[0],argmax[1]])\n",
    "    Theta2_Best = float(theta2_mesh[argmax[0],argmax[1]])\n",
    "    Theta_Best = np.array((Theta1_Best,Theta2_Best))\n",
    "    \n",
    "    \n",
    "#     If statement to show convergence\n",
    "#     Converge = np.allclose(Theta_Best, train_p[-1,0:2],atol=1e-10)\n",
    "#     if Converge == True or i ==BO_iters-1:\n",
    "#         sse_plotter(theta_mesh, SSE, Theta_True, Theta_Opt_GP, Theta_Best,train_p,plot_train=True)\n",
    "#         stdev_plotter(theta_mesh, SSE_var_GP, Theta_True, Theta_Opt_GP, Theta_Best, train_p,plot_train=True)\n",
    "#         ei_plotter(theta_mesh, EI, Theta_True, Theta_Opt_GP,Theta_Best,train_p,plot_train=True)\n",
    "#         print(\"Final number of iterations: \", i+1)\n",
    "#         print(\"The SSE at the GP mean is lowest at Theta =\",Theta_Opt_GP)\n",
    "#         print(\"The GP estimates the highest EI is at Theta = \",Theta_Best)\n",
    "        \n",
    "#         for j in range(n):\n",
    "#             x = Xexp[j]\n",
    "#             GP_mean = y_GP[argmin[0],argmin[1],j]\n",
    "#             GP_var = (stdev_GP[argmin[0],argmin[1],j])**2\n",
    "#             print(\"At Xexp = \",x,\"the GP mean is \", GP_mean, \"and the GP variance is\", GP_var)\n",
    "#         break\n",
    "    \n",
    "        \n",
    "#     sse_plotter(theta_mesh, SSE, Theta_True, Theta_Opt_GP, Theta_Best,train_p,plot_train=True)\n",
    "#     stdev_plotter(theta_mesh, SSE_var_GP, Theta_True, Theta_Opt_GP, Theta_Best, train_p,plot_train=True)\n",
    "#     ei_plotter(theta_mesh, EI, Theta_True, Theta_Opt_GP, Theta_Best,train_p,plot_train=True)\n",
    "#     print(\"The SSE at the GP mean is lowest at Theta =\",Theta_Opt_GP, \" at iteration \", i+1)\n",
    "    print(\"The GP estimates the highest EI is at Theta = \",Theta_Best, \" at iteration \", i+1, \"\\n\")\n",
    "    for j in range(n):\n",
    "        x = Xexp[j]\n",
    "        GP_mean = y_GP[argmin[0],argmin[1],j]\n",
    "        GP_var = (stdev_GP[argmin[0],argmin[1],j])**2\n",
    "        print(\"At Xexp = \",x,\"the GP mean is \", GP_mean, \"and the GP variance is\", GP_var)\n",
    "\n",
    "    ##Append best values to training data \n",
    "    #Convert training data to numpy arrays to allow concatenation to work\n",
    "    train_p = train_p.numpy() #(q x t)\n",
    "    train_y = train_y.numpy() #(1 x t)\n",
    "    \n",
    "    #Loops over Xexp values\n",
    "    for j in range(n):\n",
    "#         print(train_y)\n",
    "        ##Calculate y_Best and formal p_Best\n",
    "        #Add 5 test points, same Theta1 and Theta2, but use all values of Xexp\n",
    "        p_Best = np.array([Theta_Best[0],Theta_Best[1],Xexp[j]]) #(q x 1)\n",
    "#         print(p_Best)\n",
    "        y_Best = create_y_data(q,p_Best) #(1 x 1)\n",
    "        \n",
    "        #Add Theta_Best to train_p and y_best to train_y\n",
    "        train_p = np.concatenate((train_p, [p_Best]), axis=0) #(q x t)\n",
    "        train_y = np.concatenate((train_y, [y_Best]),axis=0) #(1 x t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cebf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EI_sing = calc_ei_total_test(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[0]\n",
    "# Error =calc_ei_total_test(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[1]\n",
    "# for i in range(n):    \n",
    "#     ei_plotter_adv_test(theta_mesh, EI_sing[i], Theta_True, train_p,Xexp[i],Theta_Opt_GP,plot_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9397ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot xy data\n",
    "title = \"XY Comparison\"\n",
    "y_GP_Opt = y_GP[argmin[0],argmin[1],:][0]\n",
    "plot_xy(Xexp, Yexp, y_GP_Opt,Theta_True,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f659c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_3D = np.meshgrid(Theta1,Theta2,Xexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fd27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "853fa683",
   "metadata": {},
   "source": [
    "stdev_plot = stdev_plotter_4D(mesh_3D,stdev_GP)\n",
    "print(\"Max Stdev: \", np.amax(stdev_GP))\n",
    "print(\"Min Stdev: \", np.amin(stdev_GP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16656",
   "metadata": {},
   "source": [
    "## Analysis of Standard Deviation\n",
    " - The GP estimates that the standard deviation is lowest at points that were directly tested\n",
    "  - This can be rationalized by the way that the contour plot is drawn\n",
    " - Standard deviation is smallest away from the edges and larger towards them\n",
    "  - This is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The more points that get tested, the more the standard deviations will decrease"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7420597",
   "metadata": {},
   "source": [
    "error_plot = error_plotter_4D(mesh_3D,error_sq_GP)\n",
    "print(\"Max Error: \", np.amax(error_sq_GP))\n",
    "print(\"Min Error: \", np.amin(error_sq_GP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4a585",
   "metadata": {},
   "source": [
    "## Analysis of Error Squared Magnitude\n",
    " - The GP emulator is most inaccurate when all values of $\\bar{p}$ are at their extreme points \n",
    "  - In general, the GP is less accurate at extreme points, this is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The GP emulator is most accurate after convergence\n",
    " - GP error is mostly very low, as more iterations are added, error decreases"
   ]
  },
  {
   "cell_type": "raw",
   "id": "562e6d2a",
   "metadata": {},
   "source": [
    "y_plot = y_plotter_4D(mesh_3D,y_GP)\n",
    "print(\"Max y: \", np.amax(y_GP))\n",
    "print(\"Min y: \", np.amin(y_GP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d487",
   "metadata": {},
   "source": [
    "## Analysis of GP Emulator (Model y)\n",
    " - The GP emulator correctly captures that y increases as $\\bar{p}$ increases. This tells us that this GP emulator model could be viable\n",
    "  - The GP emulator suitably estimates where the lowest y is achieved and the actual value of y\n",
    "  - Slight error leads to small inaccuracies in the value of $\\bar{\\theta}$ and the values of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1eb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
