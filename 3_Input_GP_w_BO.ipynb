{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bo_functions import ExactGPModel\n",
    "from bo_functions import train_GP_model\n",
    "from bo_functions import eval_GP_components\n",
    "from bo_functions import calc_ei_total_test\n",
    "from bo_functions import create_y_data\n",
    "\n",
    "from bo_plotters import plot_hyperparams\n",
    "from bo_plotters import error_plotter\n",
    "from bo_plotters import ei_plotter_adv_test\n",
    "from bo_plotters import ei_plotter\n",
    "from bo_plotters import plot_xy\n",
    "from bo_plotters import error_plotter_4D\n",
    "from bo_plotters import y_plotter_4D\n",
    "from bo_plotters import stdev_plotter_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull x and Y data from CSV\n",
    "#Pull x data from CSV\n",
    "exp_data_doc = \"exp_data.csv\"\n",
    "exp_data = np.array(pd.read_csv(exp_data_doc, header=0,sep=\",\"))\n",
    "Xexp = exp_data[:,1]\n",
    "Yexp = exp_data[:,2]\n",
    "\n",
    "n = len(Xexp)\n",
    "q = 3\n",
    "# print(n)\n",
    "Theta_True = np.array([1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test data\n",
    "train_data_doc = \"train_3_in_data.csv\"\n",
    "train_data = np.array(pd.read_csv(train_data_doc, header=0,sep=\",\"))\n",
    "# print(train_data)\n",
    "train_theta = train_data[:,1:3]\n",
    "train_p = torch.tensor(train_data[:,1:4])\n",
    "train_y = torch.tensor(train_data[:,4])\n",
    "# print(train_p)\n",
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71daa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Meshgrid\n",
    "p = 25\n",
    "Theta1 = np.linspace(-2,2,p)\n",
    "Theta2 = np.linspace(-2,2,p)\n",
    "\n",
    "theta_mesh = np.array(np.meshgrid(Theta1,Theta2))\n",
    "theta1_mesh = theta_mesh[0]\n",
    "theta2_mesh = theta_mesh[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of training iterations and train GP\n",
    "iterations = 500\n",
    "BO_iters = 30\n",
    "for i in range(BO_iters):\n",
    "    if torch.is_tensor(train_p) != True:\n",
    "        train_p = torch.from_numpy(train_p)\n",
    "    if torch.is_tensor(train_y) != True:\n",
    "        train_y = torch.from_numpy(train_y)\n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    # We will use the simplest form of GP model, exact inference\n",
    "    #Defines our model in terms of the class parameters in bo_functions\n",
    "    model = ExactGPModel(train_p, train_y, likelihood)\n",
    "    \n",
    "    train_GP = train_GP_model(model,likelihood, train_p, train_y, iterations, verbose=False)\n",
    "    noise_list = train_GP[0]\n",
    "    lengthscale_list = train_GP[1]\n",
    "    outputscale_list = train_GP[2]\n",
    "    \n",
    "#     #Plot hyperparameters vs iteration\n",
    "#     noise_title = \"Noise Hyperparameter\"\n",
    "#     lengthscale_title = \"Lengthscale Hyperparameter\"\n",
    "#     outputscale_title = \"Outputscale Hyperparameter\"\n",
    "#     plot_hyperparams(iterations, noise_list,noise_title)\n",
    "#     plot_hyperparams(iterations, lengthscale_list,lengthscale_title)\n",
    "#     plot_hyperparams(iterations, outputscale_list,outputscale_title)\n",
    "    \n",
    "    outputscale = torch.tensor([1])\n",
    "    lengthscale = torch.tensor([1])\n",
    "    noise = torch.tensor([1])\n",
    "\n",
    "    model.likelihood.noise = noise\n",
    "    model.covar_module.base_kernel.lengthscale =lengthscale\n",
    "    model.covar_module.outputscale = outputscale\n",
    "    \n",
    "#     print(\"Noise Hyperparameter: \", float(model.likelihood.noise))\n",
    "#     print(\"Lengthscale Hyperparameter: \", float(model.covar_module.base_kernel.lengthscale))\n",
    "#     print(\"Outputscale Hyperparameter: \", float(model.covar_module.outputscale))\n",
    "    \n",
    "    # Get into evaluation (predictive posterior) mode\n",
    "    model.eval()\n",
    "    likelihood.eval();\n",
    "    \n",
    "    #Will compare the rigorous solution and approximation later (multidimensional integral over each experiment using a sparse grid)\n",
    "    #Calculate EI\n",
    "    EI_Components = eval_GP_components(p,n,Xexp,Yexp, theta_mesh, model, likelihood)\n",
    "    EI = EI_Components[0]\n",
    "    Error =EI_Components[1]\n",
    "    y_GP = EI_Components[2]\n",
    "    stdev_GP = EI_Components[3]\n",
    "    error_GP = EI_Components[4]\n",
    "#     print(Error)\n",
    "\n",
    "    #Finds the index where sse is the smallest and finds which Theta combination corresponds to that value\n",
    "    argmin = np.array(np.where(np.isclose(Error, np.amin(Error),atol=1e-10)==True))\n",
    "    Theta_1_Opt = float(theta1_mesh[argmin[0],argmin[1]])\n",
    "    Theta_2_Opt = float(theta2_mesh[argmin[0],argmin[1]])\n",
    "    Theta_Opt_GP = np.array((Theta_1_Opt,Theta_2_Opt))\n",
    "\n",
    "\n",
    "    #calculates best theta value\n",
    "    argmax = np.array(np.where(np.isclose(EI, np.amax(EI),atol=1e-10)==True))\n",
    "    #     print(argmax)\n",
    "    Theta1_Best = float(theta1_mesh[argmax[0],argmax[1]])\n",
    "    Theta2_Best = float(theta2_mesh[argmax[0],argmax[1]])\n",
    "    Theta_Best = np.array((Theta1_Best,Theta2_Best))\n",
    "    \n",
    "    \n",
    "    ##If statement to show convergence\n",
    "    Converge = np.allclose(Theta_Best, train_p[-1,0:2],atol=1e-10)\n",
    "    if Converge == True:\n",
    "        error_plotter(theta_mesh, Error, Theta_True, Theta_Opt_GP,train_p,plot_train=True)\n",
    "        ei_plotter(theta_mesh, EI, Theta_True, Theta_Opt_GP,train_p,plot_train=True)\n",
    "        print(\"Final number of iterations: \", i)\n",
    "        print(\"The GP predicts that Theta =\",Theta_Opt_GP)\n",
    "        print(\"The GP estimates the highest EI is at Theta = \",Theta_Best)\n",
    "        break\n",
    "    \n",
    "#     ei_plotter(theta_mesh, EI, Theta_True, Theta_Opt_GP,train_p,plot_train=True)\n",
    "#     print(\"The GP predicts that Theta =\",Theta_Opt_GP, \" at iteration \", i)\n",
    "#     print(\"The GP estimates the highest EI is at Theta = \",Theta_Best, \" at iteration \", i, \"\\n\")\n",
    "\n",
    "    ##Append best values to training data \n",
    "    #Convert training data to numpy arrays to allow concatenation to work\n",
    "    train_p = train_p.numpy() #(q x t)\n",
    "    train_y = train_y.numpy() #(1 x t)\n",
    "    \n",
    "    #Loops over Xexp values\n",
    "    for i in range(n):\n",
    "#         print(train_y)\n",
    "        ##Calculate y_Best and formal p_Best\n",
    "        #Add 5 test points, same Theta1 and Theta2, but use all values of Xexp\n",
    "        p_Best = np.array([Theta_Best[0],Theta_Best[1],Xexp[i]]) #(q x 1)\n",
    "#         print(p_Best)\n",
    "        y_Best = create_y_data(q,p_Best) #(1 x 1)\n",
    "        \n",
    "        #Add Theta_Best to train_p and y_best to train_y\n",
    "        train_p = np.concatenate((train_p, [p_Best]), axis=0) #(q x t)\n",
    "        train_y = np.concatenate((train_y, [y_Best]),axis=0) #(1 x t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cebf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EI_sing = calc_ei_total_test(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[0]\n",
    "# Error =calc_ei_total_test(p,n,Xexp,Yexp, theta_mesh, model, likelihood)[1]\n",
    "# for i in range(n):    \n",
    "#     ei_plotter_adv_test(theta_mesh, EI_sing[i], Theta_True, train_p,Xexp[i],Theta_Opt_GP,plot_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9397ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot xy data\n",
    "title = \"XY Comparison\"\n",
    "\n",
    "y_GP_Opt = y_GP[argmax[0],argmax[1],:][0]\n",
    "plot_xy(Xexp, Yexp, y_GP_Opt,Theta_True,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f659c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_3D = np.meshgrid(Theta1,Theta2,Xexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev_plot = stdev_plotter_4D(mesh_3D,stdev_GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16656",
   "metadata": {},
   "source": [
    "## Analysis of Standard Deviation\n",
    " - The GP estimates that the standard deviation is lowest at points that were directly tested\n",
    "  - This can be rationalized by the way that the contour plot is drawn\n",
    " - Standard deviation is smallest away from the edges and larger towards them\n",
    "  - This is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The more points that get tested, the more the standard deviations will decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c653c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_plot = error_plotter_4D(mesh_3D,error_GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4a585",
   "metadata": {},
   "source": [
    "## Analysis of Error Magnitude\n",
    " - The GP emulator is most inaccurate when all values of $\\bar{p}$ are at their extreme points \n",
    "  - In general, the GP is less accurate at extreme points, this is rationalized by the fact that there are less neighbors that the GP is tested and trained with at the boundaries\n",
    " - The GP emulator is most accurate after convergence\n",
    " - GP error is mostly very low, as more iterations are added, error decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plot = y_plotter_4D(mesh_3D,y_GP)\n",
    "print(np.amax(y_GP))\n",
    "print(np.amin(y_GP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901d487",
   "metadata": {},
   "source": [
    "## Analysis of GP Emulator (Model y)\n",
    " - The GP emulator correctly captures that y increases as $\\bar{p}$ increases. This tells us that this GP emulator model could be viable\n",
    "  - The GP emulator suitably estimates where the lowest y is achieved and the actual value of y\n",
    "  - Slight error leads to small inaccuracies in the value of $\\bar{\\theta}$ and the values of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dfb0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
